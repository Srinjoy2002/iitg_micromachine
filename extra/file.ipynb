{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd24def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Install only required packages (no roboflow)\n",
    "# pip install --user pycocotools torchvision matplotlib\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pycocotools.coco import COCO\n",
    "from torchvision.transforms import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "# STEP 2: COCO Dataset Class\n",
    "class COCODataset(Dataset):\n",
    "    def __init__(self, root, ann_file):\n",
    "        self.root = root\n",
    "        self.coco = COCO(ann_file)\n",
    "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        while True:\n",
    "            img_id = self.ids[index]\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "            if len(anns) == 0:\n",
    "                index = (index + 1) % len(self.ids)\n",
    "                continue\n",
    "            path = self.coco.loadImgs(img_id)[0]['file_name']\n",
    "            img = Image.open(os.path.join(self.root, path)).convert(\"RGB\")\n",
    "            boxes, labels, masks = [], [], []\n",
    "            for ann in anns:\n",
    "                if ann['iscrowd']: continue\n",
    "                x, y, w, h = ann['bbox']\n",
    "                boxes.append([x, y, x+w, y+h])\n",
    "                labels.append(1)\n",
    "                masks.append(self.coco.annToMask(ann))\n",
    "            if len(boxes) == 0:\n",
    "                index = (index + 1) % len(self.ids)\n",
    "                continue\n",
    "            target = {\n",
    "                'boxes': torch.tensor(boxes, dtype=torch.float32),\n",
    "                'labels': torch.tensor(labels, dtype=torch.int64),\n",
    "                'masks': torch.tensor(np.stack(masks), dtype=torch.uint8),\n",
    "                'image_id': torch.tensor([img_id]),\n",
    "                'area': torch.tensor([ann['area'] for ann in anns], dtype=torch.float32),\n",
    "                'iscrowd': torch.zeros((len(anns),), dtype=torch.int64)\n",
    "            }\n",
    "            img = F.to_tensor(img)\n",
    "            return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# STEP 3: Set paths to your local dataset\n",
    "dataset_path = r\"E:\\ACS motion Controller\\python code\\code\\Microfocus-1\"  # <-- Change this path\n",
    "\n",
    "train_dir = os.path.join(dataset_path, \"train\")\n",
    "val_dir   = os.path.join(dataset_path, \"valid\")\n",
    "test_dir  = os.path.join(dataset_path, \"test\")\n",
    "\n",
    "train_data = COCODataset(train_dir, os.path.join(train_dir, \"_annotations.coco.json\"))\n",
    "val_data   = COCODataset(val_dir, os.path.join(val_dir, \"_annotations.coco.json\"))\n",
    "test_data  = COCODataset(test_dir, os.path.join(test_dir, \"_annotations.coco.json\"))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(val_data, batch_size=2, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(test_data, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# STEP 4: Load and customize the model\n",
    "model = maskrcnn_resnet50_fpn(pretrained=True)\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(model.roi_heads.box_predictor.cls_score.in_features, 2)\n",
    "model.roi_heads.mask_predictor = MaskRCNNPredictor(model.roi_heads.mask_predictor.conv5_mask.in_channels, 256, 2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# STEP 5: Train the model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "num_epochs = 100\n",
    "train_losses, val_losses, maps, ap50s, recalls = [], [], [], [], []\n",
    "\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "def coco_eval(model, dataset, loader):\n",
    "    model.eval()\n",
    "    coco_gt = dataset.coco\n",
    "    coco_dt = []\n",
    "    img_ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, targets in loader:\n",
    "            imgs = [img.to(device) for img in imgs]\n",
    "            outputs = model(imgs)\n",
    "            for target, output in zip(targets, outputs):\n",
    "                image_id = int(target[\"image_id\"].item())\n",
    "                img_ids.append(image_id)\n",
    "                boxes = output[\"boxes\"].cpu().numpy()\n",
    "                scores = output[\"scores\"].cpu().numpy()\n",
    "                labels = output[\"labels\"].cpu().numpy()\n",
    "                for box, score, label in zip(boxes, scores, labels):\n",
    "                    coco_dt.append({\n",
    "                        \"image_id\": image_id,\n",
    "                        \"category_id\": 1,\n",
    "                        \"bbox\": [box[0], box[1], box[2]-box[0], box[3]-box[1]],\n",
    "                        \"score\": float(score)\n",
    "                    })\n",
    "\n",
    "    dt_coco = coco_gt.loadRes(coco_dt)\n",
    "    coco_eval = COCOeval(coco_gt, dt_coco, \"bbox\")\n",
    "    coco_eval.params.imgIds = img_ids\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "    return coco_eval.stats\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for imgs, targets in train_loader:\n",
    "        imgs = [img.to(device) for img in imgs]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        loss_dict = model(imgs, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += losses.item()\n",
    "\n",
    "    model.train()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, targets in val_loader:\n",
    "            imgs = [img.to(device) for img in imgs]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            loss_dict = model(imgs, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            val_loss += losses.item()\n",
    "\n",
    "    metrics = coco_eval(model, val_data, val_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    maps.append(metrics[0])\n",
    "    ap50s.append(metrics[1])\n",
    "    recalls.append(metrics[8])\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}/{num_epochs}] Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | mAP: {metrics[0]:.4f} | AP50: {metrics[1]:.4f} | Recall: {metrics[8]:.4f}\")\n",
    "\n",
    "# STEP 6: Save the model\n",
    "torch.save(model.state_dict(), \"mask_rcnn_microfocus_local.pth\")\n",
    "\n",
    "# STEP 7: Prediction viewer\n",
    "def show_predictions(model, dataset, num=5, threshold=0.3):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(num):\n",
    "            img, _ = dataset[i]\n",
    "            output = model([img.to(device)])[0]\n",
    "            img_np = img.permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            plt.imshow(img_np)\n",
    "            plt.axis('off')\n",
    "            plt.title(f\"Sample {i} | Masks (score â‰¥ {threshold})\")\n",
    "\n",
    "            scores = output['scores'].cpu().numpy()\n",
    "            masks = output['masks'].cpu().numpy()\n",
    "\n",
    "            for j in range(len(scores)):\n",
    "                if scores[j] >= threshold:\n",
    "                    mask = masks[j][0]\n",
    "                    plt.imshow(mask, alpha=0.3, cmap='jet')\n",
    "\n",
    "            plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
