{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-20T06:21:09.774996Z","iopub.execute_input":"2025-06-20T06:21:09.775221Z","iopub.status.idle":"2025-06-20T06:21:09.781808Z","shell.execute_reply.started":"2025-06-20T06:21:09.775204Z","shell.execute_reply":"2025-06-20T06:21:09.780717Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Install dependencies\n!pip install roboflow scikit-learn pandas\n\nimport os, cv2, math, numpy as np, pandas as pd\nfrom glob import glob\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import (\n    Conv2D, BatchNormalization, Activation,\n    UpSampling2D, Concatenate, Dropout,\n    Input, Lambda, Multiply\n)\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import (\n    ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n)\nfrom tensorflow.keras.metrics import MeanIoU\nfrom sklearn.model_selection import KFold\nfrom roboflow import Roboflow\n\n# ─────────────────────────────────────────\n# 0) Download Roboflow YOLO dataset\n# ─────────────────────────────────────────\nrf = Roboflow(api_key=\"qz3gXKPbOfhvVaI8oDt4\")\nproject = rf.workspace(\"rkm-nnbdx\").project(\"microfocus\")\nversion = project.version(8)\ndataset = version.download(\"yolov7\")  # images + labels/*.txt\n\nBASE       = dataset.location            # e.g. \"/kaggle/working/Microfocus-8\"\nIMG_SIZE   = (384, 384)\nBATCH_SIZE = 12\nAUTOTUNE   = tf.data.AUTOTUNE\nEPOCHS     = 100\nSEED       = 42\nLR         = 1e-4\nFOLDS      = 2\nSMOOTH_W   = 7\n\ntf.random.set_seed(SEED)\nnp.random.seed(SEED)\n\n# ─────────────────────────────────────────\n# 1) Generate PNG masks from YOLO polygons\n# ─────────────────────────────────────────\ndef yolo_poly_to_mask(img_path, label_path, out_path, size=IMG_SIZE):\n    w,h = size\n    mask = np.zeros((h, w), dtype=np.uint8)\n    if os.path.exists(label_path):\n        for line in open(label_path):\n            pts = np.array(list(map(float, line.split()[1:])), dtype=np.float32).reshape(-1,2)\n            pts[:,0] *= w; pts[:,1] *= h\n            cv2.fillPoly(mask, [pts.astype(np.int32)], 255)\n    cv2.imwrite(out_path, mask)\n\nfor split in (\"train\",\"valid\",\"test\"):\n    img_dir = os.path.join(BASE, split, \"images\")\n    lbl_dir = os.path.join(BASE, split, \"labels\")\n    msk_dir = os.path.join(BASE, split, \"masks\")\n    os.makedirs(msk_dir, exist_ok=True)\n    for img_p in tqdm(glob(f\"{img_dir}/*.jpg\"), desc=f\"Make masks for {split}\"):\n        fn    = os.path.splitext(os.path.basename(img_p))[0]\n        lbl_p = os.path.join(lbl_dir, fn + \".txt\")\n        out_p = os.path.join(msk_dir, fn + \".png\")\n        yolo_poly_to_mask(img_p, lbl_p, out_p)\n\n# ─────────────────────────────────────────\n# 2) Data pipeline utilities\n# ─────────────────────────────────────────\ndef load_pair(img_path, mask_path):\n    img = tf.io.read_file(img_path)\n    img = tf.image.decode_jpeg(img, 3)\n    img = tf.image.resize(img, IMG_SIZE) / 255.0\n\n    m = tf.io.read_file(mask_path)\n    m = tf.image.decode_png(m, 1)\n    m = tf.image.resize(m, IMG_SIZE, method=\"nearest\")\n    m = tf.cast(m > 127, tf.float32)\n    return img, m\n\ndef augment(img, m):\n    cat = tf.concat([img, m], axis=-1)\n    if tf.random.uniform([]) > 0.5: cat = tf.image.flip_left_right(cat)\n    if tf.random.uniform([]) > 0.5: cat = tf.image.flip_up_down(cat)\n    k = tf.random.uniform([], 0, 4, tf.int32)\n    cat = tf.image.rot90(cat, k)\n    im, ma = cat[...,:3], cat[...,3:]\n    im = tf.image.random_brightness(im, 0.1)\n    im = tf.image.random_contrast(im, 0.9, 1.1)\n    ma = tf.cast(ma>0.5, tf.float32)\n    return im, ma\n\n# **Single** make_ds signature:\ndef make_ds(img_list, mask_list, train=False):\n    ds = tf.data.Dataset.from_tensor_slices((img_list, mask_list))\n    ds = ds.map(load_pair, num_parallel_calls=AUTOTUNE)\n    if train:\n        ds = ds.map(augment, num_parallel_calls=AUTOTUNE)\n        ds = ds.shuffle(200, seed=SEED).batch(BATCH_SIZE).repeat()\n    else:\n        ds = ds.batch(BATCH_SIZE)\n    return ds.prefetch(AUTOTUNE)\n\n# Build train/val/test sets (not used in backbone CV, but here for sanity)\ntrain_ds = make_ds(glob(f\"{BASE}/train/images/*.jpg\"),\n                   [p.replace(\"/images/\",\"/masks/\").replace(\".jpg\",\".png\")\n                    for p in glob(f\"{BASE}/train/images/*.jpg\")],\n                   train=True)\nval_ds   = make_ds(glob(f\"{BASE}/valid/images/*.jpg\"),\n                   [p.replace(\"/images/\",\"/masks/\").replace(\".jpg\",\".png\")\n                    for p in glob(f\"{BASE}/valid/images/*.jpg\")],\n                   train=False)\ntest_ds  = make_ds(glob(f\"{BASE}/test/images/*.jpg\"),\n                   [p.replace(\"/images/\",\"/masks/\").replace(\".jpg\",\".png\")\n                    for p in glob(f\"{BASE}/test/images/*.jpg\")],\n                   train=False)\n\n# ─────────────────────────────────────────\n# 3) Loss & metrics\n# ─────────────────────────────────────────\ndef dice_loss(y_true,y_pred, smooth=1e-6):\n    yt, yp = K.flatten(y_true), K.flatten(y_pred)\n    inter = K.sum(yt*yp)\n    return 1 - (2*inter+smooth)/(K.sum(yt)+K.sum(yp)+smooth)\n\ndef tversky(y_true,y_pred, alpha=0.3,beta=0.7,smooth=1e-6):\n    yt, yp = K.flatten(y_true), K.flatten(y_pred)\n    tp = K.sum(yt*yp); fp = K.sum((1-yt)*yp); fn = K.sum(yt*(1-yp))\n    return (tp+smooth)/(tp+alpha*fp+beta*fn+smooth)\n\ndef focal_tversky(y_true,y_pred):\n    t = tversky(y_true,y_pred)\n    return K.pow((1-t),0.75)\n\ndef combined_loss(y_true,y_pred):\n    return 0.4*dice_loss(y_true,y_pred) + 0.6*focal_tversky(y_true,y_pred)\n\nmetrics = ['accuracy', MeanIoU(num_classes=2,name='mean_iou')]\n\n# ─────────────────────────────────────────\n# 4) Attention‑U‑Net builder\n# ─────────────────────────────────────────\ndef attention_gate(skip, g, inter):\n    θ = Conv2D(inter,1,padding='same')(skip)\n    φ = Conv2D(inter,1,padding='same')(g)\n    up= Lambda(lambda x: tf.image.resize(x[0], tf.shape(x[1])[1:3]))([φ, skip])\n    f = Activation('relu')(θ+up)\n    ψ = Conv2D(1,1,padding='same',activation='sigmoid')(f)\n    return Multiply()([skip, ψ])\n\ndef build_effattunet(backbone):\n    inp = Input((*IMG_SIZE,3))\n    enc = backbone(include_top=False, weights='imagenet', input_tensor=inp)\n    skips = [enc.get_layer(n).output for n in (\n      \"block2a_expand_activation\",\n      \"block3a_expand_activation\",\n      \"block4a_expand_activation\",\n      \"block6a_expand_activation\"\n    )]\n    x = enc.output\n    filters=[256,128,64,32]\n    for i, skip in enumerate(reversed(skips)):\n        x = UpSampling2D()(x)\n        ag = attention_gate(skip, x, inter=filters[i]//2)\n        x  = Concatenate()([x, ag])\n        x  = Conv2D(filters[i],3,padding='same',activation='relu')(x)\n        x  = BatchNormalization()(x)\n        x  = Conv2D(filters[i],3,padding='same',activation='relu')(x)\n        x  = BatchNormalization()(x)\n        x  = Dropout(0.3)(x)\n    # final upsampling to full resolution\n    x = UpSampling2D()(x)\n    x = Conv2D(32,3,padding='same',activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(32,3,padding='same',activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.3)(x)\n    out = Conv2D(1,1,activation='sigmoid')(x)\n    return Model(inp,out)\n\n# ─────────────────────────────────────────\n# 5) Cross‑validation per backbone\n# ─────────────────────────────────────────\nbackbones = {\n  'EffB1': tf.keras.applications.EfficientNetB1,\n  'EffB2': tf.keras.applications.EfficientNetB2,\n  'EffB3': tf.keras.applications.EfficientNetB3\n}\n\nall_imgs  = sorted(glob(f\"{BASE}/train/images/*.jpg\"))\nall_masks = [p.replace(\"/images/\",\"/masks/\").replace(\".jpg\",\".png\")\n             for p in all_imgs]\nkf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n\nresults = {name: [] for name in backbones}\nfor name, eff in backbones.items():\n    print(f\"\\n=== {name} ===\")\n    for fold, (trIdx, valIdx) in enumerate(kf.split(all_imgs)):\n        print(f\" Fold {fold+1}\")\n        trI = [all_imgs[i] for i in trIdx];  trM = [all_masks[i] for i in trIdx]\n        vI  = [all_imgs[i] for i in valIdx]; vM  = [all_masks[i] for i in valIdx]\n\n        dsTr  = make_ds(trI, trM, train=True)\n        dsVal = make_ds(vI, vM, train=False)\n\n        model = build_effattunet(eff)\n        model.compile(optimizer=Adam(LR),\n                      loss=combined_loss,\n                      metrics=metrics)\n\n        def cos_lr(e):\n            t = e % 30\n            return LR * 0.5 * (1 + math.cos(math.pi * t/30))\n        cbs = [\n          LearningRateScheduler(cos_lr, verbose=0),\n          ModelCheckpoint( f\"{name}_f{fold}.h5\",\n                           monitor=\"val_mean_iou\", mode=\"max\",\n                           save_best_only=True),\n          ReduceLROnPlateau( monitor=\"val_mean_iou\",\n                            factor=0.5, patience=10,\n                            mode=\"max\", verbose=0)\n        ]\n\n        steps = len(trI)//BATCH_SIZE\n        vstps = len(vI)//BATCH_SIZE\n        h = model.fit(dsTr,\n                      epochs=EPOCHS,\n                      steps_per_epoch=steps,\n                      validation_data=dsVal,\n                      validation_steps=vstps,\n                      callbacks=cbs,\n                      verbose=1)\n        model.load_weights(f\"{name}_f{fold}.h5\")\n        results[name].append(max(h.history['mean_iou']))\n\n    print(\" →\", name, \"mean IoU:\", np.mean(results[name]))\n\n# ─────────────────────────────────────────\n# 6) Plot backbone comparison\n# ─────────────────────────────────────────\nplt.figure(figsize=(6,4))\nnames  = list(results.keys())\nscores = [np.mean(results[n]) for n in names]\nplt.bar(names, scores, color=['#a6cee3','#1f78b4','#b2df8a'])\nplt.ylabel(\"mIoU\")\nplt.ylim(0,1)\nfor i, v in enumerate(scores):\n    plt.text(i, v+0.01, f\"{v:.3f}\", ha='center')\nplt.title(\"Backbone comparison: EffB1 vs EffB2 vs EffB3\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T06:21:09.888179Z","iopub.execute_input":"2025-06-20T06:21:09.888964Z","iopub.status.idle":"2025-06-20T10:37:42.418950Z","shell.execute_reply.started":"2025-06-20T06:21:09.888930Z","shell.execute_reply":"2025-06-20T10:37:42.418266Z"}},"outputs":[{"name":"stdout","text":"Collecting roboflow\n  Downloading roboflow-1.1.66-py3-none-any.whl.metadata (9.7 kB)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.4.26)\nCollecting idna==3.7 (from roboflow)\n  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.7.2)\nRequirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.26.4)\nCollecting opencv-python-headless==4.10.0.84 (from roboflow)\n  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.1.0)\nCollecting pillow-heif>=0.18.0 (from roboflow)\n  Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.9.0.post0)\nCollecting python-dotenv (from roboflow)\n  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\nRequirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\nRequirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.4.0)\nRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\nRequirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\nRequirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\nCollecting filetype (from roboflow)\n  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->roboflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->roboflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->roboflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->roboflow) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->roboflow) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->roboflow) (2.4.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.57.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (25.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.5->roboflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.5->roboflow) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.18.5->roboflow) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.18.5->roboflow) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.18.5->roboflow) (2024.2.0)\nDownloading roboflow-1.1.66-py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\nDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\nInstalling collected packages: filetype, python-dotenv, pillow-heif, idna, opencv-python-headless, roboflow\n  Attempting uninstall: idna\n    Found existing installation: idna 3.10\n    Uninstalling idna-3.10:\n      Successfully uninstalled idna-3.10\n  Attempting uninstall: opencv-python-headless\n    Found existing installation: opencv-python-headless 4.11.0.86\n    Uninstalling opencv-python-headless-4.11.0.86:\n      Successfully uninstalled opencv-python-headless-4.11.0.86\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-bigtable 2.30.0 requires google-api-core[grpc]<3.0.0,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pillow-heif-0.22.0 python-dotenv-1.1.0 roboflow-1.1.66\nloading Roboflow workspace...\nloading Roboflow project...\n","output_type":"stream"},{"name":"stderr","text":"Make masks for train: 100%|██████████| 1314/1314 [00:00<00:00, 1332.67it/s]\nMake masks for valid: 100%|██████████| 128/128 [00:00<00:00, 1297.43it/s]\nMake masks for test: 100%|██████████| 72/72 [00:00<00:00, 1263.12it/s]\nI0000 00:00:1750400481.886438      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"\n=== EffB1 ===\n Fold 1\nDownloading data from https://storage.googleapis.com/keras-applications/efficientnetb1_notop.h5\n\u001b[1m27018416/27018416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1750400581.890384     102 service.cc:148] XLA service 0x7ed7280025a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1750400581.891250     102 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1750400590.986924     102 cuda_dnn.cc:529] Loaded cuDNN version 90300\nE0000 00:00:1750400611.573271     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750400611.759769     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750400612.244189     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750400612.449776     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750400612.824393     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750400613.030413     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750400613.521654     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750400613.764611     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n2025-06-20 06:23:35.503193: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[256,1952,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,1952,24,24]{3,2,1,0}, f32[12,256,24,24]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n2025-06-20 06:23:35.704939: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.201874285s\nTrying algorithm eng0{} for conv (f32[256,1952,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,1952,24,24]{3,2,1,0}, f32[12,256,24,24]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\nI0000 00:00:1750400666.816182     102 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 720ms/step - accuracy: 0.6323 - loss: 0.6449 - mean_iou: 0.4262 - val_accuracy: 0.8675 - val_loss: 0.8708 - val_mean_iou: 0.4338 - learning_rate: 1.0000e-04\nEpoch 2/100\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1750400730.179075     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750400730.364848     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750400730.839678     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750400731.045515     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750400731.411929     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750400731.617644     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750400732.109534     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750400732.352447     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 394ms/step - accuracy: 0.8596 - loss: 0.4200 - mean_iou: 0.4283 - val_accuracy: 0.8675 - val_loss: 0.9453 - val_mean_iou: 0.4338 - learning_rate: 9.9726e-05\nEpoch 3/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 405ms/step - accuracy: 0.8941 - loss: 0.3526 - mean_iou: 0.4304 - val_accuracy: 0.8675 - val_loss: 0.9779 - val_mean_iou: 0.4338 - learning_rate: 9.8907e-05\nEpoch 4/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 405ms/step - accuracy: 0.9012 - loss: 0.3355 - mean_iou: 0.4436 - val_accuracy: 0.8675 - val_loss: 0.9868 - val_mean_iou: 0.4338 - learning_rate: 9.7553e-05\nEpoch 5/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9069 - loss: 0.3297 - mean_iou: 0.4703 - val_accuracy: 0.8665 - val_loss: 0.9789 - val_mean_iou: 0.4338 - learning_rate: 9.5677e-05\nEpoch 6/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9177 - loss: 0.3210 - mean_iou: 0.5203 - val_accuracy: 0.8791 - val_loss: 0.8434 - val_mean_iou: 0.4338 - learning_rate: 9.3301e-05\nEpoch 7/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 416ms/step - accuracy: 0.9249 - loss: 0.3109 - mean_iou: 0.5638 - val_accuracy: 0.8872 - val_loss: 0.7796 - val_mean_iou: 0.4375 - learning_rate: 9.0451e-05\nEpoch 8/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 416ms/step - accuracy: 0.9323 - loss: 0.3014 - mean_iou: 0.6040 - val_accuracy: 0.8981 - val_loss: 0.6878 - val_mean_iou: 0.5246 - learning_rate: 8.7157e-05\nEpoch 9/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 416ms/step - accuracy: 0.9373 - loss: 0.2761 - mean_iou: 0.6405 - val_accuracy: 0.9096 - val_loss: 0.5746 - val_mean_iou: 0.6474 - learning_rate: 8.3457e-05\nEpoch 10/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9414 - loss: 0.2968 - mean_iou: 0.6896 - val_accuracy: 0.8926 - val_loss: 0.5916 - val_mean_iou: 0.6338 - learning_rate: 7.9389e-05\nEpoch 11/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 415ms/step - accuracy: 0.9424 - loss: 0.2814 - mean_iou: 0.6978 - val_accuracy: 0.9171 - val_loss: 0.5769 - val_mean_iou: 0.6538 - learning_rate: 7.5000e-05\nEpoch 12/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 416ms/step - accuracy: 0.9508 - loss: 0.2537 - mean_iou: 0.7186 - val_accuracy: 0.9272 - val_loss: 0.4737 - val_mean_iou: 0.7105 - learning_rate: 7.0337e-05\nEpoch 13/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 415ms/step - accuracy: 0.9476 - loss: 0.3017 - mean_iou: 0.7324 - val_accuracy: 0.9264 - val_loss: 0.4757 - val_mean_iou: 0.7170 - learning_rate: 6.5451e-05\nEpoch 14/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 416ms/step - accuracy: 0.9425 - loss: 0.2457 - mean_iou: 0.7091 - val_accuracy: 0.9316 - val_loss: 0.4255 - val_mean_iou: 0.7384 - learning_rate: 6.0396e-05\nEpoch 15/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 417ms/step - accuracy: 0.9487 - loss: 0.2644 - mean_iou: 0.7424 - val_accuracy: 0.9201 - val_loss: 0.4003 - val_mean_iou: 0.7540 - learning_rate: 5.5226e-05\nEpoch 16/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 414ms/step - accuracy: 0.9566 - loss: 0.2376 - mean_iou: 0.7845 - val_accuracy: 0.9351 - val_loss: 0.3760 - val_mean_iou: 0.7808 - learning_rate: 5.0000e-05\nEpoch 17/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9535 - loss: 0.2417 - mean_iou: 0.7791 - val_accuracy: 0.9340 - val_loss: 0.4015 - val_mean_iou: 0.7633 - learning_rate: 4.4774e-05\nEpoch 18/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 437ms/step - accuracy: 0.9543 - loss: 0.2607 - mean_iou: 0.7752 - val_accuracy: 0.9417 - val_loss: 0.3678 - val_mean_iou: 0.7930 - learning_rate: 3.9604e-05\nEpoch 19/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9528 - loss: 0.2368 - mean_iou: 0.7716 - val_accuracy: 0.9304 - val_loss: 0.4161 - val_mean_iou: 0.7559 - learning_rate: 3.4549e-05\nEpoch 20/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9587 - loss: 0.2360 - mean_iou: 0.8041 - val_accuracy: 0.9182 - val_loss: 0.3807 - val_mean_iou: 0.7607 - learning_rate: 2.9663e-05\nEpoch 21/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9579 - loss: 0.2257 - mean_iou: 0.7946 - val_accuracy: 0.9201 - val_loss: 0.4622 - val_mean_iou: 0.7267 - learning_rate: 2.5000e-05\nEpoch 22/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9585 - loss: 0.2240 - mean_iou: 0.8123 - val_accuracy: 0.9355 - val_loss: 0.3898 - val_mean_iou: 0.7684 - learning_rate: 2.0611e-05\nEpoch 23/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 389ms/step - accuracy: 0.9594 - loss: 0.2069 - mean_iou: 0.7986 - val_accuracy: 0.9246 - val_loss: 0.3650 - val_mean_iou: 0.7755 - learning_rate: 1.6543e-05\nEpoch 24/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9562 - loss: 0.2411 - mean_iou: 0.7975 - val_accuracy: 0.9150 - val_loss: 0.5176 - val_mean_iou: 0.6688 - learning_rate: 1.2843e-05\nEpoch 25/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 416ms/step - accuracy: 0.9577 - loss: 0.2324 - mean_iou: 0.7908 - val_accuracy: 0.9414 - val_loss: 0.3474 - val_mean_iou: 0.8062 - learning_rate: 9.5492e-06\nEpoch 26/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 416ms/step - accuracy: 0.9556 - loss: 0.2249 - mean_iou: 0.7863 - val_accuracy: 0.9437 - val_loss: 0.3474 - val_mean_iou: 0.8087 - learning_rate: 6.6987e-06\nEpoch 27/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 415ms/step - accuracy: 0.9630 - loss: 0.2092 - mean_iou: 0.8166 - val_accuracy: 0.9449 - val_loss: 0.3488 - val_mean_iou: 0.8103 - learning_rate: 4.3227e-06\nEpoch 28/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 388ms/step - accuracy: 0.9631 - loss: 0.2044 - mean_iou: 0.8109 - val_accuracy: 0.9424 - val_loss: 0.3360 - val_mean_iou: 0.8095 - learning_rate: 2.4472e-06\nEpoch 29/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9627 - loss: 0.2135 - mean_iou: 0.7951 - val_accuracy: 0.9426 - val_loss: 0.3352 - val_mean_iou: 0.8103 - learning_rate: 1.0926e-06\nEpoch 30/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 418ms/step - accuracy: 0.9553 - loss: 0.2266 - mean_iou: 0.7736 - val_accuracy: 0.9427 - val_loss: 0.3364 - val_mean_iou: 0.8103 - learning_rate: 2.7391e-07\nEpoch 31/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 388ms/step - accuracy: 0.9599 - loss: 0.2096 - mean_iou: 0.8098 - val_accuracy: 0.7171 - val_loss: 0.9034 - val_mean_iou: 0.4173 - learning_rate: 1.0000e-04\nEpoch 32/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 389ms/step - accuracy: 0.9455 - loss: 0.2448 - mean_iou: 0.7504 - val_accuracy: 0.6979 - val_loss: 0.6056 - val_mean_iou: 0.5177 - learning_rate: 9.9726e-05\nEpoch 33/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9581 - loss: 0.2050 - mean_iou: 0.8187 - val_accuracy: 0.9028 - val_loss: 0.6036 - val_mean_iou: 0.6335 - learning_rate: 9.8907e-05\nEpoch 34/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9494 - loss: 0.2223 - mean_iou: 0.7664 - val_accuracy: 0.8383 - val_loss: 0.9859 - val_mean_iou: 0.4332 - learning_rate: 9.7553e-05\nEpoch 35/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9565 - loss: 0.1998 - mean_iou: 0.8187 - val_accuracy: 0.4855 - val_loss: 0.7927 - val_mean_iou: 0.3368 - learning_rate: 9.5677e-05\nEpoch 36/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9566 - loss: 0.2148 - mean_iou: 0.8173 - val_accuracy: 0.5049 - val_loss: 0.7890 - val_mean_iou: 0.4144 - learning_rate: 9.3301e-05\nEpoch 37/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9536 - loss: 0.1924 - mean_iou: 0.7972 - val_accuracy: 0.6716 - val_loss: 0.8981 - val_mean_iou: 0.4200 - learning_rate: 9.0451e-05\nEpoch 38/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 389ms/step - accuracy: 0.9620 - loss: 0.1824 - mean_iou: 0.8443 - val_accuracy: 0.9300 - val_loss: 0.3634 - val_mean_iou: 0.7795 - learning_rate: 8.7157e-05\nEpoch 39/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 389ms/step - accuracy: 0.9569 - loss: 0.1951 - mean_iou: 0.8314 - val_accuracy: 0.8167 - val_loss: 0.5838 - val_mean_iou: 0.5905 - learning_rate: 8.3457e-05\nEpoch 40/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9545 - loss: 0.1963 - mean_iou: 0.8019 - val_accuracy: 0.9158 - val_loss: 0.4003 - val_mean_iou: 0.7420 - learning_rate: 7.9389e-05\nEpoch 41/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 389ms/step - accuracy: 0.9588 - loss: 0.1802 - mean_iou: 0.8106 - val_accuracy: 0.5315 - val_loss: 0.8318 - val_mean_iou: 0.3753 - learning_rate: 7.5000e-05\nEpoch 42/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9569 - loss: 0.1829 - mean_iou: 0.8215 - val_accuracy: 0.3824 - val_loss: 0.8370 - val_mean_iou: 0.3418 - learning_rate: 7.0337e-05\nEpoch 43/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 389ms/step - accuracy: 0.9587 - loss: 0.1803 - mean_iou: 0.8319 - val_accuracy: 0.9213 - val_loss: 0.4300 - val_mean_iou: 0.7400 - learning_rate: 6.5451e-05\nEpoch 44/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9582 - loss: 0.1652 - mean_iou: 0.8417 - val_accuracy: 0.9446 - val_loss: 0.3492 - val_mean_iou: 0.8025 - learning_rate: 6.0396e-05\nEpoch 45/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9598 - loss: 0.1734 - mean_iou: 0.8316 - val_accuracy: 0.9443 - val_loss: 0.3552 - val_mean_iou: 0.8006 - learning_rate: 5.5226e-05\nEpoch 46/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9634 - loss: 0.1562 - mean_iou: 0.8390 - val_accuracy: 0.4722 - val_loss: 0.8133 - val_mean_iou: 0.3329 - learning_rate: 5.0000e-05\nEpoch 47/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9611 - loss: 0.1639 - mean_iou: 0.8364 - val_accuracy: 0.5338 - val_loss: 0.7861 - val_mean_iou: 0.3694 - learning_rate: 4.4774e-05\nEpoch 48/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 417ms/step - accuracy: 0.9662 - loss: 0.1451 - mean_iou: 0.8552 - val_accuracy: 0.9436 - val_loss: 0.3248 - val_mean_iou: 0.8124 - learning_rate: 3.9604e-05\nEpoch 49/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9641 - loss: 0.1548 - mean_iou: 0.8422 - val_accuracy: 0.9449 - val_loss: 0.3611 - val_mean_iou: 0.7998 - learning_rate: 3.4549e-05\nEpoch 50/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9631 - loss: 0.1511 - mean_iou: 0.8534 - val_accuracy: 0.9470 - val_loss: 0.3440 - val_mean_iou: 0.8079 - learning_rate: 2.9663e-05\nEpoch 51/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 415ms/step - accuracy: 0.9648 - loss: 0.1560 - mean_iou: 0.8597 - val_accuracy: 0.9524 - val_loss: 0.3108 - val_mean_iou: 0.8309 - learning_rate: 2.5000e-05\nEpoch 52/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9665 - loss: 0.1509 - mean_iou: 0.8630 - val_accuracy: 0.9259 - val_loss: 0.4366 - val_mean_iou: 0.7342 - learning_rate: 2.0611e-05\nEpoch 53/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9683 - loss: 0.1545 - mean_iou: 0.8708 - val_accuracy: 0.9464 - val_loss: 0.3308 - val_mean_iou: 0.8161 - learning_rate: 1.6543e-05\nEpoch 54/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 389ms/step - accuracy: 0.9718 - loss: 0.1390 - mean_iou: 0.8832 - val_accuracy: 0.9480 - val_loss: 0.3120 - val_mean_iou: 0.8219 - learning_rate: 1.2843e-05\nEpoch 55/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9690 - loss: 0.1469 - mean_iou: 0.8718 - val_accuracy: 0.9493 - val_loss: 0.3119 - val_mean_iou: 0.8251 - learning_rate: 9.5492e-06\nEpoch 56/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9710 - loss: 0.1427 - mean_iou: 0.8808 - val_accuracy: 0.9514 - val_loss: 0.3136 - val_mean_iou: 0.8302 - learning_rate: 6.6987e-06\nEpoch 57/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9696 - loss: 0.1330 - mean_iou: 0.8794 - val_accuracy: 0.9480 - val_loss: 0.3253 - val_mean_iou: 0.8191 - learning_rate: 4.3227e-06\nEpoch 58/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9713 - loss: 0.1533 - mean_iou: 0.8762 - val_accuracy: 0.9488 - val_loss: 0.3193 - val_mean_iou: 0.8225 - learning_rate: 2.4472e-06\nEpoch 59/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 415ms/step - accuracy: 0.9656 - loss: 0.1555 - mean_iou: 0.8615 - val_accuracy: 0.9515 - val_loss: 0.3027 - val_mean_iou: 0.8324 - learning_rate: 1.0926e-06\nEpoch 60/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 420ms/step - accuracy: 0.9689 - loss: 0.1397 - mean_iou: 0.8691 - val_accuracy: 0.9522 - val_loss: 0.3012 - val_mean_iou: 0.8342 - learning_rate: 2.7391e-07\nEpoch 61/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9615 - loss: 0.1728 - mean_iou: 0.8529 - val_accuracy: 0.8976 - val_loss: 0.4321 - val_mean_iou: 0.7182 - learning_rate: 1.0000e-04\nEpoch 62/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 394ms/step - accuracy: 0.9668 - loss: 0.1759 - mean_iou: 0.8543 - val_accuracy: 0.9122 - val_loss: 0.4127 - val_mean_iou: 0.7413 - learning_rate: 9.9726e-05\nEpoch 63/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9684 - loss: 0.1722 - mean_iou: 0.8686 - val_accuracy: 0.5343 - val_loss: 0.8533 - val_mean_iou: 0.3721 - learning_rate: 9.8907e-05\nEpoch 64/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9685 - loss: 0.1650 - mean_iou: 0.8665 - val_accuracy: 0.8602 - val_loss: 0.9987 - val_mean_iou: 0.4324 - learning_rate: 9.7553e-05\nEpoch 65/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 389ms/step - accuracy: 0.9675 - loss: 0.1593 - mean_iou: 0.8675 - val_accuracy: 0.2748 - val_loss: 0.7727 - val_mean_iou: 0.2152 - learning_rate: 9.5677e-05\nEpoch 66/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9709 - loss: 0.1665 - mean_iou: 0.8819 - val_accuracy: 0.6068 - val_loss: 0.8488 - val_mean_iou: 0.3679 - learning_rate: 9.3301e-05\nEpoch 67/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9681 - loss: 0.1511 - mean_iou: 0.8763 - val_accuracy: 0.9075 - val_loss: 0.5566 - val_mean_iou: 0.6894 - learning_rate: 9.0451e-05\nEpoch 68/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9657 - loss: 0.1945 - mean_iou: 0.8593 - val_accuracy: 0.9150 - val_loss: 0.4184 - val_mean_iou: 0.7391 - learning_rate: 8.7157e-05\nEpoch 69/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9733 - loss: 0.1665 - mean_iou: 0.8793 - val_accuracy: 0.5131 - val_loss: 0.8186 - val_mean_iou: 0.4009 - learning_rate: 8.3457e-05\nEpoch 70/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 389ms/step - accuracy: 0.9766 - loss: 0.1440 - mean_iou: 0.8976 - val_accuracy: 0.4580 - val_loss: 0.7882 - val_mean_iou: 0.4095 - learning_rate: 7.9389e-05\nEpoch 71/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9711 - loss: 0.1539 - mean_iou: 0.8806 - val_accuracy: 0.9260 - val_loss: 0.5226 - val_mean_iou: 0.7088 - learning_rate: 7.5000e-05\nEpoch 72/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9692 - loss: 0.1603 - mean_iou: 0.8783 - val_accuracy: 0.9314 - val_loss: 0.4483 - val_mean_iou: 0.7552 - learning_rate: 7.0337e-05\nEpoch 73/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9700 - loss: 0.1573 - mean_iou: 0.8762 - val_accuracy: 0.8879 - val_loss: 0.8094 - val_mean_iou: 0.5282 - learning_rate: 6.5451e-05\nEpoch 74/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9767 - loss: 0.1388 - mean_iou: 0.9020 - val_accuracy: 0.3852 - val_loss: 0.7826 - val_mean_iou: 0.3524 - learning_rate: 6.0396e-05\nEpoch 75/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 389ms/step - accuracy: 0.9759 - loss: 0.1360 - mean_iou: 0.9001 - val_accuracy: 0.8834 - val_loss: 0.8502 - val_mean_iou: 0.5128 - learning_rate: 5.5226e-05\nEpoch 76/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 389ms/step - accuracy: 0.9730 - loss: 0.1411 - mean_iou: 0.8937 - val_accuracy: 0.7441 - val_loss: 0.9686 - val_mean_iou: 0.4152 - learning_rate: 5.0000e-05\nEpoch 77/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9768 - loss: 0.1297 - mean_iou: 0.9047 - val_accuracy: 0.9263 - val_loss: 0.4212 - val_mean_iou: 0.7514 - learning_rate: 4.4774e-05\nEpoch 78/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9722 - loss: 0.1459 - mean_iou: 0.8879 - val_accuracy: 0.8425 - val_loss: 0.7460 - val_mean_iou: 0.5314 - learning_rate: 3.9604e-05\nEpoch 79/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9742 - loss: 0.1334 - mean_iou: 0.8952 - val_accuracy: 0.6170 - val_loss: 0.7169 - val_mean_iou: 0.4008 - learning_rate: 3.4549e-05\nEpoch 80/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9768 - loss: 0.1260 - mean_iou: 0.9056 - val_accuracy: 0.8717 - val_loss: 0.8605 - val_mean_iou: 0.4815 - learning_rate: 2.9663e-05\nEpoch 81/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9745 - loss: 0.1358 - mean_iou: 0.8990 - val_accuracy: 0.9415 - val_loss: 0.3944 - val_mean_iou: 0.7710 - learning_rate: 2.5000e-05\nEpoch 82/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9802 - loss: 0.1192 - mean_iou: 0.9133 - val_accuracy: 0.9476 - val_loss: 0.3635 - val_mean_iou: 0.7981 - learning_rate: 2.0611e-05\nEpoch 83/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9754 - loss: 0.1312 - mean_iou: 0.9004 - val_accuracy: 0.9507 - val_loss: 0.3360 - val_mean_iou: 0.8141 - learning_rate: 1.6543e-05\nEpoch 84/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 417ms/step - accuracy: 0.9719 - loss: 0.1428 - mean_iou: 0.8840 - val_accuracy: 0.9580 - val_loss: 0.2866 - val_mean_iou: 0.8495 - learning_rate: 1.2843e-05\nEpoch 85/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9747 - loss: 0.1236 - mean_iou: 0.8996 - val_accuracy: 0.9565 - val_loss: 0.3139 - val_mean_iou: 0.8402 - learning_rate: 9.5492e-06\nEpoch 86/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9768 - loss: 0.1154 - mean_iou: 0.9088 - val_accuracy: 0.9570 - val_loss: 0.3001 - val_mean_iou: 0.8446 - learning_rate: 6.6987e-06\nEpoch 87/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9765 - loss: 0.1202 - mean_iou: 0.9038 - val_accuracy: 0.9568 - val_loss: 0.3087 - val_mean_iou: 0.8425 - learning_rate: 4.3227e-06\nEpoch 88/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9780 - loss: 0.1174 - mean_iou: 0.9120 - val_accuracy: 0.9582 - val_loss: 0.2984 - val_mean_iou: 0.8474 - learning_rate: 2.4472e-06\nEpoch 89/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 414ms/step - accuracy: 0.9780 - loss: 0.1185 - mean_iou: 0.9093 - val_accuracy: 0.9590 - val_loss: 0.2857 - val_mean_iou: 0.8520 - learning_rate: 1.0926e-06\nEpoch 90/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9750 - loss: 0.1255 - mean_iou: 0.9017 - val_accuracy: 0.9590 - val_loss: 0.2857 - val_mean_iou: 0.8520 - learning_rate: 2.7391e-07\nEpoch 91/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9784 - loss: 0.1148 - mean_iou: 0.9107 - val_accuracy: 0.9125 - val_loss: 0.5069 - val_mean_iou: 0.6759 - learning_rate: 1.0000e-04\nEpoch 92/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9704 - loss: 0.1346 - mean_iou: 0.8880 - val_accuracy: 0.7997 - val_loss: 0.5403 - val_mean_iou: 0.5997 - learning_rate: 9.9726e-05\nEpoch 93/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9715 - loss: 0.1396 - mean_iou: 0.8926 - val_accuracy: 0.9185 - val_loss: 0.4838 - val_mean_iou: 0.7166 - learning_rate: 9.8907e-05\nEpoch 94/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9648 - loss: 0.1705 - mean_iou: 0.8619 - val_accuracy: 0.8702 - val_loss: 0.9862 - val_mean_iou: 0.4450 - learning_rate: 9.7553e-05\nEpoch 95/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9677 - loss: 0.1387 - mean_iou: 0.8811 - val_accuracy: 0.9213 - val_loss: 0.6094 - val_mean_iou: 0.6736 - learning_rate: 9.5677e-05\nEpoch 96/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9700 - loss: 0.1364 - mean_iou: 0.8878 - val_accuracy: 0.3540 - val_loss: 0.7832 - val_mean_iou: 0.4095 - learning_rate: 9.3301e-05\nEpoch 97/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9671 - loss: 0.1315 - mean_iou: 0.8692 - val_accuracy: 0.5951 - val_loss: 0.8421 - val_mean_iou: 0.4087 - learning_rate: 9.0451e-05\nEpoch 98/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9703 - loss: 0.1348 - mean_iou: 0.8927 - val_accuracy: 0.6310 - val_loss: 0.8601 - val_mean_iou: 0.4161 - learning_rate: 8.7157e-05\nEpoch 99/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9726 - loss: 0.1219 - mean_iou: 0.9006 - val_accuracy: 0.2491 - val_loss: 0.7692 - val_mean_iou: 0.4302 - learning_rate: 8.3457e-05\nEpoch 100/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9725 - loss: 0.1220 - mean_iou: 0.9020 - val_accuracy: 0.4311 - val_loss: 0.8066 - val_mean_iou: 0.4098 - learning_rate: 7.9389e-05\n Fold 2\nEpoch 1/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 674ms/step - accuracy: 0.6167 - loss: 0.6640 - mean_iou: 0.4174 - val_accuracy: 0.8632 - val_loss: 0.8759 - val_mean_iou: 0.4316 - learning_rate: 1.0000e-04\nEpoch 2/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 393ms/step - accuracy: 0.8579 - loss: 0.4618 - mean_iou: 0.4385 - val_accuracy: 0.8632 - val_loss: 0.9558 - val_mean_iou: 0.4316 - learning_rate: 9.9726e-05\nEpoch 3/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 404ms/step - accuracy: 0.8918 - loss: 0.3748 - mean_iou: 0.4403 - val_accuracy: 0.8632 - val_loss: 0.9851 - val_mean_iou: 0.4316 - learning_rate: 9.8907e-05\nEpoch 4/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 401ms/step - accuracy: 0.9075 - loss: 0.3533 - mean_iou: 0.4787 - val_accuracy: 0.8634 - val_loss: 0.9893 - val_mean_iou: 0.4316 - learning_rate: 9.7553e-05\nEpoch 5/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 421ms/step - accuracy: 0.9146 - loss: 0.3301 - mean_iou: 0.5391 - val_accuracy: 0.8686 - val_loss: 0.9406 - val_mean_iou: 0.4323 - learning_rate: 9.5677e-05\nEpoch 6/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 415ms/step - accuracy: 0.9322 - loss: 0.2959 - mean_iou: 0.6395 - val_accuracy: 0.8756 - val_loss: 0.8823 - val_mean_iou: 0.4619 - learning_rate: 9.3301e-05\nEpoch 7/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9221 - loss: 0.3477 - mean_iou: 0.6691 - val_accuracy: 0.8633 - val_loss: 0.9849 - val_mean_iou: 0.4339 - learning_rate: 9.0451e-05\nEpoch 8/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9325 - loss: 0.2973 - mean_iou: 0.7189 - val_accuracy: 0.8637 - val_loss: 0.9885 - val_mean_iou: 0.4335 - learning_rate: 8.7157e-05\nEpoch 9/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 389ms/step - accuracy: 0.9356 - loss: 0.3015 - mean_iou: 0.7397 - val_accuracy: 0.8646 - val_loss: 0.9814 - val_mean_iou: 0.4357 - learning_rate: 8.3457e-05\nEpoch 10/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 419ms/step - accuracy: 0.9419 - loss: 0.2741 - mean_iou: 0.7582 - val_accuracy: 0.8973 - val_loss: 0.6079 - val_mean_iou: 0.6459 - learning_rate: 7.9389e-05\nEpoch 11/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 394ms/step - accuracy: 0.9406 - loss: 0.2770 - mean_iou: 0.7635 - val_accuracy: 0.7960 - val_loss: 0.9430 - val_mean_iou: 0.4291 - learning_rate: 7.5000e-05\nEpoch 12/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9453 - loss: 0.2892 - mean_iou: 0.7845 - val_accuracy: 0.8731 - val_loss: 0.8801 - val_mean_iou: 0.4762 - learning_rate: 7.0337e-05\nEpoch 13/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9497 - loss: 0.2773 - mean_iou: 0.7973 - val_accuracy: 0.8716 - val_loss: 0.8950 - val_mean_iou: 0.4710 - learning_rate: 6.5451e-05\nEpoch 14/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9483 - loss: 0.2430 - mean_iou: 0.7972 - val_accuracy: 0.7053 - val_loss: 0.8564 - val_mean_iou: 0.4244 - learning_rate: 6.0396e-05\nEpoch 15/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 415ms/step - accuracy: 0.9498 - loss: 0.2648 - mean_iou: 0.7969 - val_accuracy: 0.8909 - val_loss: 0.5326 - val_mean_iou: 0.6675 - learning_rate: 5.5226e-05\nEpoch 16/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9490 - loss: 0.2735 - mean_iou: 0.7945 - val_accuracy: 0.7273 - val_loss: 0.6460 - val_mean_iou: 0.4950 - learning_rate: 5.0000e-05\nEpoch 17/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9553 - loss: 0.2480 - mean_iou: 0.8172 - val_accuracy: 0.8635 - val_loss: 0.7500 - val_mean_iou: 0.5264 - learning_rate: 4.4774e-05\nEpoch 18/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9550 - loss: 0.2463 - mean_iou: 0.8166 - val_accuracy: 0.8910 - val_loss: 0.6615 - val_mean_iou: 0.5924 - learning_rate: 3.9604e-05\nEpoch 19/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9545 - loss: 0.2604 - mean_iou: 0.8124 - val_accuracy: 0.9029 - val_loss: 0.6131 - val_mean_iou: 0.6469 - learning_rate: 3.4549e-05\nEpoch 20/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 419ms/step - accuracy: 0.9645 - loss: 0.2191 - mean_iou: 0.8533 - val_accuracy: 0.9133 - val_loss: 0.5540 - val_mean_iou: 0.6802 - learning_rate: 2.9663e-05\nEpoch 21/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9559 - loss: 0.2297 - mean_iou: 0.8315 - val_accuracy: 0.8520 - val_loss: 0.6091 - val_mean_iou: 0.6160 - learning_rate: 2.5000e-05\nEpoch 22/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9593 - loss: 0.2189 - mean_iou: 0.8330 - val_accuracy: 0.8209 - val_loss: 0.9760 - val_mean_iou: 0.4269 - learning_rate: 2.0611e-05\nEpoch 23/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9607 - loss: 0.2124 - mean_iou: 0.8444 - val_accuracy: 0.8994 - val_loss: 0.5915 - val_mean_iou: 0.6581 - learning_rate: 1.6543e-05\nEpoch 24/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 417ms/step - accuracy: 0.9666 - loss: 0.1899 - mean_iou: 0.8650 - val_accuracy: 0.9191 - val_loss: 0.4735 - val_mean_iou: 0.7303 - learning_rate: 1.2843e-05\nEpoch 25/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9562 - loss: 0.2354 - mean_iou: 0.8177 - val_accuracy: 0.9135 - val_loss: 0.6016 - val_mean_iou: 0.6607 - learning_rate: 9.5492e-06\nEpoch 26/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 417ms/step - accuracy: 0.9638 - loss: 0.2031 - mean_iou: 0.8535 - val_accuracy: 0.9377 - val_loss: 0.4319 - val_mean_iou: 0.7692 - learning_rate: 6.6987e-06\nEpoch 27/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 417ms/step - accuracy: 0.9619 - loss: 0.2040 - mean_iou: 0.8488 - val_accuracy: 0.9527 - val_loss: 0.3284 - val_mean_iou: 0.8336 - learning_rate: 4.3227e-06\nEpoch 28/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9626 - loss: 0.1981 - mean_iou: 0.8505 - val_accuracy: 0.9515 - val_loss: 0.3304 - val_mean_iou: 0.8327 - learning_rate: 2.4472e-06\nEpoch 29/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 420ms/step - accuracy: 0.9601 - loss: 0.2262 - mean_iou: 0.8397 - val_accuracy: 0.9516 - val_loss: 0.3185 - val_mean_iou: 0.8344 - learning_rate: 1.0926e-06\nEpoch 30/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9606 - loss: 0.2091 - mean_iou: 0.8383 - val_accuracy: 0.9513 - val_loss: 0.3160 - val_mean_iou: 0.8342 - learning_rate: 2.7391e-07\nEpoch 31/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9589 - loss: 0.2068 - mean_iou: 0.8376 - val_accuracy: 0.8306 - val_loss: 0.9613 - val_mean_iou: 0.4306 - learning_rate: 1.0000e-04\nEpoch 32/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 394ms/step - accuracy: 0.9511 - loss: 0.2412 - mean_iou: 0.8126 - val_accuracy: 0.8642 - val_loss: 0.9398 - val_mean_iou: 0.4610 - learning_rate: 9.9726e-05\nEpoch 33/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9575 - loss: 0.1956 - mean_iou: 0.8426 - val_accuracy: 0.8492 - val_loss: 0.9873 - val_mean_iou: 0.4310 - learning_rate: 9.8907e-05\nEpoch 34/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 389ms/step - accuracy: 0.9541 - loss: 0.2218 - mean_iou: 0.8252 - val_accuracy: 0.7648 - val_loss: 0.9438 - val_mean_iou: 0.4133 - learning_rate: 9.7553e-05\nEpoch 35/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 394ms/step - accuracy: 0.9592 - loss: 0.1934 - mean_iou: 0.8449 - val_accuracy: 0.5424 - val_loss: 0.6822 - val_mean_iou: 0.3511 - learning_rate: 9.5677e-05\nEpoch 36/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 389ms/step - accuracy: 0.9532 - loss: 0.2084 - mean_iou: 0.8344 - val_accuracy: 0.7554 - val_loss: 0.9070 - val_mean_iou: 0.4203 - learning_rate: 9.3301e-05\nEpoch 37/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 389ms/step - accuracy: 0.9575 - loss: 0.1925 - mean_iou: 0.8478 - val_accuracy: 0.6427 - val_loss: 0.8652 - val_mean_iou: 0.3857 - learning_rate: 9.0451e-05\nEpoch 38/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9659 - loss: 0.1711 - mean_iou: 0.8713 - val_accuracy: 0.8649 - val_loss: 0.9411 - val_mean_iou: 0.4596 - learning_rate: 8.7157e-05\nEpoch 39/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9637 - loss: 0.1667 - mean_iou: 0.8669 - val_accuracy: 0.6910 - val_loss: 0.9229 - val_mean_iou: 0.3806 - learning_rate: 8.3457e-05\nEpoch 40/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 394ms/step - accuracy: 0.9625 - loss: 0.1795 - mean_iou: 0.8597 - val_accuracy: 0.8580 - val_loss: 0.8599 - val_mean_iou: 0.4874 - learning_rate: 7.9389e-05\nEpoch 41/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9657 - loss: 0.1505 - mean_iou: 0.8781 - val_accuracy: 0.8544 - val_loss: 0.9915 - val_mean_iou: 0.4308 - learning_rate: 7.5000e-05\nEpoch 42/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9637 - loss: 0.1643 - mean_iou: 0.8704 - val_accuracy: 0.9198 - val_loss: 0.5339 - val_mean_iou: 0.6888 - learning_rate: 7.0337e-05\nEpoch 43/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 389ms/step - accuracy: 0.9631 - loss: 0.1728 - mean_iou: 0.8634 - val_accuracy: 0.8646 - val_loss: 0.9632 - val_mean_iou: 0.4426 - learning_rate: 6.5451e-05\nEpoch 44/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9668 - loss: 0.1524 - mean_iou: 0.8799 - val_accuracy: 0.9439 - val_loss: 0.4001 - val_mean_iou: 0.7885 - learning_rate: 6.0396e-05\nEpoch 45/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9618 - loss: 0.1805 - mean_iou: 0.8605 - val_accuracy: 0.9052 - val_loss: 0.4927 - val_mean_iou: 0.6942 - learning_rate: 5.5226e-05\nEpoch 46/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 394ms/step - accuracy: 0.9667 - loss: 0.1590 - mean_iou: 0.8770 - val_accuracy: 0.9262 - val_loss: 0.4638 - val_mean_iou: 0.7294 - learning_rate: 5.0000e-05\nEpoch 47/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9686 - loss: 0.1470 - mean_iou: 0.8830 - val_accuracy: 0.8764 - val_loss: 0.7775 - val_mean_iou: 0.5130 - learning_rate: 4.4774e-05\nEpoch 48/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 389ms/step - accuracy: 0.9589 - loss: 0.1823 - mean_iou: 0.8560 - val_accuracy: 0.9342 - val_loss: 0.4496 - val_mean_iou: 0.7452 - learning_rate: 3.9604e-05\nEpoch 49/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9657 - loss: 0.1624 - mean_iou: 0.8753 - val_accuracy: 0.9065 - val_loss: 0.6053 - val_mean_iou: 0.6515 - learning_rate: 3.4549e-05\nEpoch 50/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9710 - loss: 0.1378 - mean_iou: 0.8932 - val_accuracy: 0.9205 - val_loss: 0.5481 - val_mean_iou: 0.6832 - learning_rate: 2.9663e-05\nEpoch 51/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9706 - loss: 0.1435 - mean_iou: 0.8895 - val_accuracy: 0.9309 - val_loss: 0.4380 - val_mean_iou: 0.7524 - learning_rate: 2.5000e-05\nEpoch 52/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9727 - loss: 0.1361 - mean_iou: 0.8971 - val_accuracy: 0.6927 - val_loss: 0.8652 - val_mean_iou: 0.3984 - learning_rate: 2.0611e-05\nEpoch 53/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 394ms/step - accuracy: 0.9710 - loss: 0.1438 - mean_iou: 0.8874 - val_accuracy: 0.8844 - val_loss: 0.8114 - val_mean_iou: 0.5241 - learning_rate: 1.6543e-05\nEpoch 54/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9723 - loss: 0.1451 - mean_iou: 0.8935 - val_accuracy: 0.9523 - val_loss: 0.3276 - val_mean_iou: 0.8240 - learning_rate: 1.2843e-05\nEpoch 55/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9678 - loss: 0.1544 - mean_iou: 0.8800 - val_accuracy: 0.9469 - val_loss: 0.3767 - val_mean_iou: 0.7982 - learning_rate: 9.5492e-06\nEpoch 56/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 394ms/step - accuracy: 0.9703 - loss: 0.1509 - mean_iou: 0.8854 - val_accuracy: 0.9420 - val_loss: 0.3917 - val_mean_iou: 0.7779 - learning_rate: 6.6987e-06\nEpoch 57/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9697 - loss: 0.1470 - mean_iou: 0.8865 - val_accuracy: 0.9028 - val_loss: 0.6485 - val_mean_iou: 0.6059 - learning_rate: 4.3227e-06\nEpoch 58/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 395ms/step - accuracy: 0.9742 - loss: 0.1414 - mean_iou: 0.8981 - val_accuracy: 0.9515 - val_loss: 0.3304 - val_mean_iou: 0.8196 - learning_rate: 2.4472e-06\nEpoch 59/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 415ms/step - accuracy: 0.9686 - loss: 0.1568 - mean_iou: 0.8801 - val_accuracy: 0.9578 - val_loss: 0.2933 - val_mean_iou: 0.8474 - learning_rate: 1.0926e-06\nEpoch 60/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 416ms/step - accuracy: 0.9705 - loss: 0.1444 - mean_iou: 0.8894 - val_accuracy: 0.9579 - val_loss: 0.2860 - val_mean_iou: 0.8487 - learning_rate: 2.7391e-07\nEpoch 61/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9730 - loss: 0.1393 - mean_iou: 0.8973 - val_accuracy: 0.7583 - val_loss: 0.9041 - val_mean_iou: 0.4195 - learning_rate: 1.0000e-04\nEpoch 62/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9683 - loss: 0.1493 - mean_iou: 0.8814 - val_accuracy: 0.6188 - val_loss: 0.8206 - val_mean_iou: 0.3748 - learning_rate: 9.9726e-05\nEpoch 63/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9697 - loss: 0.1770 - mean_iou: 0.8828 - val_accuracy: 0.8897 - val_loss: 0.7107 - val_mean_iou: 0.5678 - learning_rate: 9.8907e-05\nEpoch 64/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9686 - loss: 0.1827 - mean_iou: 0.8668 - val_accuracy: 0.7008 - val_loss: 0.9629 - val_mean_iou: 0.3633 - learning_rate: 9.7553e-05\nEpoch 65/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9712 - loss: 0.1596 - mean_iou: 0.8849 - val_accuracy: 0.7008 - val_loss: 0.8817 - val_mean_iou: 0.4029 - learning_rate: 9.5677e-05\nEpoch 66/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9735 - loss: 0.1542 - mean_iou: 0.8908 - val_accuracy: 0.7960 - val_loss: 0.9260 - val_mean_iou: 0.4319 - learning_rate: 9.3301e-05\nEpoch 67/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9727 - loss: 0.1382 - mean_iou: 0.8951 - val_accuracy: 0.9044 - val_loss: 0.4280 - val_mean_iou: 0.7275 - learning_rate: 9.0451e-05\nEpoch 68/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9726 - loss: 0.1671 - mean_iou: 0.8779 - val_accuracy: 0.7959 - val_loss: 0.9384 - val_mean_iou: 0.4260 - learning_rate: 8.7157e-05\nEpoch 69/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9774 - loss: 0.1328 - mean_iou: 0.9042 - val_accuracy: 0.9197 - val_loss: 0.5280 - val_mean_iou: 0.6899 - learning_rate: 8.3457e-05\nEpoch 70/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 395ms/step - accuracy: 0.9713 - loss: 0.1851 - mean_iou: 0.8724 - val_accuracy: 0.7816 - val_loss: 0.9438 - val_mean_iou: 0.4177 - learning_rate: 7.9389e-05\nEpoch 71/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9716 - loss: 0.1479 - mean_iou: 0.8855 - val_accuracy: 0.8713 - val_loss: 0.9303 - val_mean_iou: 0.4649 - learning_rate: 7.5000e-05\nEpoch 72/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9687 - loss: 0.1657 - mean_iou: 0.8791 - val_accuracy: 0.8744 - val_loss: 0.7051 - val_mean_iou: 0.5487 - learning_rate: 7.0337e-05\nEpoch 73/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9744 - loss: 0.1358 - mean_iou: 0.8969 - val_accuracy: 0.3940 - val_loss: 0.7456 - val_mean_iou: 0.2414 - learning_rate: 6.5451e-05\nEpoch 74/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9726 - loss: 0.1821 - mean_iou: 0.8796 - val_accuracy: 0.9076 - val_loss: 0.5404 - val_mean_iou: 0.6671 - learning_rate: 6.0396e-05\nEpoch 75/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9751 - loss: 0.1471 - mean_iou: 0.8974 - val_accuracy: 0.8820 - val_loss: 0.7931 - val_mean_iou: 0.5264 - learning_rate: 5.5226e-05\nEpoch 76/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9765 - loss: 0.1372 - mean_iou: 0.9024 - val_accuracy: 0.8758 - val_loss: 0.8673 - val_mean_iou: 0.4883 - learning_rate: 5.0000e-05\nEpoch 77/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9766 - loss: 0.1699 - mean_iou: 0.8944 - val_accuracy: 0.8828 - val_loss: 0.6396 - val_mean_iou: 0.5845 - learning_rate: 4.4774e-05\nEpoch 78/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 389ms/step - accuracy: 0.9764 - loss: 0.1433 - mean_iou: 0.9004 - val_accuracy: 0.8970 - val_loss: 0.6302 - val_mean_iou: 0.5930 - learning_rate: 3.9604e-05\nEpoch 79/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 394ms/step - accuracy: 0.9776 - loss: 0.1195 - mean_iou: 0.9117 - val_accuracy: 0.9490 - val_loss: 0.3583 - val_mean_iou: 0.8058 - learning_rate: 3.4549e-05\nEpoch 80/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9789 - loss: 0.1158 - mean_iou: 0.9126 - val_accuracy: 0.9341 - val_loss: 0.4369 - val_mean_iou: 0.7418 - learning_rate: 2.9663e-05\nEpoch 81/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9728 - loss: 0.1632 - mean_iou: 0.8899 - val_accuracy: 0.8021 - val_loss: 0.7995 - val_mean_iou: 0.4806 - learning_rate: 2.5000e-05\nEpoch 82/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9793 - loss: 0.1211 - mean_iou: 0.9153 - val_accuracy: 0.8796 - val_loss: 0.7018 - val_mean_iou: 0.5591 - learning_rate: 2.0611e-05\nEpoch 83/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9802 - loss: 0.1055 - mean_iou: 0.9211 - val_accuracy: 0.9545 - val_loss: 0.3123 - val_mean_iou: 0.8327 - learning_rate: 1.6543e-05\nEpoch 84/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 415ms/step - accuracy: 0.9768 - loss: 0.1263 - mean_iou: 0.9104 - val_accuracy: 0.9596 - val_loss: 0.2810 - val_mean_iou: 0.8515 - learning_rate: 1.2843e-05\nEpoch 85/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9793 - loss: 0.1108 - mean_iou: 0.9186 - val_accuracy: 0.9589 - val_loss: 0.2764 - val_mean_iou: 0.8515 - learning_rate: 9.5492e-06\nEpoch 86/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9781 - loss: 0.1208 - mean_iou: 0.9160 - val_accuracy: 0.9506 - val_loss: 0.3544 - val_mean_iou: 0.8137 - learning_rate: 6.6987e-06\nEpoch 87/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9768 - loss: 0.1138 - mean_iou: 0.9138 - val_accuracy: 0.9562 - val_loss: 0.3156 - val_mean_iou: 0.8371 - learning_rate: 4.3227e-06\nEpoch 88/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 394ms/step - accuracy: 0.9787 - loss: 0.1103 - mean_iou: 0.9173 - val_accuracy: 0.9592 - val_loss: 0.2805 - val_mean_iou: 0.8515 - learning_rate: 2.4472e-06\nEpoch 89/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 416ms/step - accuracy: 0.9785 - loss: 0.1128 - mean_iou: 0.9169 - val_accuracy: 0.9596 - val_loss: 0.2755 - val_mean_iou: 0.8534 - learning_rate: 1.0926e-06\nEpoch 90/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 415ms/step - accuracy: 0.9774 - loss: 0.1159 - mean_iou: 0.9114 - val_accuracy: 0.9595 - val_loss: 0.2730 - val_mean_iou: 0.8538 - learning_rate: 2.7391e-07\nEpoch 91/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9732 - loss: 0.1281 - mean_iou: 0.9017 - val_accuracy: 0.2326 - val_loss: 0.7672 - val_mean_iou: 0.4328 - learning_rate: 1.0000e-04\nEpoch 92/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9772 - loss: 0.1198 - mean_iou: 0.9115 - val_accuracy: 0.6272 - val_loss: 0.8662 - val_mean_iou: 0.3650 - learning_rate: 9.9726e-05\nEpoch 93/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 391ms/step - accuracy: 0.9739 - loss: 0.1200 - mean_iou: 0.9047 - val_accuracy: 0.8374 - val_loss: 0.9683 - val_mean_iou: 0.4329 - learning_rate: 9.8907e-05\nEpoch 94/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 389ms/step - accuracy: 0.9735 - loss: 0.1316 - mean_iou: 0.9002 - val_accuracy: 0.9337 - val_loss: 0.4397 - val_mean_iou: 0.7489 - learning_rate: 9.7553e-05\nEpoch 95/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9763 - loss: 0.1180 - mean_iou: 0.9113 - val_accuracy: 0.7443 - val_loss: 0.7894 - val_mean_iou: 0.4406 - learning_rate: 9.5677e-05\nEpoch 96/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 394ms/step - accuracy: 0.9734 - loss: 0.1346 - mean_iou: 0.8979 - val_accuracy: 0.8558 - val_loss: 0.9439 - val_mean_iou: 0.4421 - learning_rate: 9.3301e-05\nEpoch 97/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 393ms/step - accuracy: 0.9683 - loss: 0.1454 - mean_iou: 0.8872 - val_accuracy: 0.8654 - val_loss: 0.9615 - val_mean_iou: 0.4442 - learning_rate: 9.0451e-05\nEpoch 98/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.9724 - loss: 0.1287 - mean_iou: 0.8998 - val_accuracy: 0.8106 - val_loss: 0.9422 - val_mean_iou: 0.4346 - learning_rate: 8.7157e-05\nEpoch 99/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9703 - loss: 0.1322 - mean_iou: 0.8946 - val_accuracy: 0.8296 - val_loss: 0.9560 - val_mean_iou: 0.4350 - learning_rate: 8.3457e-05\nEpoch 100/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 389ms/step - accuracy: 0.9732 - loss: 0.1226 - mean_iou: 0.9031 - val_accuracy: 0.8338 - val_loss: 0.9664 - val_mean_iou: 0.4323 - learning_rate: 7.9389e-05\n → EffB1 mean IoU: 0.9111467897891998\n\n=== EffB2 ===\n Fold 1\nDownloading data from https://storage.googleapis.com/keras-applications/efficientnetb2_notop.h5\n\u001b[1m31790344/31790344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1750405355.086930     103 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750405355.276493     103 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750405355.809304     103 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750405356.020072     103 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750405356.401695     103 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750405356.612739     103 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750405357.199172     103 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750405357.451066     103 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n2025-06-20 07:42:39.247222: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[256,2128,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,2128,24,24]{3,2,1,0}, f32[12,256,24,24]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n2025-06-20 07:42:39.557785: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.310741467s\nTrying algorithm eng0{} for conv (f32[256,2128,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,2128,24,24]{3,2,1,0}, f32[12,256,24,24]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 739ms/step - accuracy: 0.6499 - loss: 0.6287 - mean_iou: 0.4307 - val_accuracy: 0.8675 - val_loss: 0.8692 - val_mean_iou: 0.4338 - learning_rate: 1.0000e-04\nEpoch 2/100\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1750405460.834331     103 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750405461.022561     103 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750405461.510893     103 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750405461.720800     103 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750405462.093508     103 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750405462.303544     103 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750405462.821997     103 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750405463.073991     103 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 407ms/step - accuracy: 0.8656 - loss: 0.4093 - mean_iou: 0.4294 - val_accuracy: 0.8675 - val_loss: 0.9524 - val_mean_iou: 0.4338 - learning_rate: 9.9726e-05\nEpoch 3/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 421ms/step - accuracy: 0.8957 - loss: 0.3481 - mean_iou: 0.4510 - val_accuracy: 0.8675 - val_loss: 0.9836 - val_mean_iou: 0.4338 - learning_rate: 9.8907e-05\nEpoch 4/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 418ms/step - accuracy: 0.9100 - loss: 0.3160 - mean_iou: 0.5284 - val_accuracy: 0.8675 - val_loss: 0.9898 - val_mean_iou: 0.4338 - learning_rate: 9.7553e-05\nEpoch 5/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 409ms/step - accuracy: 0.9176 - loss: 0.3081 - mean_iou: 0.5958 - val_accuracy: 0.8675 - val_loss: 0.9912 - val_mean_iou: 0.4338 - learning_rate: 9.5677e-05\nEpoch 6/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 435ms/step - accuracy: 0.9290 - loss: 0.2897 - mean_iou: 0.6687 - val_accuracy: 0.8753 - val_loss: 0.8921 - val_mean_iou: 0.4514 - learning_rate: 9.3301e-05\nEpoch 7/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 434ms/step - accuracy: 0.9276 - loss: 0.2958 - mean_iou: 0.6943 - val_accuracy: 0.8764 - val_loss: 0.9027 - val_mean_iou: 0.4572 - learning_rate: 9.0451e-05\nEpoch 8/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 436ms/step - accuracy: 0.9342 - loss: 0.2932 - mean_iou: 0.7146 - val_accuracy: 0.8759 - val_loss: 0.9050 - val_mean_iou: 0.4590 - learning_rate: 8.7157e-05\nEpoch 9/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 405ms/step - accuracy: 0.9397 - loss: 0.2624 - mean_iou: 0.7384 - val_accuracy: 0.8719 - val_loss: 0.9579 - val_mean_iou: 0.4439 - learning_rate: 8.3457e-05\nEpoch 10/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 437ms/step - accuracy: 0.9383 - loss: 0.2828 - mean_iou: 0.7491 - val_accuracy: 0.8796 - val_loss: 0.8750 - val_mean_iou: 0.4881 - learning_rate: 7.9389e-05\nEpoch 11/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 435ms/step - accuracy: 0.9436 - loss: 0.2667 - mean_iou: 0.7682 - val_accuracy: 0.8814 - val_loss: 0.8534 - val_mean_iou: 0.4883 - learning_rate: 7.5000e-05\nEpoch 12/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 435ms/step - accuracy: 0.9513 - loss: 0.2436 - mean_iou: 0.7938 - val_accuracy: 0.8994 - val_loss: 0.7070 - val_mean_iou: 0.5762 - learning_rate: 7.0337e-05\nEpoch 13/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 434ms/step - accuracy: 0.9474 - loss: 0.2894 - mean_iou: 0.7817 - val_accuracy: 0.9013 - val_loss: 0.6398 - val_mean_iou: 0.5871 - learning_rate: 6.5451e-05\nEpoch 14/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 411ms/step - accuracy: 0.9442 - loss: 0.2343 - mean_iou: 0.7789 - val_accuracy: 0.8693 - val_loss: 0.9562 - val_mean_iou: 0.4390 - learning_rate: 6.0396e-05\nEpoch 15/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 437ms/step - accuracy: 0.9495 - loss: 0.2546 - mean_iou: 0.7943 - val_accuracy: 0.8931 - val_loss: 0.5941 - val_mean_iou: 0.6450 - learning_rate: 5.5226e-05\nEpoch 16/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 436ms/step - accuracy: 0.9563 - loss: 0.2281 - mean_iou: 0.8199 - val_accuracy: 0.9358 - val_loss: 0.3925 - val_mean_iou: 0.7666 - learning_rate: 5.0000e-05\nEpoch 17/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 409ms/step - accuracy: 0.9563 - loss: 0.2261 - mean_iou: 0.8216 - val_accuracy: 0.9267 - val_loss: 0.4566 - val_mean_iou: 0.7261 - learning_rate: 4.4774e-05\nEpoch 18/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 411ms/step - accuracy: 0.9569 - loss: 0.2449 - mean_iou: 0.8220 - val_accuracy: 0.8961 - val_loss: 0.7446 - val_mean_iou: 0.5356 - learning_rate: 3.9604e-05\nEpoch 19/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9538 - loss: 0.2254 - mean_iou: 0.8197 - val_accuracy: 0.8543 - val_loss: 0.9829 - val_mean_iou: 0.4346 - learning_rate: 3.4549e-05\nEpoch 20/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 411ms/step - accuracy: 0.9598 - loss: 0.2233 - mean_iou: 0.8386 - val_accuracy: 0.8587 - val_loss: 0.9798 - val_mean_iou: 0.4364 - learning_rate: 2.9663e-05\nEpoch 21/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 437ms/step - accuracy: 0.9589 - loss: 0.2131 - mean_iou: 0.8322 - val_accuracy: 0.9328 - val_loss: 0.3471 - val_mean_iou: 0.7863 - learning_rate: 2.5000e-05\nEpoch 22/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 410ms/step - accuracy: 0.9591 - loss: 0.2138 - mean_iou: 0.8383 - val_accuracy: 0.8862 - val_loss: 0.8114 - val_mean_iou: 0.5003 - learning_rate: 2.0611e-05\nEpoch 23/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 409ms/step - accuracy: 0.9612 - loss: 0.1942 - mean_iou: 0.8409 - val_accuracy: 0.8574 - val_loss: 0.9481 - val_mean_iou: 0.4417 - learning_rate: 1.6543e-05\nEpoch 24/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 409ms/step - accuracy: 0.9582 - loss: 0.2293 - mean_iou: 0.8322 - val_accuracy: 0.8665 - val_loss: 0.9630 - val_mean_iou: 0.4389 - learning_rate: 1.2843e-05\nEpoch 25/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.9616 - loss: 0.2142 - mean_iou: 0.8382 - val_accuracy: 0.8733 - val_loss: 0.9333 - val_mean_iou: 0.4520 - learning_rate: 9.5492e-06\nEpoch 26/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 432ms/step - accuracy: 0.9588 - loss: 0.2086 - mean_iou: 0.8333 - val_accuracy: 0.9422 - val_loss: 0.3522 - val_mean_iou: 0.8024 - learning_rate: 6.6987e-06\nEpoch 27/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 433ms/step - accuracy: 0.9649 - loss: 0.1938 - mean_iou: 0.8504 - val_accuracy: 0.9453 - val_loss: 0.3257 - val_mean_iou: 0.8135 - learning_rate: 4.3227e-06\nEpoch 28/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 409ms/step - accuracy: 0.9641 - loss: 0.1936 - mean_iou: 0.8473 - val_accuracy: 0.9449 - val_loss: 0.3296 - val_mean_iou: 0.8118 - learning_rate: 2.4472e-06\nEpoch 29/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 433ms/step - accuracy: 0.9642 - loss: 0.2022 - mean_iou: 0.8403 - val_accuracy: 0.9470 - val_loss: 0.3227 - val_mean_iou: 0.8183 - learning_rate: 1.0926e-06\nEpoch 30/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 411ms/step - accuracy: 0.9583 - loss: 0.2116 - mean_iou: 0.8280 - val_accuracy: 0.9464 - val_loss: 0.3217 - val_mean_iou: 0.8183 - learning_rate: 2.7391e-07\nEpoch 31/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 409ms/step - accuracy: 0.9576 - loss: 0.2099 - mean_iou: 0.8333 - val_accuracy: 0.8086 - val_loss: 0.9039 - val_mean_iou: 0.4411 - learning_rate: 1.0000e-04\nEpoch 32/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 411ms/step - accuracy: 0.9470 - loss: 0.2376 - mean_iou: 0.7911 - val_accuracy: 0.9039 - val_loss: 0.4024 - val_mean_iou: 0.7351 - learning_rate: 9.9726e-05\nEpoch 33/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9582 - loss: 0.1947 - mean_iou: 0.8398 - val_accuracy: 0.9253 - val_loss: 0.4474 - val_mean_iou: 0.7255 - learning_rate: 9.8907e-05\nEpoch 34/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9589 - loss: 0.1917 - mean_iou: 0.8290 - val_accuracy: 0.9162 - val_loss: 0.4838 - val_mean_iou: 0.6912 - learning_rate: 9.7553e-05\nEpoch 35/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.9584 - loss: 0.1888 - mean_iou: 0.8461 - val_accuracy: 0.9085 - val_loss: 0.5840 - val_mean_iou: 0.6513 - learning_rate: 9.5677e-05\nEpoch 36/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9568 - loss: 0.2083 - mean_iou: 0.8353 - val_accuracy: 0.8689 - val_loss: 0.9063 - val_mean_iou: 0.4606 - learning_rate: 9.3301e-05\nEpoch 37/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9538 - loss: 0.1903 - mean_iou: 0.8308 - val_accuracy: 0.7078 - val_loss: 0.6700 - val_mean_iou: 0.5000 - learning_rate: 9.0451e-05\nEpoch 38/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 409ms/step - accuracy: 0.9623 - loss: 0.1754 - mean_iou: 0.8561 - val_accuracy: 0.8966 - val_loss: 0.6192 - val_mean_iou: 0.6176 - learning_rate: 8.7157e-05\nEpoch 39/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 405ms/step - accuracy: 0.9583 - loss: 0.1904 - mean_iou: 0.8497 - val_accuracy: 0.9165 - val_loss: 0.5231 - val_mean_iou: 0.6877 - learning_rate: 8.3457e-05\nEpoch 40/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 410ms/step - accuracy: 0.9534 - loss: 0.2019 - mean_iou: 0.8326 - val_accuracy: 0.9201 - val_loss: 0.4969 - val_mean_iou: 0.6897 - learning_rate: 7.9389e-05\nEpoch 41/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 409ms/step - accuracy: 0.9625 - loss: 0.1680 - mean_iou: 0.8560 - val_accuracy: 0.9204 - val_loss: 0.5061 - val_mean_iou: 0.6890 - learning_rate: 7.5000e-05\nEpoch 42/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 409ms/step - accuracy: 0.9583 - loss: 0.1782 - mean_iou: 0.8495 - val_accuracy: 0.9074 - val_loss: 0.6866 - val_mean_iou: 0.5928 - learning_rate: 7.0337e-05\nEpoch 43/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.9580 - loss: 0.1786 - mean_iou: 0.8500 - val_accuracy: 0.7929 - val_loss: 0.7326 - val_mean_iou: 0.5179 - learning_rate: 6.5451e-05\nEpoch 44/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 406ms/step - accuracy: 0.9585 - loss: 0.1664 - mean_iou: 0.8575 - val_accuracy: 0.9401 - val_loss: 0.4016 - val_mean_iou: 0.7804 - learning_rate: 6.0396e-05\nEpoch 45/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 410ms/step - accuracy: 0.9644 - loss: 0.1603 - mean_iou: 0.8691 - val_accuracy: 0.6620 - val_loss: 0.8423 - val_mean_iou: 0.3836 - learning_rate: 5.5226e-05\nEpoch 46/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 409ms/step - accuracy: 0.9633 - loss: 0.1563 - mean_iou: 0.8626 - val_accuracy: 0.8738 - val_loss: 0.7791 - val_mean_iou: 0.5141 - learning_rate: 5.0000e-05\nEpoch 47/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 409ms/step - accuracy: 0.9655 - loss: 0.1555 - mean_iou: 0.8748 - val_accuracy: 0.8153 - val_loss: 0.7118 - val_mean_iou: 0.5308 - learning_rate: 4.4774e-05\nEpoch 48/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 409ms/step - accuracy: 0.9667 - loss: 0.1438 - mean_iou: 0.8788 - val_accuracy: 0.9320 - val_loss: 0.4155 - val_mean_iou: 0.7587 - learning_rate: 3.9604e-05\nEpoch 49/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9659 - loss: 0.1515 - mean_iou: 0.8668 - val_accuracy: 0.8528 - val_loss: 0.7909 - val_mean_iou: 0.5162 - learning_rate: 3.4549e-05\nEpoch 50/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 409ms/step - accuracy: 0.9668 - loss: 0.1415 - mean_iou: 0.8787 - val_accuracy: 0.8654 - val_loss: 0.7180 - val_mean_iou: 0.5337 - learning_rate: 2.9663e-05\nEpoch 51/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 434ms/step - accuracy: 0.9667 - loss: 0.1498 - mean_iou: 0.8795 - val_accuracy: 0.9499 - val_loss: 0.3313 - val_mean_iou: 0.8250 - learning_rate: 2.5000e-05\nEpoch 52/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 434ms/step - accuracy: 0.9673 - loss: 0.1484 - mean_iou: 0.8777 - val_accuracy: 0.9523 - val_loss: 0.3259 - val_mean_iou: 0.8258 - learning_rate: 2.0611e-05\nEpoch 53/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.9708 - loss: 0.1486 - mean_iou: 0.8890 - val_accuracy: 0.9386 - val_loss: 0.3622 - val_mean_iou: 0.7979 - learning_rate: 1.6543e-05\nEpoch 54/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 410ms/step - accuracy: 0.9728 - loss: 0.1346 - mean_iou: 0.8982 - val_accuracy: 0.9363 - val_loss: 0.3931 - val_mean_iou: 0.7995 - learning_rate: 1.2843e-05\nEpoch 55/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 767ms/step - accuracy: 0.9719 - loss: 0.1395 - mean_iou: 0.8935 - val_accuracy: 0.9396 - val_loss: 0.3702 - val_mean_iou: 0.8051 - learning_rate: 9.5492e-06\nEpoch 56/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 433ms/step - accuracy: 0.9704 - loss: 0.1397 - mean_iou: 0.8926 - val_accuracy: 0.9555 - val_loss: 0.3102 - val_mean_iou: 0.8374 - learning_rate: 6.6987e-06\nEpoch 57/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 436ms/step - accuracy: 0.9732 - loss: 0.1223 - mean_iou: 0.9030 - val_accuracy: 0.9564 - val_loss: 0.3059 - val_mean_iou: 0.8418 - learning_rate: 4.3227e-06\nEpoch 58/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 436ms/step - accuracy: 0.9720 - loss: 0.1489 - mean_iou: 0.8904 - val_accuracy: 0.9569 - val_loss: 0.2942 - val_mean_iou: 0.8470 - learning_rate: 2.4472e-06\nEpoch 59/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 433ms/step - accuracy: 0.9699 - loss: 0.1423 - mean_iou: 0.8877 - val_accuracy: 0.9575 - val_loss: 0.2935 - val_mean_iou: 0.8480 - learning_rate: 1.0926e-06\nEpoch 60/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9680 - loss: 0.1417 - mean_iou: 0.8817 - val_accuracy: 0.9572 - val_loss: 0.2947 - val_mean_iou: 0.8471 - learning_rate: 2.7391e-07\nEpoch 61/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 412ms/step - accuracy: 0.9669 - loss: 0.1607 - mean_iou: 0.8799 - val_accuracy: 0.8804 - val_loss: 0.6436 - val_mean_iou: 0.5887 - learning_rate: 1.0000e-04\nEpoch 62/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 409ms/step - accuracy: 0.9689 - loss: 0.1695 - mean_iou: 0.8749 - val_accuracy: 0.8440 - val_loss: 0.9687 - val_mean_iou: 0.4414 - learning_rate: 9.9726e-05\nEpoch 63/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9638 - loss: 0.1960 - mean_iou: 0.8638 - val_accuracy: 0.9001 - val_loss: 0.7077 - val_mean_iou: 0.5821 - learning_rate: 9.8907e-05\nEpoch 64/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9730 - loss: 0.1537 - mean_iou: 0.8898 - val_accuracy: 0.8705 - val_loss: 0.9566 - val_mean_iou: 0.4478 - learning_rate: 9.7553e-05\nEpoch 65/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9654 - loss: 0.1630 - mean_iou: 0.8704 - val_accuracy: 0.8672 - val_loss: 0.9910 - val_mean_iou: 0.4356 - learning_rate: 9.5677e-05\nEpoch 66/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9691 - loss: 0.1695 - mean_iou: 0.8801 - val_accuracy: 0.9230 - val_loss: 0.4793 - val_mean_iou: 0.7151 - learning_rate: 9.3301e-05\nEpoch 67/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 409ms/step - accuracy: 0.9683 - loss: 0.1527 - mean_iou: 0.8795 - val_accuracy: 0.8546 - val_loss: 0.9728 - val_mean_iou: 0.4386 - learning_rate: 9.0451e-05\nEpoch 68/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 406ms/step - accuracy: 0.9686 - loss: 0.1849 - mean_iou: 0.8734 - val_accuracy: 0.8257 - val_loss: 0.9757 - val_mean_iou: 0.4239 - learning_rate: 8.7157e-05\nEpoch 69/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 409ms/step - accuracy: 0.9741 - loss: 0.1629 - mean_iou: 0.8873 - val_accuracy: 0.8427 - val_loss: 0.9720 - val_mean_iou: 0.4328 - learning_rate: 8.3457e-05\nEpoch 70/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.9753 - loss: 0.1466 - mean_iou: 0.8977 - val_accuracy: 0.8698 - val_loss: 0.9740 - val_mean_iou: 0.4430 - learning_rate: 7.9389e-05\nEpoch 71/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.9728 - loss: 0.1512 - mean_iou: 0.8908 - val_accuracy: 0.3911 - val_loss: 0.7771 - val_mean_iou: 0.2636 - learning_rate: 7.5000e-05\nEpoch 72/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 411ms/step - accuracy: 0.9726 - loss: 0.1467 - mean_iou: 0.8921 - val_accuracy: 0.8157 - val_loss: 0.6874 - val_mean_iou: 0.5405 - learning_rate: 7.0337e-05\nEpoch 73/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 411ms/step - accuracy: 0.9720 - loss: 0.1530 - mean_iou: 0.8879 - val_accuracy: 0.8774 - val_loss: 0.8089 - val_mean_iou: 0.4980 - learning_rate: 6.5451e-05\nEpoch 74/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.9757 - loss: 0.1419 - mean_iou: 0.9002 - val_accuracy: 0.5429 - val_loss: 0.8569 - val_mean_iou: 0.3247 - learning_rate: 6.0396e-05\nEpoch 75/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 409ms/step - accuracy: 0.9746 - loss: 0.1401 - mean_iou: 0.8963 - val_accuracy: 0.9462 - val_loss: 0.3629 - val_mean_iou: 0.8047 - learning_rate: 5.5226e-05\nEpoch 76/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 409ms/step - accuracy: 0.9757 - loss: 0.1337 - mean_iou: 0.9045 - val_accuracy: 0.9393 - val_loss: 0.3953 - val_mean_iou: 0.7797 - learning_rate: 5.0000e-05\nEpoch 77/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9768 - loss: 0.1270 - mean_iou: 0.9076 - val_accuracy: 0.9289 - val_loss: 0.4477 - val_mean_iou: 0.7511 - learning_rate: 4.4774e-05\nEpoch 78/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9742 - loss: 0.1439 - mean_iou: 0.8944 - val_accuracy: 0.7993 - val_loss: 0.5416 - val_mean_iou: 0.5842 - learning_rate: 3.9604e-05\nEpoch 79/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 406ms/step - accuracy: 0.9775 - loss: 0.1219 - mean_iou: 0.9115 - val_accuracy: 0.9464 - val_loss: 0.3338 - val_mean_iou: 0.8242 - learning_rate: 3.4549e-05\nEpoch 80/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.9774 - loss: 0.1249 - mean_iou: 0.9086 - val_accuracy: 0.9425 - val_loss: 0.3348 - val_mean_iou: 0.8043 - learning_rate: 2.9663e-05\nEpoch 81/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.9758 - loss: 0.1277 - mean_iou: 0.9072 - val_accuracy: 0.7583 - val_loss: 0.5925 - val_mean_iou: 0.5551 - learning_rate: 2.5000e-05\nEpoch 82/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 410ms/step - accuracy: 0.9799 - loss: 0.1178 - mean_iou: 0.9135 - val_accuracy: 0.9583 - val_loss: 0.3118 - val_mean_iou: 0.8424 - learning_rate: 2.0611e-05\nEpoch 83/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9768 - loss: 0.1245 - mean_iou: 0.9067 - val_accuracy: 0.9518 - val_loss: 0.3231 - val_mean_iou: 0.8283 - learning_rate: 1.6543e-05\nEpoch 84/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 406ms/step - accuracy: 0.9784 - loss: 0.1252 - mean_iou: 0.9100 - val_accuracy: 0.9519 - val_loss: 0.3215 - val_mean_iou: 0.8297 - learning_rate: 1.2843e-05\nEpoch 85/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 433ms/step - accuracy: 0.9759 - loss: 0.1214 - mean_iou: 0.9057 - val_accuracy: 0.9615 - val_loss: 0.2912 - val_mean_iou: 0.8569 - learning_rate: 9.5492e-06\nEpoch 86/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 409ms/step - accuracy: 0.9790 - loss: 0.1107 - mean_iou: 0.9180 - val_accuracy: 0.9597 - val_loss: 0.2962 - val_mean_iou: 0.8509 - learning_rate: 6.6987e-06\nEpoch 87/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 436ms/step - accuracy: 0.9772 - loss: 0.1200 - mean_iou: 0.9105 - val_accuracy: 0.9621 - val_loss: 0.2892 - val_mean_iou: 0.8599 - learning_rate: 4.3227e-06\nEpoch 88/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.9781 - loss: 0.1144 - mean_iou: 0.9143 - val_accuracy: 0.9612 - val_loss: 0.2935 - val_mean_iou: 0.8574 - learning_rate: 2.4472e-06\nEpoch 89/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 409ms/step - accuracy: 0.9796 - loss: 0.1105 - mean_iou: 0.9167 - val_accuracy: 0.9609 - val_loss: 0.2922 - val_mean_iou: 0.8569 - learning_rate: 1.0926e-06\nEpoch 90/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.9770 - loss: 0.1189 - mean_iou: 0.9115 - val_accuracy: 0.9614 - val_loss: 0.2913 - val_mean_iou: 0.8582 - learning_rate: 2.7391e-07\nEpoch 91/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.9780 - loss: 0.1134 - mean_iou: 0.9160 - val_accuracy: 0.2477 - val_loss: 0.7747 - val_mean_iou: 0.1507 - learning_rate: 1.0000e-04\nEpoch 92/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9758 - loss: 0.1187 - mean_iou: 0.9106 - val_accuracy: 0.5369 - val_loss: 0.8285 - val_mean_iou: 0.3234 - learning_rate: 9.9726e-05\nEpoch 93/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 409ms/step - accuracy: 0.9744 - loss: 0.1282 - mean_iou: 0.9064 - val_accuracy: 0.8611 - val_loss: 0.7998 - val_mean_iou: 0.5044 - learning_rate: 9.8907e-05\nEpoch 94/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 405ms/step - accuracy: 0.9733 - loss: 0.1443 - mean_iou: 0.8937 - val_accuracy: 0.6763 - val_loss: 0.7695 - val_mean_iou: 0.4192 - learning_rate: 9.7553e-05\nEpoch 95/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 406ms/step - accuracy: 0.9705 - loss: 0.1341 - mean_iou: 0.8933 - val_accuracy: 0.8601 - val_loss: 0.9888 - val_mean_iou: 0.4349 - learning_rate: 9.5677e-05\nEpoch 96/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9707 - loss: 0.1330 - mean_iou: 0.8952 - val_accuracy: 0.8701 - val_loss: 0.6087 - val_mean_iou: 0.6034 - learning_rate: 9.3301e-05\nEpoch 97/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.9656 - loss: 0.1414 - mean_iou: 0.8830 - val_accuracy: 0.9475 - val_loss: 0.3776 - val_mean_iou: 0.7947 - learning_rate: 9.0451e-05\nEpoch 98/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 410ms/step - accuracy: 0.9735 - loss: 0.1225 - mean_iou: 0.9054 - val_accuracy: 0.9528 - val_loss: 0.3445 - val_mean_iou: 0.8182 - learning_rate: 8.7157e-05\nEpoch 99/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9739 - loss: 0.1196 - mean_iou: 0.9079 - val_accuracy: 0.6618 - val_loss: 0.7876 - val_mean_iou: 0.4035 - learning_rate: 8.3457e-05\nEpoch 100/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9724 - loss: 0.1238 - mean_iou: 0.9033 - val_accuracy: 0.8240 - val_loss: 0.6721 - val_mean_iou: 0.5611 - learning_rate: 7.9389e-05\n Fold 2\nEpoch 1/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 653ms/step - accuracy: 0.6948 - loss: 0.6237 - mean_iou: 0.5334 - val_accuracy: 0.8400 - val_loss: 0.8713 - val_mean_iou: 0.4296 - learning_rate: 1.0000e-04\nEpoch 2/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 405ms/step - accuracy: 0.8765 - loss: 0.4344 - mean_iou: 0.4459 - val_accuracy: 0.8450 - val_loss: 0.9395 - val_mean_iou: 0.4295 - learning_rate: 9.9726e-05\nEpoch 3/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 447ms/step - accuracy: 0.9006 - loss: 0.3590 - mean_iou: 0.4656 - val_accuracy: 0.8624 - val_loss: 0.9732 - val_mean_iou: 0.4316 - learning_rate: 9.8907e-05\nEpoch 4/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 439ms/step - accuracy: 0.9158 - loss: 0.3402 - mean_iou: 0.5286 - val_accuracy: 0.8634 - val_loss: 0.9820 - val_mean_iou: 0.4320 - learning_rate: 9.7553e-05\nEpoch 5/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 435ms/step - accuracy: 0.9197 - loss: 0.3230 - mean_iou: 0.5591 - val_accuracy: 0.8650 - val_loss: 0.9660 - val_mean_iou: 0.4352 - learning_rate: 9.5677e-05\nEpoch 6/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 432ms/step - accuracy: 0.9310 - loss: 0.2976 - mean_iou: 0.6160 - val_accuracy: 0.8647 - val_loss: 0.9765 - val_mean_iou: 0.4356 - learning_rate: 9.3301e-05\nEpoch 7/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 431ms/step - accuracy: 0.9282 - loss: 0.3406 - mean_iou: 0.6552 - val_accuracy: 0.8729 - val_loss: 0.8994 - val_mean_iou: 0.4681 - learning_rate: 9.0451e-05\nEpoch 8/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 434ms/step - accuracy: 0.9301 - loss: 0.3035 - mean_iou: 0.6758 - val_accuracy: 0.8972 - val_loss: 0.6791 - val_mean_iou: 0.5633 - learning_rate: 8.7157e-05\nEpoch 9/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 406ms/step - accuracy: 0.9379 - loss: 0.3023 - mean_iou: 0.7240 - val_accuracy: 0.8927 - val_loss: 0.7174 - val_mean_iou: 0.5474 - learning_rate: 8.3457e-05\nEpoch 10/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 433ms/step - accuracy: 0.9431 - loss: 0.2730 - mean_iou: 0.7356 - val_accuracy: 0.9212 - val_loss: 0.5396 - val_mean_iou: 0.6668 - learning_rate: 7.9389e-05\nEpoch 11/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 431ms/step - accuracy: 0.9442 - loss: 0.2846 - mean_iou: 0.7576 - val_accuracy: 0.9178 - val_loss: 0.5272 - val_mean_iou: 0.6692 - learning_rate: 7.5000e-05\nEpoch 12/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 406ms/step - accuracy: 0.9486 - loss: 0.2853 - mean_iou: 0.7771 - val_accuracy: 0.9093 - val_loss: 0.6308 - val_mean_iou: 0.6265 - learning_rate: 7.0337e-05\nEpoch 13/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 404ms/step - accuracy: 0.9494 - loss: 0.2800 - mean_iou: 0.7840 - val_accuracy: 0.9119 - val_loss: 0.5937 - val_mean_iou: 0.6302 - learning_rate: 6.5451e-05\nEpoch 14/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 435ms/step - accuracy: 0.9499 - loss: 0.2479 - mean_iou: 0.7897 - val_accuracy: 0.9248 - val_loss: 0.4568 - val_mean_iou: 0.7194 - learning_rate: 6.0396e-05\nEpoch 15/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 406ms/step - accuracy: 0.9517 - loss: 0.2626 - mean_iou: 0.7802 - val_accuracy: 0.8636 - val_loss: 0.9841 - val_mean_iou: 0.4323 - learning_rate: 5.5226e-05\nEpoch 16/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9525 - loss: 0.2671 - mean_iou: 0.7899 - val_accuracy: 0.8630 - val_loss: 0.9750 - val_mean_iou: 0.4349 - learning_rate: 5.0000e-05\nEpoch 17/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.9528 - loss: 0.2553 - mean_iou: 0.7978 - val_accuracy: 0.8633 - val_loss: 0.9878 - val_mean_iou: 0.4321 - learning_rate: 4.4774e-05\nEpoch 18/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 432ms/step - accuracy: 0.9519 - loss: 0.2519 - mean_iou: 0.7944 - val_accuracy: 0.9326 - val_loss: 0.4153 - val_mean_iou: 0.7638 - learning_rate: 3.9604e-05\nEpoch 19/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.9517 - loss: 0.2710 - mean_iou: 0.7925 - val_accuracy: 0.8989 - val_loss: 0.5440 - val_mean_iou: 0.6585 - learning_rate: 3.4549e-05\nEpoch 20/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 405ms/step - accuracy: 0.9636 - loss: 0.2229 - mean_iou: 0.8435 - val_accuracy: 0.9200 - val_loss: 0.4014 - val_mean_iou: 0.7598 - learning_rate: 2.9663e-05\nEpoch 21/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 406ms/step - accuracy: 0.9548 - loss: 0.2295 - mean_iou: 0.8197 - val_accuracy: 0.8669 - val_loss: 0.9516 - val_mean_iou: 0.4448 - learning_rate: 2.5000e-05\nEpoch 22/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 432ms/step - accuracy: 0.9618 - loss: 0.2196 - mean_iou: 0.8172 - val_accuracy: 0.9389 - val_loss: 0.4292 - val_mean_iou: 0.7738 - learning_rate: 2.0611e-05\nEpoch 23/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 432ms/step - accuracy: 0.9624 - loss: 0.2104 - mean_iou: 0.8386 - val_accuracy: 0.9438 - val_loss: 0.4003 - val_mean_iou: 0.7889 - learning_rate: 1.6543e-05\nEpoch 24/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9649 - loss: 0.2055 - mean_iou: 0.8489 - val_accuracy: 0.9360 - val_loss: 0.4250 - val_mean_iou: 0.7644 - learning_rate: 1.2843e-05\nEpoch 25/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 433ms/step - accuracy: 0.9583 - loss: 0.2344 - mean_iou: 0.7983 - val_accuracy: 0.9518 - val_loss: 0.3325 - val_mean_iou: 0.8246 - learning_rate: 9.5492e-06\nEpoch 26/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 403ms/step - accuracy: 0.9650 - loss: 0.2062 - mean_iou: 0.8421 - val_accuracy: 0.9490 - val_loss: 0.3555 - val_mean_iou: 0.8135 - learning_rate: 6.6987e-06\nEpoch 27/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 432ms/step - accuracy: 0.9605 - loss: 0.2129 - mean_iou: 0.8319 - val_accuracy: 0.9515 - val_loss: 0.3268 - val_mean_iou: 0.8298 - learning_rate: 4.3227e-06\nEpoch 28/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 431ms/step - accuracy: 0.9636 - loss: 0.1990 - mean_iou: 0.8384 - val_accuracy: 0.9527 - val_loss: 0.3206 - val_mean_iou: 0.8352 - learning_rate: 2.4472e-06\nEpoch 29/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9587 - loss: 0.2365 - mean_iou: 0.8147 - val_accuracy: 0.9523 - val_loss: 0.3213 - val_mean_iou: 0.8342 - learning_rate: 1.0926e-06\nEpoch 30/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 434ms/step - accuracy: 0.9604 - loss: 0.2163 - mean_iou: 0.8196 - val_accuracy: 0.9525 - val_loss: 0.3194 - val_mean_iou: 0.8360 - learning_rate: 2.7391e-07\nEpoch 31/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.9594 - loss: 0.2048 - mean_iou: 0.8212 - val_accuracy: 0.8564 - val_loss: 0.9911 - val_mean_iou: 0.4306 - learning_rate: 1.0000e-04\nEpoch 32/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 406ms/step - accuracy: 0.9507 - loss: 0.2438 - mean_iou: 0.7936 - val_accuracy: 0.8533 - val_loss: 0.9770 - val_mean_iou: 0.4363 - learning_rate: 9.9726e-05\nEpoch 33/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 404ms/step - accuracy: 0.9562 - loss: 0.2033 - mean_iou: 0.8273 - val_accuracy: 0.8631 - val_loss: 0.9941 - val_mean_iou: 0.4316 - learning_rate: 9.8907e-05\nEpoch 34/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 403ms/step - accuracy: 0.9505 - loss: 0.2355 - mean_iou: 0.8024 - val_accuracy: 0.7669 - val_loss: 0.8829 - val_mean_iou: 0.4442 - learning_rate: 9.7553e-05\nEpoch 35/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 400ms/step - accuracy: 0.9598 - loss: 0.1920 - mean_iou: 0.8305 - val_accuracy: 0.8275 - val_loss: 0.5903 - val_mean_iou: 0.6259 - learning_rate: 9.5677e-05\nEpoch 36/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9580 - loss: 0.1945 - mean_iou: 0.8344 - val_accuracy: 0.8632 - val_loss: 0.9952 - val_mean_iou: 0.4317 - learning_rate: 9.3301e-05\nEpoch 37/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 405ms/step - accuracy: 0.9578 - loss: 0.1982 - mean_iou: 0.8375 - val_accuracy: 0.8679 - val_loss: 0.9456 - val_mean_iou: 0.4501 - learning_rate: 9.0451e-05\nEpoch 38/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 404ms/step - accuracy: 0.9652 - loss: 0.1718 - mean_iou: 0.8644 - val_accuracy: 0.8632 - val_loss: 0.9965 - val_mean_iou: 0.4316 - learning_rate: 8.7157e-05\nEpoch 39/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 406ms/step - accuracy: 0.9623 - loss: 0.1764 - mean_iou: 0.8556 - val_accuracy: 0.8614 - val_loss: 0.9953 - val_mean_iou: 0.4316 - learning_rate: 8.3457e-05\nEpoch 40/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 405ms/step - accuracy: 0.9610 - loss: 0.1868 - mean_iou: 0.8502 - val_accuracy: 0.9275 - val_loss: 0.4636 - val_mean_iou: 0.7266 - learning_rate: 7.9389e-05\nEpoch 41/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 405ms/step - accuracy: 0.9649 - loss: 0.1552 - mean_iou: 0.8692 - val_accuracy: 0.9183 - val_loss: 0.5100 - val_mean_iou: 0.7082 - learning_rate: 7.5000e-05\nEpoch 42/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 404ms/step - accuracy: 0.9629 - loss: 0.1729 - mean_iou: 0.8583 - val_accuracy: 0.8629 - val_loss: 0.9487 - val_mean_iou: 0.4478 - learning_rate: 7.0337e-05\nEpoch 43/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 406ms/step - accuracy: 0.9624 - loss: 0.1757 - mean_iou: 0.8523 - val_accuracy: 0.8572 - val_loss: 0.9345 - val_mean_iou: 0.4575 - learning_rate: 6.5451e-05\nEpoch 44/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 403ms/step - accuracy: 0.9659 - loss: 0.1544 - mean_iou: 0.8705 - val_accuracy: 0.8621 - val_loss: 0.9960 - val_mean_iou: 0.4316 - learning_rate: 6.0396e-05\nEpoch 45/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9647 - loss: 0.1726 - mean_iou: 0.8657 - val_accuracy: 0.9213 - val_loss: 0.5315 - val_mean_iou: 0.6856 - learning_rate: 5.5226e-05\nEpoch 46/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 404ms/step - accuracy: 0.9668 - loss: 0.1630 - mean_iou: 0.8715 - val_accuracy: 0.8634 - val_loss: 0.9936 - val_mean_iou: 0.4327 - learning_rate: 5.0000e-05\nEpoch 47/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.9678 - loss: 0.1548 - mean_iou: 0.8711 - val_accuracy: 0.8634 - val_loss: 0.9962 - val_mean_iou: 0.4320 - learning_rate: 4.4774e-05\nEpoch 48/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 406ms/step - accuracy: 0.9626 - loss: 0.1705 - mean_iou: 0.8619 - val_accuracy: 0.8665 - val_loss: 0.9731 - val_mean_iou: 0.4425 - learning_rate: 3.9604e-05\nEpoch 49/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 402ms/step - accuracy: 0.9694 - loss: 0.1508 - mean_iou: 0.8812 - val_accuracy: 0.9333 - val_loss: 0.4684 - val_mean_iou: 0.7426 - learning_rate: 3.4549e-05\nEpoch 50/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 404ms/step - accuracy: 0.9726 - loss: 0.1375 - mean_iou: 0.8952 - val_accuracy: 0.9348 - val_loss: 0.3831 - val_mean_iou: 0.7793 - learning_rate: 2.9663e-05\nEpoch 51/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 406ms/step - accuracy: 0.9701 - loss: 0.1470 - mean_iou: 0.8839 - val_accuracy: 0.9410 - val_loss: 0.3795 - val_mean_iou: 0.7913 - learning_rate: 2.5000e-05\nEpoch 52/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 409ms/step - accuracy: 0.9708 - loss: 0.1433 - mean_iou: 0.8887 - val_accuracy: 0.9514 - val_loss: 0.3409 - val_mean_iou: 0.8225 - learning_rate: 2.0611e-05\nEpoch 53/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 405ms/step - accuracy: 0.9692 - loss: 0.1482 - mean_iou: 0.8785 - val_accuracy: 0.9539 - val_loss: 0.3051 - val_mean_iou: 0.8359 - learning_rate: 1.6543e-05\nEpoch 54/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.9703 - loss: 0.1525 - mean_iou: 0.8848 - val_accuracy: 0.9540 - val_loss: 0.3024 - val_mean_iou: 0.8360 - learning_rate: 1.2843e-05\nEpoch 55/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 431ms/step - accuracy: 0.9697 - loss: 0.1487 - mean_iou: 0.8821 - val_accuracy: 0.9574 - val_loss: 0.3062 - val_mean_iou: 0.8412 - learning_rate: 9.5492e-06\nEpoch 56/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 410ms/step - accuracy: 0.9737 - loss: 0.1392 - mean_iou: 0.8930 - val_accuracy: 0.9549 - val_loss: 0.3102 - val_mean_iou: 0.8350 - learning_rate: 6.6987e-06\nEpoch 57/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 434ms/step - accuracy: 0.9729 - loss: 0.1356 - mean_iou: 0.8928 - val_accuracy: 0.9574 - val_loss: 0.2898 - val_mean_iou: 0.8434 - learning_rate: 4.3227e-06\nEpoch 58/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 433ms/step - accuracy: 0.9750 - loss: 0.1403 - mean_iou: 0.8976 - val_accuracy: 0.9586 - val_loss: 0.2883 - val_mean_iou: 0.8492 - learning_rate: 2.4472e-06\nEpoch 59/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 431ms/step - accuracy: 0.9673 - loss: 0.1650 - mean_iou: 0.8717 - val_accuracy: 0.9588 - val_loss: 0.2869 - val_mean_iou: 0.8501 - learning_rate: 1.0926e-06\nEpoch 60/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 435ms/step - accuracy: 0.9715 - loss: 0.1422 - mean_iou: 0.8894 - val_accuracy: 0.9589 - val_loss: 0.2865 - val_mean_iou: 0.8502 - learning_rate: 2.7391e-07\nEpoch 61/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9701 - loss: 0.1474 - mean_iou: 0.8866 - val_accuracy: 0.8620 - val_loss: 0.9953 - val_mean_iou: 0.4317 - learning_rate: 1.0000e-04\nEpoch 62/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 405ms/step - accuracy: 0.9684 - loss: 0.1506 - mean_iou: 0.8755 - val_accuracy: 0.8918 - val_loss: 0.7561 - val_mean_iou: 0.5434 - learning_rate: 9.9726e-05\nEpoch 63/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 404ms/step - accuracy: 0.9674 - loss: 0.1827 - mean_iou: 0.8693 - val_accuracy: 0.2210 - val_loss: 0.7534 - val_mean_iou: 0.1298 - learning_rate: 9.8907e-05\nEpoch 64/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.9691 - loss: 0.1860 - mean_iou: 0.8662 - val_accuracy: 0.8419 - val_loss: 0.8963 - val_mean_iou: 0.4634 - learning_rate: 9.7553e-05\nEpoch 65/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.9684 - loss: 0.1714 - mean_iou: 0.8718 - val_accuracy: 0.9249 - val_loss: 0.4576 - val_mean_iou: 0.7153 - learning_rate: 9.5677e-05\nEpoch 66/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 409ms/step - accuracy: 0.9741 - loss: 0.1544 - mean_iou: 0.8917 - val_accuracy: 0.1429 - val_loss: 0.7578 - val_mean_iou: 0.3960 - learning_rate: 9.3301e-05\nEpoch 67/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9694 - loss: 0.1549 - mean_iou: 0.8817 - val_accuracy: 0.8229 - val_loss: 0.7288 - val_mean_iou: 0.5382 - learning_rate: 9.0451e-05\nEpoch 68/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 404ms/step - accuracy: 0.9742 - loss: 0.1644 - mean_iou: 0.8830 - val_accuracy: 0.9180 - val_loss: 0.4816 - val_mean_iou: 0.7024 - learning_rate: 8.7157e-05\nEpoch 69/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 406ms/step - accuracy: 0.9739 - loss: 0.1565 - mean_iou: 0.8865 - val_accuracy: 0.8620 - val_loss: 0.9980 - val_mean_iou: 0.4316 - learning_rate: 8.3457e-05\nEpoch 70/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.9706 - loss: 0.1885 - mean_iou: 0.8689 - val_accuracy: 0.9250 - val_loss: 0.4205 - val_mean_iou: 0.7399 - learning_rate: 7.9389e-05\nEpoch 71/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 405ms/step - accuracy: 0.9732 - loss: 0.1437 - mean_iou: 0.8883 - val_accuracy: 0.8337 - val_loss: 0.9670 - val_mean_iou: 0.4349 - learning_rate: 7.5000e-05\nEpoch 72/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.9677 - loss: 0.1693 - mean_iou: 0.8730 - val_accuracy: 0.8904 - val_loss: 0.7076 - val_mean_iou: 0.5596 - learning_rate: 7.0337e-05\nEpoch 73/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 406ms/step - accuracy: 0.9771 - loss: 0.1249 - mean_iou: 0.9052 - val_accuracy: 0.9374 - val_loss: 0.3931 - val_mean_iou: 0.7678 - learning_rate: 6.5451e-05\nEpoch 74/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 410ms/step - accuracy: 0.9743 - loss: 0.1768 - mean_iou: 0.8857 - val_accuracy: 0.8597 - val_loss: 0.9878 - val_mean_iou: 0.4355 - learning_rate: 6.0396e-05\nEpoch 75/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9757 - loss: 0.1478 - mean_iou: 0.8975 - val_accuracy: 0.9152 - val_loss: 0.5410 - val_mean_iou: 0.6622 - learning_rate: 5.5226e-05\nEpoch 76/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 402ms/step - accuracy: 0.9752 - loss: 0.1465 - mean_iou: 0.8961 - val_accuracy: 0.9352 - val_loss: 0.4490 - val_mean_iou: 0.7453 - learning_rate: 5.0000e-05\nEpoch 77/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.9772 - loss: 0.1682 - mean_iou: 0.8963 - val_accuracy: 0.9220 - val_loss: 0.5661 - val_mean_iou: 0.6927 - learning_rate: 4.4774e-05\nEpoch 78/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 405ms/step - accuracy: 0.9780 - loss: 0.1352 - mean_iou: 0.9053 - val_accuracy: 0.9369 - val_loss: 0.4005 - val_mean_iou: 0.7670 - learning_rate: 3.9604e-05\nEpoch 79/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.9774 - loss: 0.1194 - mean_iou: 0.9106 - val_accuracy: 0.8558 - val_loss: 0.9948 - val_mean_iou: 0.4308 - learning_rate: 3.4549e-05\nEpoch 80/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.9766 - loss: 0.1247 - mean_iou: 0.9028 - val_accuracy: 0.8592 - val_loss: 0.9946 - val_mean_iou: 0.4318 - learning_rate: 2.9663e-05\nEpoch 81/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 405ms/step - accuracy: 0.9756 - loss: 0.1497 - mean_iou: 0.8986 - val_accuracy: 0.8633 - val_loss: 0.9991 - val_mean_iou: 0.4317 - learning_rate: 2.5000e-05\nEpoch 82/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 405ms/step - accuracy: 0.9813 - loss: 0.1112 - mean_iou: 0.9232 - val_accuracy: 0.9300 - val_loss: 0.5032 - val_mean_iou: 0.7216 - learning_rate: 2.0611e-05\nEpoch 83/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 405ms/step - accuracy: 0.9819 - loss: 0.1024 - mean_iou: 0.9258 - val_accuracy: 0.9501 - val_loss: 0.3724 - val_mean_iou: 0.8079 - learning_rate: 1.6543e-05\nEpoch 84/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 404ms/step - accuracy: 0.9796 - loss: 0.1152 - mean_iou: 0.9189 - val_accuracy: 0.8677 - val_loss: 0.9467 - val_mean_iou: 0.4502 - learning_rate: 1.2843e-05\nEpoch 85/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.9791 - loss: 0.1130 - mean_iou: 0.9154 - val_accuracy: 0.8793 - val_loss: 0.8226 - val_mean_iou: 0.5049 - learning_rate: 9.5492e-06\nEpoch 86/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 432ms/step - accuracy: 0.9784 - loss: 0.1212 - mean_iou: 0.9153 - val_accuracy: 0.9595 - val_loss: 0.2851 - val_mean_iou: 0.8528 - learning_rate: 6.6987e-06\nEpoch 87/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 404ms/step - accuracy: 0.9749 - loss: 0.1284 - mean_iou: 0.9041 - val_accuracy: 0.9535 - val_loss: 0.3179 - val_mean_iou: 0.8286 - learning_rate: 4.3227e-06\nEpoch 88/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.9774 - loss: 0.1162 - mean_iou: 0.9099 - val_accuracy: 0.9562 - val_loss: 0.3109 - val_mean_iou: 0.8366 - learning_rate: 2.4472e-06\nEpoch 89/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 433ms/step - accuracy: 0.9796 - loss: 0.1075 - mean_iou: 0.9206 - val_accuracy: 0.9602 - val_loss: 0.2799 - val_mean_iou: 0.8538 - learning_rate: 1.0926e-06\nEpoch 90/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 430ms/step - accuracy: 0.9790 - loss: 0.1116 - mean_iou: 0.9165 - val_accuracy: 0.9608 - val_loss: 0.2754 - val_mean_iou: 0.8561 - learning_rate: 2.7391e-07\nEpoch 91/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 405ms/step - accuracy: 0.9743 - loss: 0.1253 - mean_iou: 0.8999 - val_accuracy: 0.9280 - val_loss: 0.4573 - val_mean_iou: 0.7298 - learning_rate: 1.0000e-04\nEpoch 92/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 403ms/step - accuracy: 0.9768 - loss: 0.1215 - mean_iou: 0.9090 - val_accuracy: 0.9100 - val_loss: 0.5894 - val_mean_iou: 0.6412 - learning_rate: 9.9726e-05\nEpoch 93/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 405ms/step - accuracy: 0.9728 - loss: 0.1258 - mean_iou: 0.8994 - val_accuracy: 0.8990 - val_loss: 0.6317 - val_mean_iou: 0.6089 - learning_rate: 9.8907e-05\nEpoch 94/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 402ms/step - accuracy: 0.9708 - loss: 0.1423 - mean_iou: 0.8907 - val_accuracy: 0.7791 - val_loss: 0.8841 - val_mean_iou: 0.4522 - learning_rate: 9.7553e-05\nEpoch 95/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 406ms/step - accuracy: 0.9697 - loss: 0.1458 - mean_iou: 0.8891 - val_accuracy: 0.8631 - val_loss: 0.9991 - val_mean_iou: 0.4316 - learning_rate: 9.5677e-05\nEpoch 96/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 404ms/step - accuracy: 0.9727 - loss: 0.1421 - mean_iou: 0.8933 - val_accuracy: 0.8415 - val_loss: 0.5159 - val_mean_iou: 0.6341 - learning_rate: 9.3301e-05\nEpoch 97/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 405ms/step - accuracy: 0.9669 - loss: 0.1505 - mean_iou: 0.8825 - val_accuracy: 0.8636 - val_loss: 0.9935 - val_mean_iou: 0.4336 - learning_rate: 9.0451e-05\nEpoch 98/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 405ms/step - accuracy: 0.9746 - loss: 0.1197 - mean_iou: 0.9060 - val_accuracy: 0.7558 - val_loss: 0.6958 - val_mean_iou: 0.4948 - learning_rate: 8.7157e-05\nEpoch 99/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 404ms/step - accuracy: 0.9679 - loss: 0.1471 - mean_iou: 0.8849 - val_accuracy: 0.3600 - val_loss: 0.8020 - val_mean_iou: 0.2212 - learning_rate: 8.3457e-05\nEpoch 100/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 403ms/step - accuracy: 0.9711 - loss: 0.1272 - mean_iou: 0.8969 - val_accuracy: 0.8323 - val_loss: 0.7708 - val_mean_iou: 0.5138 - learning_rate: 7.9389e-05\n → EffB2 mean IoU: 0.9161454141139984\n\n=== EffB3 ===\n Fold 1\nDownloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n\u001b[1m43941136/43941136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1750410308.985554     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750410309.180045     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750410309.744325     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750410309.961801     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750410310.382548     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750410310.600358     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750410311.170985     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750410311.433260     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n2025-06-20 09:05:13.260763: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[256,2352,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,2352,24,24]{3,2,1,0}, f32[12,256,24,24]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n2025-06-20 09:05:13.709222: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.448575729s\nTrying algorithm eng0{} for conv (f32[256,2352,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,2352,24,24]{3,2,1,0}, f32[12,256,24,24]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n2025-06-20 09:05:16.388994: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,208,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,208,192,192]{3,2,1,0}, f32[12,32,192,192]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n2025-06-20 09:05:16.409458: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.020588603s\nTrying algorithm eng0{} for conv (f32[32,208,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,208,192,192]{3,2,1,0}, f32[12,32,192,192]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 794ms/step - accuracy: 0.6451 - loss: 0.6432 - mean_iou: 0.4888 - val_accuracy: 0.8627 - val_loss: 0.8367 - val_mean_iou: 0.4338 - learning_rate: 1.0000e-04\nEpoch 2/100\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1750410427.190640     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750410427.384595     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750410427.916582     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750410428.133709     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750410428.528858     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750410428.745841     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750410429.255216     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750410429.516998     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n2025-06-20 09:07:11.244383: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[256,2352,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[9,2352,24,24]{3,2,1,0}, f32[9,256,24,24]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n2025-06-20 09:07:11.336588: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.092321178s\nTrying algorithm eng0{} for conv (f32[256,2352,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[9,2352,24,24]{3,2,1,0}, f32[9,256,24,24]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 476ms/step - accuracy: 0.8571 - loss: 0.4496 - mean_iou: 0.4281 - val_accuracy: 0.8675 - val_loss: 0.9282 - val_mean_iou: 0.4338 - learning_rate: 9.9726e-05\nEpoch 3/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 488ms/step - accuracy: 0.8839 - loss: 0.3916 - mean_iou: 0.4267 - val_accuracy: 0.8675 - val_loss: 0.9686 - val_mean_iou: 0.4338 - learning_rate: 9.8907e-05\nEpoch 4/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 481ms/step - accuracy: 0.8991 - loss: 0.3604 - mean_iou: 0.4278 - val_accuracy: 0.8676 - val_loss: 0.9743 - val_mean_iou: 0.4338 - learning_rate: 9.7553e-05\nEpoch 5/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 473ms/step - accuracy: 0.9072 - loss: 0.3581 - mean_iou: 0.4323 - val_accuracy: 0.8682 - val_loss: 0.9684 - val_mean_iou: 0.4338 - learning_rate: 9.5677e-05\nEpoch 6/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 476ms/step - accuracy: 0.9204 - loss: 0.3391 - mean_iou: 0.4380 - val_accuracy: 0.8685 - val_loss: 0.9592 - val_mean_iou: 0.4338 - learning_rate: 9.3301e-05\nEpoch 7/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 473ms/step - accuracy: 0.9207 - loss: 0.3422 - mean_iou: 0.4422 - val_accuracy: 0.8801 - val_loss: 0.8639 - val_mean_iou: 0.4338 - learning_rate: 9.0451e-05\nEpoch 8/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 477ms/step - accuracy: 0.9225 - loss: 0.3370 - mean_iou: 0.4578 - val_accuracy: 0.8876 - val_loss: 0.8009 - val_mean_iou: 0.4338 - learning_rate: 8.7157e-05\nEpoch 9/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 477ms/step - accuracy: 0.9327 - loss: 0.3073 - mean_iou: 0.4745 - val_accuracy: 0.8812 - val_loss: 0.8617 - val_mean_iou: 0.4338 - learning_rate: 8.3457e-05\nEpoch 10/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 508ms/step - accuracy: 0.9397 - loss: 0.3234 - mean_iou: 0.5297 - val_accuracy: 0.9133 - val_loss: 0.5634 - val_mean_iou: 0.4433 - learning_rate: 7.9389e-05\nEpoch 11/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 478ms/step - accuracy: 0.9399 - loss: 0.3073 - mean_iou: 0.5398 - val_accuracy: 0.9137 - val_loss: 0.5040 - val_mean_iou: 0.4338 - learning_rate: 7.5000e-05\nEpoch 12/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 475ms/step - accuracy: 0.9452 - loss: 0.2874 - mean_iou: 0.5579 - val_accuracy: 0.8979 - val_loss: 0.5515 - val_mean_iou: 0.4341 - learning_rate: 7.0337e-05\nEpoch 13/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 506ms/step - accuracy: 0.9448 - loss: 0.3285 - mean_iou: 0.6036 - val_accuracy: 0.8879 - val_loss: 0.7619 - val_mean_iou: 0.5069 - learning_rate: 6.5451e-05\nEpoch 14/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 473ms/step - accuracy: 0.9409 - loss: 0.2654 - mean_iou: 0.5486 - val_accuracy: 0.8671 - val_loss: 0.9787 - val_mean_iou: 0.4341 - learning_rate: 6.0396e-05\nEpoch 15/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 501ms/step - accuracy: 0.9486 - loss: 0.2858 - mean_iou: 0.6123 - val_accuracy: 0.7826 - val_loss: 0.5993 - val_mean_iou: 0.6173 - learning_rate: 5.5226e-05\nEpoch 16/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 477ms/step - accuracy: 0.9551 - loss: 0.2591 - mean_iou: 0.6503 - val_accuracy: 0.5761 - val_loss: 0.7484 - val_mean_iou: 0.4381 - learning_rate: 5.0000e-05\nEpoch 17/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 475ms/step - accuracy: 0.9561 - loss: 0.2560 - mean_iou: 0.6754 - val_accuracy: 0.1816 - val_loss: 0.7648 - val_mean_iou: 0.3060 - learning_rate: 4.4774e-05\nEpoch 18/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 473ms/step - accuracy: 0.9552 - loss: 0.2787 - mean_iou: 0.6603 - val_accuracy: 0.2468 - val_loss: 0.7751 - val_mean_iou: 0.3101 - learning_rate: 3.9604e-05\nEpoch 19/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 474ms/step - accuracy: 0.9523 - loss: 0.2541 - mean_iou: 0.6472 - val_accuracy: 0.6727 - val_loss: 0.8656 - val_mean_iou: 0.4407 - learning_rate: 3.4549e-05\nEpoch 20/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 503ms/step - accuracy: 0.9606 - loss: 0.2552 - mean_iou: 0.7078 - val_accuracy: 0.9179 - val_loss: 0.4841 - val_mean_iou: 0.6932 - learning_rate: 2.9663e-05\nEpoch 21/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 474ms/step - accuracy: 0.9569 - loss: 0.2435 - mean_iou: 0.6900 - val_accuracy: 0.5611 - val_loss: 0.8511 - val_mean_iou: 0.3754 - learning_rate: 2.5000e-05\nEpoch 22/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 478ms/step - accuracy: 0.9593 - loss: 0.2396 - mean_iou: 0.7292 - val_accuracy: 0.8960 - val_loss: 0.6863 - val_mean_iou: 0.5352 - learning_rate: 2.0611e-05\nEpoch 23/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 501ms/step - accuracy: 0.9587 - loss: 0.2200 - mean_iou: 0.6819 - val_accuracy: 0.9236 - val_loss: 0.4081 - val_mean_iou: 0.7619 - learning_rate: 1.6543e-05\nEpoch 24/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 475ms/step - accuracy: 0.9573 - loss: 0.2550 - mean_iou: 0.6988 - val_accuracy: 0.9307 - val_loss: 0.3829 - val_mean_iou: 0.6527 - learning_rate: 1.2843e-05\nEpoch 25/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 505ms/step - accuracy: 0.9573 - loss: 0.2534 - mean_iou: 0.7011 - val_accuracy: 0.9396 - val_loss: 0.3580 - val_mean_iou: 0.7997 - learning_rate: 9.5492e-06\nEpoch 26/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 476ms/step - accuracy: 0.9558 - loss: 0.2370 - mean_iou: 0.6794 - val_accuracy: 0.8780 - val_loss: 0.8264 - val_mean_iou: 0.4769 - learning_rate: 6.6987e-06\nEpoch 27/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 475ms/step - accuracy: 0.9613 - loss: 0.2336 - mean_iou: 0.7279 - val_accuracy: 0.8902 - val_loss: 0.7207 - val_mean_iou: 0.5128 - learning_rate: 4.3227e-06\nEpoch 28/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 474ms/step - accuracy: 0.9640 - loss: 0.2211 - mean_iou: 0.7221 - val_accuracy: 0.9411 - val_loss: 0.3567 - val_mean_iou: 0.7974 - learning_rate: 2.4472e-06\nEpoch 29/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 472ms/step - accuracy: 0.9617 - loss: 0.2339 - mean_iou: 0.6962 - val_accuracy: 0.9415 - val_loss: 0.3649 - val_mean_iou: 0.7890 - learning_rate: 1.0926e-06\nEpoch 30/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 502ms/step - accuracy: 0.9567 - loss: 0.2388 - mean_iou: 0.6695 - val_accuracy: 0.9426 - val_loss: 0.3517 - val_mean_iou: 0.8015 - learning_rate: 2.7391e-07\nEpoch 31/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 472ms/step - accuracy: 0.9605 - loss: 0.2237 - mean_iou: 0.7092 - val_accuracy: 0.8609 - val_loss: 0.9731 - val_mean_iou: 0.4388 - learning_rate: 1.0000e-04\nEpoch 32/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 474ms/step - accuracy: 0.9460 - loss: 0.2571 - mean_iou: 0.6722 - val_accuracy: 0.7750 - val_loss: 0.9040 - val_mean_iou: 0.4427 - learning_rate: 9.9726e-05\nEpoch 33/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 476ms/step - accuracy: 0.9573 - loss: 0.2197 - mean_iou: 0.7482 - val_accuracy: 0.7749 - val_loss: 0.9237 - val_mean_iou: 0.4297 - learning_rate: 9.8907e-05\nEpoch 34/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 476ms/step - accuracy: 0.9516 - loss: 0.2282 - mean_iou: 0.6752 - val_accuracy: 0.8596 - val_loss: 0.9960 - val_mean_iou: 0.4328 - learning_rate: 9.7553e-05\nEpoch 35/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 475ms/step - accuracy: 0.9559 - loss: 0.2109 - mean_iou: 0.7527 - val_accuracy: 0.8488 - val_loss: 0.7522 - val_mean_iou: 0.5346 - learning_rate: 9.5677e-05\nEpoch 36/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 476ms/step - accuracy: 0.9575 - loss: 0.2225 - mean_iou: 0.7685 - val_accuracy: 0.8612 - val_loss: 0.5095 - val_mean_iou: 0.6931 - learning_rate: 9.3301e-05\nEpoch 37/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 474ms/step - accuracy: 0.9563 - loss: 0.1925 - mean_iou: 0.7365 - val_accuracy: 0.8750 - val_loss: 0.6182 - val_mean_iou: 0.6018 - learning_rate: 9.0451e-05\nEpoch 38/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 475ms/step - accuracy: 0.9625 - loss: 0.1869 - mean_iou: 0.7865 - val_accuracy: 0.7546 - val_loss: 0.9298 - val_mean_iou: 0.4202 - learning_rate: 8.7157e-05\nEpoch 39/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 475ms/step - accuracy: 0.9583 - loss: 0.1964 - mean_iou: 0.7930 - val_accuracy: 0.6859 - val_loss: 0.6507 - val_mean_iou: 0.5420 - learning_rate: 8.3457e-05\nEpoch 40/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 474ms/step - accuracy: 0.9571 - loss: 0.1979 - mean_iou: 0.7411 - val_accuracy: 0.8581 - val_loss: 0.8081 - val_mean_iou: 0.5125 - learning_rate: 7.9389e-05\nEpoch 41/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 475ms/step - accuracy: 0.9616 - loss: 0.1803 - mean_iou: 0.7646 - val_accuracy: 0.2471 - val_loss: 0.7736 - val_mean_iou: 0.2185 - learning_rate: 7.5000e-05\nEpoch 42/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 473ms/step - accuracy: 0.9574 - loss: 0.1876 - mean_iou: 0.7661 - val_accuracy: 0.9192 - val_loss: 0.4836 - val_mean_iou: 0.7145 - learning_rate: 7.0337e-05\nEpoch 43/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 472ms/step - accuracy: 0.9568 - loss: 0.1885 - mean_iou: 0.7783 - val_accuracy: 0.9412 - val_loss: 0.4245 - val_mean_iou: 0.7714 - learning_rate: 6.5451e-05\nEpoch 44/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 473ms/step - accuracy: 0.9612 - loss: 0.1654 - mean_iou: 0.8004 - val_accuracy: 0.9223 - val_loss: 0.4692 - val_mean_iou: 0.7204 - learning_rate: 6.0396e-05\nEpoch 45/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 478ms/step - accuracy: 0.9631 - loss: 0.1736 - mean_iou: 0.8161 - val_accuracy: 0.8997 - val_loss: 0.4936 - val_mean_iou: 0.6868 - learning_rate: 5.5226e-05\nEpoch 46/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 474ms/step - accuracy: 0.9618 - loss: 0.1623 - mean_iou: 0.7868 - val_accuracy: 0.8712 - val_loss: 0.6380 - val_mean_iou: 0.5949 - learning_rate: 5.0000e-05\nEpoch 47/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 474ms/step - accuracy: 0.9638 - loss: 0.1645 - mean_iou: 0.8061 - val_accuracy: 0.8661 - val_loss: 0.9286 - val_mean_iou: 0.4588 - learning_rate: 4.4774e-05\nEpoch 48/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 474ms/step - accuracy: 0.9667 - loss: 0.1479 - mean_iou: 0.8019 - val_accuracy: 0.9295 - val_loss: 0.4033 - val_mean_iou: 0.7563 - learning_rate: 3.9604e-05\nEpoch 49/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 473ms/step - accuracy: 0.9685 - loss: 0.1508 - mean_iou: 0.8172 - val_accuracy: 0.9246 - val_loss: 0.3895 - val_mean_iou: 0.7700 - learning_rate: 3.4549e-05\nEpoch 50/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 474ms/step - accuracy: 0.9668 - loss: 0.1480 - mean_iou: 0.8368 - val_accuracy: 0.4749 - val_loss: 0.7798 - val_mean_iou: 0.3170 - learning_rate: 2.9663e-05\nEpoch 51/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 503ms/step - accuracy: 0.9666 - loss: 0.1542 - mean_iou: 0.8378 - val_accuracy: 0.9480 - val_loss: 0.3206 - val_mean_iou: 0.8193 - learning_rate: 2.5000e-05\nEpoch 52/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 474ms/step - accuracy: 0.9676 - loss: 0.1524 - mean_iou: 0.8376 - val_accuracy: 0.9355 - val_loss: 0.3871 - val_mean_iou: 0.7740 - learning_rate: 2.0611e-05\nEpoch 53/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 475ms/step - accuracy: 0.9707 - loss: 0.1522 - mean_iou: 0.8497 - val_accuracy: 0.7184 - val_loss: 0.7367 - val_mean_iou: 0.4539 - learning_rate: 1.6543e-05\nEpoch 54/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 473ms/step - accuracy: 0.9726 - loss: 0.1413 - mean_iou: 0.8607 - val_accuracy: 0.8314 - val_loss: 0.8924 - val_mean_iou: 0.4589 - learning_rate: 1.2843e-05\nEpoch 55/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 475ms/step - accuracy: 0.9706 - loss: 0.1469 - mean_iou: 0.8570 - val_accuracy: 0.7392 - val_loss: 0.7305 - val_mean_iou: 0.4669 - learning_rate: 9.5492e-06\nEpoch 56/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 504ms/step - accuracy: 0.9743 - loss: 0.1370 - mean_iou: 0.8704 - val_accuracy: 0.9526 - val_loss: 0.3164 - val_mean_iou: 0.8332 - learning_rate: 6.6987e-06\nEpoch 57/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 505ms/step - accuracy: 0.9724 - loss: 0.1343 - mean_iou: 0.8654 - val_accuracy: 0.9547 - val_loss: 0.3018 - val_mean_iou: 0.8422 - learning_rate: 4.3227e-06\nEpoch 58/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 505ms/step - accuracy: 0.9737 - loss: 0.1538 - mean_iou: 0.8604 - val_accuracy: 0.9586 - val_loss: 0.2987 - val_mean_iou: 0.8512 - learning_rate: 2.4472e-06\nEpoch 59/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 470ms/step - accuracy: 0.9716 - loss: 0.1452 - mean_iou: 0.8538 - val_accuracy: 0.9535 - val_loss: 0.3065 - val_mean_iou: 0.8388 - learning_rate: 1.0926e-06\nEpoch 60/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 475ms/step - accuracy: 0.9717 - loss: 0.1372 - mean_iou: 0.8568 - val_accuracy: 0.9557 - val_loss: 0.3012 - val_mean_iou: 0.8443 - learning_rate: 2.7391e-07\nEpoch 61/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 474ms/step - accuracy: 0.9674 - loss: 0.1620 - mean_iou: 0.8540 - val_accuracy: 0.7092 - val_loss: 0.8839 - val_mean_iou: 0.4114 - learning_rate: 1.0000e-04\nEpoch 62/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 474ms/step - accuracy: 0.9708 - loss: 0.1762 - mean_iou: 0.8444 - val_accuracy: 0.8275 - val_loss: 0.8411 - val_mean_iou: 0.4926 - learning_rate: 9.9726e-05\nEpoch 63/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 474ms/step - accuracy: 0.9636 - loss: 0.2058 - mean_iou: 0.8461 - val_accuracy: 0.8719 - val_loss: 0.6627 - val_mean_iou: 0.5778 - learning_rate: 9.8907e-05\nEpoch 64/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 475ms/step - accuracy: 0.9732 - loss: 0.1700 - mean_iou: 0.8779 - val_accuracy: 0.8766 - val_loss: 0.8952 - val_mean_iou: 0.4782 - learning_rate: 9.7553e-05\nEpoch 65/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 472ms/step - accuracy: 0.9642 - loss: 0.1811 - mean_iou: 0.8433 - val_accuracy: 0.8666 - val_loss: 0.9819 - val_mean_iou: 0.4360 - learning_rate: 9.5677e-05\nEpoch 66/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 473ms/step - accuracy: 0.9715 - loss: 0.1694 - mean_iou: 0.8733 - val_accuracy: 0.9282 - val_loss: 0.4526 - val_mean_iou: 0.7325 - learning_rate: 9.3301e-05\nEpoch 67/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 475ms/step - accuracy: 0.9720 - loss: 0.1419 - mean_iou: 0.8808 - val_accuracy: 0.8678 - val_loss: 0.5670 - val_mean_iou: 0.6304 - learning_rate: 9.0451e-05\nEpoch 68/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 476ms/step - accuracy: 0.9664 - loss: 0.2020 - mean_iou: 0.8584 - val_accuracy: 0.8119 - val_loss: 0.7061 - val_mean_iou: 0.5168 - learning_rate: 8.7157e-05\nEpoch 69/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 476ms/step - accuracy: 0.9751 - loss: 0.1754 - mean_iou: 0.8805 - val_accuracy: 0.5286 - val_loss: 0.8289 - val_mean_iou: 0.4273 - learning_rate: 8.3457e-05\nEpoch 70/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 475ms/step - accuracy: 0.9755 - loss: 0.1517 - mean_iou: 0.8847 - val_accuracy: 0.7811 - val_loss: 0.9644 - val_mean_iou: 0.4316 - learning_rate: 7.9389e-05\nEpoch 71/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 473ms/step - accuracy: 0.9736 - loss: 0.1579 - mean_iou: 0.8788 - val_accuracy: 0.9002 - val_loss: 0.5451 - val_mean_iou: 0.6738 - learning_rate: 7.5000e-05\nEpoch 72/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 475ms/step - accuracy: 0.9717 - loss: 0.1554 - mean_iou: 0.8793 - val_accuracy: 0.7546 - val_loss: 0.5960 - val_mean_iou: 0.5603 - learning_rate: 7.0337e-05\nEpoch 73/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 472ms/step - accuracy: 0.9741 - loss: 0.1517 - mean_iou: 0.8828 - val_accuracy: 0.6608 - val_loss: 0.8819 - val_mean_iou: 0.3729 - learning_rate: 6.5451e-05\nEpoch 74/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 475ms/step - accuracy: 0.9779 - loss: 0.1421 - mean_iou: 0.8997 - val_accuracy: 0.7510 - val_loss: 0.8476 - val_mean_iou: 0.4330 - learning_rate: 6.0396e-05\nEpoch 75/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 476ms/step - accuracy: 0.9773 - loss: 0.1347 - mean_iou: 0.9004 - val_accuracy: 0.8163 - val_loss: 0.9021 - val_mean_iou: 0.4511 - learning_rate: 5.5226e-05\nEpoch 76/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 473ms/step - accuracy: 0.9735 - loss: 0.1443 - mean_iou: 0.8912 - val_accuracy: 0.3186 - val_loss: 0.7739 - val_mean_iou: 0.4184 - learning_rate: 5.0000e-05\nEpoch 77/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 472ms/step - accuracy: 0.9785 - loss: 0.1268 - mean_iou: 0.9088 - val_accuracy: 0.6781 - val_loss: 0.6874 - val_mean_iou: 0.4525 - learning_rate: 4.4774e-05\nEpoch 78/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 473ms/step - accuracy: 0.9779 - loss: 0.1302 - mean_iou: 0.9053 - val_accuracy: 0.7344 - val_loss: 0.9142 - val_mean_iou: 0.4076 - learning_rate: 3.9604e-05\nEpoch 79/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 474ms/step - accuracy: 0.9794 - loss: 0.1223 - mean_iou: 0.9087 - val_accuracy: 0.9506 - val_loss: 0.3531 - val_mean_iou: 0.8134 - learning_rate: 3.4549e-05\nEpoch 80/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 472ms/step - accuracy: 0.9784 - loss: 0.1266 - mean_iou: 0.9071 - val_accuracy: 0.3583 - val_loss: 0.7591 - val_mean_iou: 0.2545 - learning_rate: 2.9663e-05\nEpoch 81/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 476ms/step - accuracy: 0.9781 - loss: 0.1244 - mean_iou: 0.9011 - val_accuracy: 0.9485 - val_loss: 0.3642 - val_mean_iou: 0.8017 - learning_rate: 2.5000e-05\nEpoch 82/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 476ms/step - accuracy: 0.9826 - loss: 0.1121 - mean_iou: 0.9212 - val_accuracy: 0.9496 - val_loss: 0.3295 - val_mean_iou: 0.8208 - learning_rate: 2.0611e-05\nEpoch 83/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 474ms/step - accuracy: 0.9778 - loss: 0.1232 - mean_iou: 0.9079 - val_accuracy: 0.9573 - val_loss: 0.2954 - val_mean_iou: 0.8472 - learning_rate: 1.6543e-05\nEpoch 84/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 473ms/step - accuracy: 0.9751 - loss: 0.1385 - mean_iou: 0.8898 - val_accuracy: 0.9571 - val_loss: 0.3085 - val_mean_iou: 0.8435 - learning_rate: 1.2843e-05\nEpoch 85/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 474ms/step - accuracy: 0.9765 - loss: 0.1236 - mean_iou: 0.9021 - val_accuracy: 0.9535 - val_loss: 0.3124 - val_mean_iou: 0.8354 - learning_rate: 9.5492e-06\nEpoch 86/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 473ms/step - accuracy: 0.9804 - loss: 0.1071 - mean_iou: 0.9193 - val_accuracy: 0.9514 - val_loss: 0.3384 - val_mean_iou: 0.8169 - learning_rate: 6.6987e-06\nEpoch 87/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 475ms/step - accuracy: 0.9801 - loss: 0.1118 - mean_iou: 0.9114 - val_accuracy: 0.9426 - val_loss: 0.4181 - val_mean_iou: 0.7710 - learning_rate: 4.3227e-06\nEpoch 88/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 475ms/step - accuracy: 0.9793 - loss: 0.1153 - mean_iou: 0.9144 - val_accuracy: 0.9540 - val_loss: 0.3312 - val_mean_iou: 0.8262 - learning_rate: 2.4472e-06\nEpoch 89/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 506ms/step - accuracy: 0.9806 - loss: 0.1099 - mean_iou: 0.9168 - val_accuracy: 0.9613 - val_loss: 0.3032 - val_mean_iou: 0.8531 - learning_rate: 1.0926e-06\nEpoch 90/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 505ms/step - accuracy: 0.9789 - loss: 0.1170 - mean_iou: 0.9123 - val_accuracy: 0.9635 - val_loss: 0.2857 - val_mean_iou: 0.8626 - learning_rate: 2.7391e-07\nEpoch 91/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 472ms/step - accuracy: 0.9791 - loss: 0.1163 - mean_iou: 0.9063 - val_accuracy: 0.8631 - val_loss: 0.9687 - val_mean_iou: 0.4370 - learning_rate: 1.0000e-04\nEpoch 92/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 473ms/step - accuracy: 0.9776 - loss: 0.1185 - mean_iou: 0.9048 - val_accuracy: 0.5368 - val_loss: 0.8716 - val_mean_iou: 0.4400 - learning_rate: 9.9726e-05\nEpoch 93/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 472ms/step - accuracy: 0.9752 - loss: 0.1292 - mean_iou: 0.8979 - val_accuracy: 0.9241 - val_loss: 0.4938 - val_mean_iou: 0.6933 - learning_rate: 9.8907e-05\nEpoch 94/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 477ms/step - accuracy: 0.9738 - loss: 0.1457 - mean_iou: 0.8795 - val_accuracy: 0.8421 - val_loss: 0.7987 - val_mean_iou: 0.5084 - learning_rate: 9.7553e-05\nEpoch 95/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 471ms/step - accuracy: 0.9744 - loss: 0.1225 - mean_iou: 0.8987 - val_accuracy: 0.7802 - val_loss: 0.8757 - val_mean_iou: 0.4377 - learning_rate: 9.5677e-05\nEpoch 96/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 473ms/step - accuracy: 0.9725 - loss: 0.1299 - mean_iou: 0.8823 - val_accuracy: 0.8400 - val_loss: 0.9710 - val_mean_iou: 0.4346 - learning_rate: 9.3301e-05\nEpoch 97/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 473ms/step - accuracy: 0.9718 - loss: 0.1321 - mean_iou: 0.8874 - val_accuracy: 0.8560 - val_loss: 0.8651 - val_mean_iou: 0.4764 - learning_rate: 9.0451e-05\nEpoch 98/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 469ms/step - accuracy: 0.9754 - loss: 0.1175 - mean_iou: 0.9056 - val_accuracy: 0.8462 - val_loss: 0.9707 - val_mean_iou: 0.4376 - learning_rate: 8.7157e-05\nEpoch 99/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 473ms/step - accuracy: 0.9748 - loss: 0.1161 - mean_iou: 0.9044 - val_accuracy: 0.8796 - val_loss: 0.8325 - val_mean_iou: 0.4895 - learning_rate: 8.3457e-05\nEpoch 100/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 473ms/step - accuracy: 0.9763 - loss: 0.1105 - mean_iou: 0.9109 - val_accuracy: 0.7700 - val_loss: 0.9528 - val_mean_iou: 0.4071 - learning_rate: 7.9389e-05\n Fold 2\nEpoch 1/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 740ms/step - accuracy: 0.6049 - loss: 0.6583 - mean_iou: 0.4157 - val_accuracy: 0.8632 - val_loss: 0.9942 - val_mean_iou: 0.4316 - learning_rate: 1.0000e-04\nEpoch 2/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 473ms/step - accuracy: 0.8387 - loss: 0.4664 - mean_iou: 0.4368 - val_accuracy: 0.8632 - val_loss: 0.9973 - val_mean_iou: 0.4316 - learning_rate: 9.9726e-05\nEpoch 3/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 485ms/step - accuracy: 0.8906 - loss: 0.3672 - mean_iou: 0.4367 - val_accuracy: 0.8633 - val_loss: 0.9969 - val_mean_iou: 0.4316 - learning_rate: 9.8907e-05\nEpoch 4/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 477ms/step - accuracy: 0.8979 - loss: 0.3496 - mean_iou: 0.4880 - val_accuracy: 0.8657 - val_loss: 0.9618 - val_mean_iou: 0.4316 - learning_rate: 9.7553e-05\nEpoch 5/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 480ms/step - accuracy: 0.9174 - loss: 0.3188 - mean_iou: 0.5781 - val_accuracy: 0.8898 - val_loss: 0.6773 - val_mean_iou: 0.4316 - learning_rate: 9.5677e-05\nEpoch 6/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 480ms/step - accuracy: 0.9288 - loss: 0.2937 - mean_iou: 0.6499 - val_accuracy: 0.8738 - val_loss: 0.8858 - val_mean_iou: 0.4316 - learning_rate: 9.3301e-05\nEpoch 7/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 508ms/step - accuracy: 0.9282 - loss: 0.3330 - mean_iou: 0.6940 - val_accuracy: 0.8827 - val_loss: 0.7166 - val_mean_iou: 0.5372 - learning_rate: 9.0451e-05\nEpoch 8/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 509ms/step - accuracy: 0.9282 - loss: 0.2997 - mean_iou: 0.7127 - val_accuracy: 0.8911 - val_loss: 0.7135 - val_mean_iou: 0.5520 - learning_rate: 8.7157e-05\nEpoch 9/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 507ms/step - accuracy: 0.9397 - loss: 0.2864 - mean_iou: 0.7575 - val_accuracy: 0.9112 - val_loss: 0.5838 - val_mean_iou: 0.6389 - learning_rate: 8.3457e-05\nEpoch 10/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 484ms/step - accuracy: 0.9498 - loss: 0.2544 - mean_iou: 0.7901 - val_accuracy: 0.8876 - val_loss: 0.7775 - val_mean_iou: 0.5300 - learning_rate: 7.9389e-05\nEpoch 11/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 508ms/step - accuracy: 0.9430 - loss: 0.2722 - mean_iou: 0.7773 - val_accuracy: 0.9078 - val_loss: 0.5701 - val_mean_iou: 0.6471 - learning_rate: 7.5000e-05\nEpoch 12/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 478ms/step - accuracy: 0.9515 - loss: 0.2741 - mean_iou: 0.8004 - val_accuracy: 0.8916 - val_loss: 0.7221 - val_mean_iou: 0.5707 - learning_rate: 7.0337e-05\nEpoch 13/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 508ms/step - accuracy: 0.9533 - loss: 0.2670 - mean_iou: 0.8126 - val_accuracy: 0.9405 - val_loss: 0.4028 - val_mean_iou: 0.7731 - learning_rate: 6.5451e-05\nEpoch 14/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 482ms/step - accuracy: 0.9544 - loss: 0.2332 - mean_iou: 0.8190 - val_accuracy: 0.9082 - val_loss: 0.5600 - val_mean_iou: 0.6599 - learning_rate: 6.0396e-05\nEpoch 15/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 478ms/step - accuracy: 0.9508 - loss: 0.2633 - mean_iou: 0.8053 - val_accuracy: 0.8802 - val_loss: 0.7433 - val_mean_iou: 0.5318 - learning_rate: 5.5226e-05\nEpoch 16/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 480ms/step - accuracy: 0.9554 - loss: 0.2561 - mean_iou: 0.8138 - val_accuracy: 0.8968 - val_loss: 0.5481 - val_mean_iou: 0.6775 - learning_rate: 5.0000e-05\nEpoch 17/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 481ms/step - accuracy: 0.9583 - loss: 0.2341 - mean_iou: 0.8291 - val_accuracy: 0.4218 - val_loss: 0.7825 - val_mean_iou: 0.4294 - learning_rate: 4.4774e-05\nEpoch 18/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 508ms/step - accuracy: 0.9559 - loss: 0.2370 - mean_iou: 0.8232 - val_accuracy: 0.9412 - val_loss: 0.3843 - val_mean_iou: 0.7865 - learning_rate: 3.9604e-05\nEpoch 19/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 483ms/step - accuracy: 0.9561 - loss: 0.2514 - mean_iou: 0.8178 - val_accuracy: 0.8719 - val_loss: 0.8367 - val_mean_iou: 0.4841 - learning_rate: 3.4549e-05\nEpoch 20/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 479ms/step - accuracy: 0.9680 - loss: 0.2055 - mean_iou: 0.8661 - val_accuracy: 0.8750 - val_loss: 0.8377 - val_mean_iou: 0.4914 - learning_rate: 2.9663e-05\nEpoch 21/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 480ms/step - accuracy: 0.9616 - loss: 0.2098 - mean_iou: 0.8501 - val_accuracy: 0.7310 - val_loss: 0.7895 - val_mean_iou: 0.4557 - learning_rate: 2.5000e-05\nEpoch 22/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 478ms/step - accuracy: 0.9628 - loss: 0.2060 - mean_iou: 0.8415 - val_accuracy: 0.7188 - val_loss: 0.8558 - val_mean_iou: 0.4582 - learning_rate: 2.0611e-05\nEpoch 23/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 479ms/step - accuracy: 0.9659 - loss: 0.1930 - mean_iou: 0.8588 - val_accuracy: 0.9067 - val_loss: 0.6200 - val_mean_iou: 0.6354 - learning_rate: 1.6543e-05\nEpoch 24/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 483ms/step - accuracy: 0.9669 - loss: 0.1906 - mean_iou: 0.8661 - val_accuracy: 0.9434 - val_loss: 0.4043 - val_mean_iou: 0.7838 - learning_rate: 1.2843e-05\nEpoch 25/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 477ms/step - accuracy: 0.9586 - loss: 0.2257 - mean_iou: 0.8197 - val_accuracy: 0.9216 - val_loss: 0.5220 - val_mean_iou: 0.7025 - learning_rate: 9.5492e-06\nEpoch 26/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 511ms/step - accuracy: 0.9669 - loss: 0.1907 - mean_iou: 0.8640 - val_accuracy: 0.9507 - val_loss: 0.3372 - val_mean_iou: 0.8236 - learning_rate: 6.6987e-06\nEpoch 27/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 510ms/step - accuracy: 0.9650 - loss: 0.1957 - mean_iou: 0.8589 - val_accuracy: 0.9520 - val_loss: 0.3301 - val_mean_iou: 0.8327 - learning_rate: 4.3227e-06\nEpoch 28/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 481ms/step - accuracy: 0.9678 - loss: 0.1791 - mean_iou: 0.8663 - val_accuracy: 0.9521 - val_loss: 0.3298 - val_mean_iou: 0.8310 - learning_rate: 2.4472e-06\nEpoch 29/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 509ms/step - accuracy: 0.9645 - loss: 0.2137 - mean_iou: 0.8523 - val_accuracy: 0.9533 - val_loss: 0.3237 - val_mean_iou: 0.8370 - learning_rate: 1.0926e-06\nEpoch 30/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 508ms/step - accuracy: 0.9642 - loss: 0.1952 - mean_iou: 0.8501 - val_accuracy: 0.9531 - val_loss: 0.3226 - val_mean_iou: 0.8373 - learning_rate: 2.7391e-07\nEpoch 31/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 483ms/step - accuracy: 0.9630 - loss: 0.1901 - mean_iou: 0.8487 - val_accuracy: 0.8361 - val_loss: 0.9080 - val_mean_iou: 0.4557 - learning_rate: 1.0000e-04\nEpoch 32/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 482ms/step - accuracy: 0.9570 - loss: 0.2276 - mean_iou: 0.8310 - val_accuracy: 0.3855 - val_loss: 0.7772 - val_mean_iou: 0.4345 - learning_rate: 9.9726e-05\nEpoch 33/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 479ms/step - accuracy: 0.9636 - loss: 0.1827 - mean_iou: 0.8603 - val_accuracy: 0.6354 - val_loss: 0.8677 - val_mean_iou: 0.3620 - learning_rate: 9.8907e-05\nEpoch 34/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 479ms/step - accuracy: 0.9512 - loss: 0.2300 - mean_iou: 0.8166 - val_accuracy: 0.6228 - val_loss: 0.8499 - val_mean_iou: 0.3813 - learning_rate: 9.7553e-05\nEpoch 35/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 480ms/step - accuracy: 0.9643 - loss: 0.1774 - mean_iou: 0.8607 - val_accuracy: 0.8471 - val_loss: 0.9948 - val_mean_iou: 0.4252 - learning_rate: 9.5677e-05\nEpoch 36/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 476ms/step - accuracy: 0.9601 - loss: 0.1849 - mean_iou: 0.8506 - val_accuracy: 0.2329 - val_loss: 0.7787 - val_mean_iou: 0.3659 - learning_rate: 9.3301e-05\nEpoch 37/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 475ms/step - accuracy: 0.9655 - loss: 0.1643 - mean_iou: 0.8714 - val_accuracy: 0.8694 - val_loss: 0.9212 - val_mean_iou: 0.4564 - learning_rate: 9.0451e-05\nEpoch 38/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 477ms/step - accuracy: 0.9646 - loss: 0.1722 - mean_iou: 0.8686 - val_accuracy: 0.8570 - val_loss: 0.9290 - val_mean_iou: 0.4460 - learning_rate: 8.7157e-05\nEpoch 39/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 476ms/step - accuracy: 0.9656 - loss: 0.1630 - mean_iou: 0.8736 - val_accuracy: 0.8607 - val_loss: 0.9642 - val_mean_iou: 0.4445 - learning_rate: 8.3457e-05\nEpoch 40/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 477ms/step - accuracy: 0.9638 - loss: 0.1793 - mean_iou: 0.8645 - val_accuracy: 0.7491 - val_loss: 0.8483 - val_mean_iou: 0.4365 - learning_rate: 7.9389e-05\nEpoch 41/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 476ms/step - accuracy: 0.9676 - loss: 0.1452 - mean_iou: 0.8839 - val_accuracy: 0.5827 - val_loss: 0.7940 - val_mean_iou: 0.3520 - learning_rate: 7.5000e-05\nEpoch 42/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 482ms/step - accuracy: 0.9658 - loss: 0.1634 - mean_iou: 0.8764 - val_accuracy: 0.5572 - val_loss: 0.8332 - val_mean_iou: 0.3733 - learning_rate: 7.0337e-05\nEpoch 43/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 479ms/step - accuracy: 0.9671 - loss: 0.1589 - mean_iou: 0.8750 - val_accuracy: 0.8942 - val_loss: 0.6330 - val_mean_iou: 0.6049 - learning_rate: 6.5451e-05\nEpoch 44/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 483ms/step - accuracy: 0.9691 - loss: 0.1435 - mean_iou: 0.8872 - val_accuracy: 0.8719 - val_loss: 0.8680 - val_mean_iou: 0.4856 - learning_rate: 6.0396e-05\nEpoch 45/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 479ms/step - accuracy: 0.9677 - loss: 0.1644 - mean_iou: 0.8767 - val_accuracy: 0.9093 - val_loss: 0.5636 - val_mean_iou: 0.6612 - learning_rate: 5.5226e-05\nEpoch 46/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 480ms/step - accuracy: 0.9692 - loss: 0.1501 - mean_iou: 0.8834 - val_accuracy: 0.6378 - val_loss: 0.8506 - val_mean_iou: 0.3881 - learning_rate: 5.0000e-05\nEpoch 47/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 478ms/step - accuracy: 0.9674 - loss: 0.1462 - mean_iou: 0.8809 - val_accuracy: 0.4705 - val_loss: 0.7964 - val_mean_iou: 0.3037 - learning_rate: 4.4774e-05\nEpoch 48/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 479ms/step - accuracy: 0.9639 - loss: 0.1619 - mean_iou: 0.8727 - val_accuracy: 0.6162 - val_loss: 0.8032 - val_mean_iou: 0.3884 - learning_rate: 3.9604e-05\nEpoch 49/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 478ms/step - accuracy: 0.9688 - loss: 0.1484 - mean_iou: 0.8864 - val_accuracy: 0.8111 - val_loss: 0.7852 - val_mean_iou: 0.4890 - learning_rate: 3.4549e-05\nEpoch 50/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 483ms/step - accuracy: 0.9732 - loss: 0.1324 - mean_iou: 0.9003 - val_accuracy: 0.8628 - val_loss: 0.9960 - val_mean_iou: 0.4327 - learning_rate: 2.9663e-05\nEpoch 51/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 477ms/step - accuracy: 0.9733 - loss: 0.1316 - mean_iou: 0.8994 - val_accuracy: 0.8878 - val_loss: 0.5433 - val_mean_iou: 0.6929 - learning_rate: 2.5000e-05\nEpoch 52/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 478ms/step - accuracy: 0.9728 - loss: 0.1359 - mean_iou: 0.8980 - val_accuracy: 0.9293 - val_loss: 0.4721 - val_mean_iou: 0.7276 - learning_rate: 2.0611e-05\nEpoch 53/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 477ms/step - accuracy: 0.9711 - loss: 0.1417 - mean_iou: 0.8878 - val_accuracy: 0.9488 - val_loss: 0.3432 - val_mean_iou: 0.8164 - learning_rate: 1.6543e-05\nEpoch 54/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 507ms/step - accuracy: 0.9719 - loss: 0.1461 - mean_iou: 0.8926 - val_accuracy: 0.9550 - val_loss: 0.3095 - val_mean_iou: 0.8376 - learning_rate: 1.2843e-05\nEpoch 55/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 507ms/step - accuracy: 0.9711 - loss: 0.1417 - mean_iou: 0.8918 - val_accuracy: 0.9566 - val_loss: 0.3033 - val_mean_iou: 0.8431 - learning_rate: 9.5492e-06\nEpoch 56/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 477ms/step - accuracy: 0.9741 - loss: 0.1346 - mean_iou: 0.8991 - val_accuracy: 0.9455 - val_loss: 0.3648 - val_mean_iou: 0.7947 - learning_rate: 6.6987e-06\nEpoch 57/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 475ms/step - accuracy: 0.9738 - loss: 0.1320 - mean_iou: 0.9005 - val_accuracy: 0.9514 - val_loss: 0.3448 - val_mean_iou: 0.8163 - learning_rate: 4.3227e-06\nEpoch 58/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 476ms/step - accuracy: 0.9751 - loss: 0.1390 - mean_iou: 0.9025 - val_accuracy: 0.9509 - val_loss: 0.3606 - val_mean_iou: 0.8116 - learning_rate: 2.4472e-06\nEpoch 59/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 479ms/step - accuracy: 0.9715 - loss: 0.1476 - mean_iou: 0.8901 - val_accuracy: 0.9543 - val_loss: 0.3384 - val_mean_iou: 0.8259 - learning_rate: 1.0926e-06\nEpoch 60/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 510ms/step - accuracy: 0.9740 - loss: 0.1307 - mean_iou: 0.9014 - val_accuracy: 0.9596 - val_loss: 0.2979 - val_mean_iou: 0.8502 - learning_rate: 2.7391e-07\nEpoch 61/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 477ms/step - accuracy: 0.9739 - loss: 0.1355 - mean_iou: 0.9007 - val_accuracy: 0.5592 - val_loss: 0.8119 - val_mean_iou: 0.3579 - learning_rate: 1.0000e-04\nEpoch 62/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 477ms/step - accuracy: 0.9662 - loss: 0.1574 - mean_iou: 0.8759 - val_accuracy: 0.7620 - val_loss: 0.8882 - val_mean_iou: 0.4272 - learning_rate: 9.9726e-05\nEpoch 63/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 479ms/step - accuracy: 0.9698 - loss: 0.1731 - mean_iou: 0.8804 - val_accuracy: 0.6558 - val_loss: 0.8238 - val_mean_iou: 0.4015 - learning_rate: 9.8907e-05\nEpoch 64/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 480ms/step - accuracy: 0.9692 - loss: 0.1793 - mean_iou: 0.8691 - val_accuracy: 0.6216 - val_loss: 0.8251 - val_mean_iou: 0.3693 - learning_rate: 9.7553e-05\nEpoch 65/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 478ms/step - accuracy: 0.9700 - loss: 0.1677 - mean_iou: 0.8791 - val_accuracy: 0.7994 - val_loss: 0.8319 - val_mean_iou: 0.4669 - learning_rate: 9.5677e-05\nEpoch 66/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 478ms/step - accuracy: 0.9739 - loss: 0.1532 - mean_iou: 0.8930 - val_accuracy: 0.7678 - val_loss: 0.8420 - val_mean_iou: 0.4408 - learning_rate: 9.3301e-05\nEpoch 67/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 482ms/step - accuracy: 0.9729 - loss: 0.1418 - mean_iou: 0.8953 - val_accuracy: 0.7066 - val_loss: 0.8524 - val_mean_iou: 0.4099 - learning_rate: 9.0451e-05\nEpoch 68/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 480ms/step - accuracy: 0.9782 - loss: 0.1461 - mean_iou: 0.9008 - val_accuracy: 0.6725 - val_loss: 0.8283 - val_mean_iou: 0.3945 - learning_rate: 8.7157e-05\nEpoch 69/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 479ms/step - accuracy: 0.9755 - loss: 0.1443 - mean_iou: 0.8959 - val_accuracy: 0.8237 - val_loss: 0.9680 - val_mean_iou: 0.4250 - learning_rate: 8.3457e-05\nEpoch 70/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 482ms/step - accuracy: 0.9701 - loss: 0.1927 - mean_iou: 0.8699 - val_accuracy: 0.8921 - val_loss: 0.5685 - val_mean_iou: 0.6624 - learning_rate: 7.9389e-05\nEpoch 71/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 480ms/step - accuracy: 0.9738 - loss: 0.1396 - mean_iou: 0.8936 - val_accuracy: 0.7723 - val_loss: 0.9054 - val_mean_iou: 0.4244 - learning_rate: 7.5000e-05\nEpoch 72/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 481ms/step - accuracy: 0.9698 - loss: 0.1581 - mean_iou: 0.8844 - val_accuracy: 0.8425 - val_loss: 0.5006 - val_mean_iou: 0.6363 - learning_rate: 7.0337e-05\nEpoch 73/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 480ms/step - accuracy: 0.9759 - loss: 0.1314 - mean_iou: 0.9036 - val_accuracy: 0.8493 - val_loss: 0.9784 - val_mean_iou: 0.4346 - learning_rate: 6.5451e-05\nEpoch 74/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 480ms/step - accuracy: 0.9753 - loss: 0.1727 - mean_iou: 0.8898 - val_accuracy: 0.7721 - val_loss: 0.9444 - val_mean_iou: 0.4102 - learning_rate: 6.0396e-05\nEpoch 75/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 481ms/step - accuracy: 0.9764 - loss: 0.1449 - mean_iou: 0.9029 - val_accuracy: 0.7248 - val_loss: 0.8435 - val_mean_iou: 0.4208 - learning_rate: 5.5226e-05\nEpoch 76/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 481ms/step - accuracy: 0.9732 - loss: 0.1521 - mean_iou: 0.8900 - val_accuracy: 0.6587 - val_loss: 0.8381 - val_mean_iou: 0.3798 - learning_rate: 5.0000e-05\nEpoch 77/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 480ms/step - accuracy: 0.9756 - loss: 0.1739 - mean_iou: 0.8899 - val_accuracy: 0.9149 - val_loss: 0.5119 - val_mean_iou: 0.6883 - learning_rate: 4.4774e-05\nEpoch 78/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 478ms/step - accuracy: 0.9795 - loss: 0.1295 - mean_iou: 0.9129 - val_accuracy: 0.9225 - val_loss: 0.4807 - val_mean_iou: 0.7102 - learning_rate: 3.9604e-05\nEpoch 79/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 478ms/step - accuracy: 0.9787 - loss: 0.1137 - mean_iou: 0.9165 - val_accuracy: 0.8632 - val_loss: 0.8321 - val_mean_iou: 0.5062 - learning_rate: 3.4549e-05\nEpoch 80/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 478ms/step - accuracy: 0.9793 - loss: 0.1137 - mean_iou: 0.9146 - val_accuracy: 0.7534 - val_loss: 0.7965 - val_mean_iou: 0.5553 - learning_rate: 2.9663e-05\nEpoch 81/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 479ms/step - accuracy: 0.9760 - loss: 0.1476 - mean_iou: 0.9008 - val_accuracy: 0.8876 - val_loss: 0.5940 - val_mean_iou: 0.6300 - learning_rate: 2.5000e-05\nEpoch 82/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 479ms/step - accuracy: 0.9807 - loss: 0.1123 - mean_iou: 0.9212 - val_accuracy: 0.9470 - val_loss: 0.3441 - val_mean_iou: 0.8018 - learning_rate: 2.0611e-05\nEpoch 83/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 477ms/step - accuracy: 0.9810 - loss: 0.1038 - mean_iou: 0.9246 - val_accuracy: 0.9522 - val_loss: 0.3204 - val_mean_iou: 0.8206 - learning_rate: 1.6543e-05\nEpoch 84/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 478ms/step - accuracy: 0.9780 - loss: 0.1199 - mean_iou: 0.9150 - val_accuracy: 0.9238 - val_loss: 0.4558 - val_mean_iou: 0.7301 - learning_rate: 1.2843e-05\nEpoch 85/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 481ms/step - accuracy: 0.9803 - loss: 0.1074 - mean_iou: 0.9226 - val_accuracy: 0.9326 - val_loss: 0.4323 - val_mean_iou: 0.7521 - learning_rate: 9.5492e-06\nEpoch 86/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 484ms/step - accuracy: 0.9795 - loss: 0.1150 - mean_iou: 0.9206 - val_accuracy: 0.9518 - val_loss: 0.3346 - val_mean_iou: 0.8184 - learning_rate: 6.6987e-06\nEpoch 87/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 482ms/step - accuracy: 0.9763 - loss: 0.1166 - mean_iou: 0.9114 - val_accuracy: 0.9552 - val_loss: 0.3214 - val_mean_iou: 0.8335 - learning_rate: 4.3227e-06\nEpoch 88/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 483ms/step - accuracy: 0.9787 - loss: 0.1110 - mean_iou: 0.9174 - val_accuracy: 0.9542 - val_loss: 0.3234 - val_mean_iou: 0.8309 - learning_rate: 2.4472e-06\nEpoch 89/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 479ms/step - accuracy: 0.9779 - loss: 0.1160 - mean_iou: 0.9146 - val_accuracy: 0.9564 - val_loss: 0.3094 - val_mean_iou: 0.8392 - learning_rate: 1.0926e-06\nEpoch 90/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 481ms/step - accuracy: 0.9812 - loss: 0.1011 - mean_iou: 0.9253 - val_accuracy: 0.9575 - val_loss: 0.3028 - val_mean_iou: 0.8438 - learning_rate: 2.7391e-07\nEpoch 91/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 479ms/step - accuracy: 0.9751 - loss: 0.1190 - mean_iou: 0.9094 - val_accuracy: 0.8268 - val_loss: 0.9593 - val_mean_iou: 0.4317 - learning_rate: 1.0000e-04\nEpoch 92/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 482ms/step - accuracy: 0.9785 - loss: 0.1140 - mean_iou: 0.9166 - val_accuracy: 0.7213 - val_loss: 0.8633 - val_mean_iou: 0.4124 - learning_rate: 9.9726e-05\nEpoch 93/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 482ms/step - accuracy: 0.9739 - loss: 0.1196 - mean_iou: 0.9061 - val_accuracy: 0.8111 - val_loss: 0.9445 - val_mean_iou: 0.4289 - learning_rate: 9.8907e-05\nEpoch 94/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 476ms/step - accuracy: 0.9768 - loss: 0.1215 - mean_iou: 0.9113 - val_accuracy: 0.7780 - val_loss: 0.9083 - val_mean_iou: 0.4269 - learning_rate: 9.7553e-05\nEpoch 95/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 474ms/step - accuracy: 0.9737 - loss: 0.1279 - mean_iou: 0.9043 - val_accuracy: 0.8342 - val_loss: 0.9649 - val_mean_iou: 0.4346 - learning_rate: 9.5677e-05\nEpoch 96/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 476ms/step - accuracy: 0.9755 - loss: 0.1319 - mean_iou: 0.9041 - val_accuracy: 0.8069 - val_loss: 0.9059 - val_mean_iou: 0.4453 - learning_rate: 9.3301e-05\nEpoch 97/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 477ms/step - accuracy: 0.9682 - loss: 0.1487 - mean_iou: 0.8875 - val_accuracy: 0.8860 - val_loss: 0.6151 - val_mean_iou: 0.6328 - learning_rate: 9.0451e-05\nEpoch 98/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 480ms/step - accuracy: 0.9740 - loss: 0.1237 - mean_iou: 0.9052 - val_accuracy: 0.8877 - val_loss: 0.7572 - val_mean_iou: 0.5429 - learning_rate: 8.7157e-05\nEpoch 99/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 477ms/step - accuracy: 0.9716 - loss: 0.1347 - mean_iou: 0.8983 - val_accuracy: 0.9019 - val_loss: 0.6067 - val_mean_iou: 0.6507 - learning_rate: 8.3457e-05\nEpoch 100/100\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 477ms/step - accuracy: 0.9746 - loss: 0.1191 - mean_iou: 0.9074 - val_accuracy: 0.8505 - val_loss: 0.6740 - val_mean_iou: 0.5714 - learning_rate: 7.9389e-05\n → EffB3 mean IoU: 0.9165161848068237\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 600x400 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAhgAAAF2CAYAAAAskuGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8uUlEQVR4nO3deVxUZeP///eAMqAGqCgKkrjlkgmmQbhmobgvZaFWEJnelX4sKUuzXFPa3L5qWeaW5R2mZrmEOy135JpZd6lZbpmgZoKigjLn90c/5nacQUGPjOjr+Xicx4O55jrnXNfhDLznOteZsRiGYQgAAMBEHu5uAAAAuPEQMAAAgOkIGAAAwHQEDAAAYDoCBgAAMB0BAwAAmI6AAQAATEfAAAAApiNgAAAA0xEw4CQ0NFSdO3e+ZJ19+/bJYrHorbfeKqZWwQxz586VxWLRvn373N2Ua+LUqVN64oknVKVKFVksFj377LOSpIyMDPXs2VMVK1aUxWLR5MmT3dpOd3vzzTdVs2ZNeXp6Kjw8XJJ0/vx5vfDCCwoJCZGHh4e6d+/u1ja6W0pKisLDw+Xt7S2LxaITJ05IkubPn6969eqpdOnS8vf3d2sbr3cEjOtU/j+CC5fKlSurTZs2+uKLL9zdPKDYuHotXLh899139rrjx4/X3Llz9dRTT2n+/Pl69NFHJUmDBw/WqlWrNGzYMM2fP1/t27dXamqq07YqVKigu+++Wx999JFTO1avXq2+ffuqYcOG8vT0VGhoaHEdgsvKD/wFLa+99pq97urVq/XCCy+oefPmmjNnjsaPHy9Jmj17tt5880317NlT8+bN0+DBgyXJaVtly5ZVgwYN9Oqrr+r06dMO7ViyZIliY2NVs2ZNlSlTRnXr1tVzzz1n/+fsbqGhoQUeo/bt29vr/fXXX3rooYfk4+Oj6dOna/78+Spbtqx27typxx57TLVq1dLMmTP13nvvSZLuueceh215eXmpRo0a6t+/vw4ePOjQhv/+97968MEH7ccoICBArVq10rJly4r1WBSHUu5uAC5tzJgxqlGjhgzDUEZGhubOnauOHTtq2bJllx1lAC726KOPqlevXrJare5uSpHlvxYuVrt2bfvP69ev1913362RI0c61Fm/fr26deum559/3l6Wnp4uSRo0aJDuuusuSf/8Y0lOTtYjjzyiEydOaMCAAfb6CxYsUHJysu68804FBQWZ2jez9O7dWx07dnQqb9y4sf3n9evXy8PDQ7NmzZKXl5dDeXBwsCZNmuS0ftu2bRUXFyfpn1Gir7/+Wq+88op++OEHffLJJ/Z6/fv3V1BQkB555BHdeuut+vHHHzVt2jStXLlS27Ztk4+Pj5ndvSLh4eF67rnnnMov/J1u3rxZJ0+e1NixYxUdHW0vT01Nlc1m05QpUxzOO0mqVq2akpKSJEm5ubn6+eefNWPGDK1atUq//PKLypQpI0nav3+/Tp48qfj4eAUFBen06dNavHixunbtqnfffVf9+/e/Ft12DwPXpTlz5hiSjM2bNzuUHz9+3ChdurTRp0+fa7bv6tWrG506dbpknb179xqSjDfffPOatQPmOXXqlLubcMUKei24UqNGDZfnrsViMQYMGOBQtmHDBkOS8cknnziU5+TkGMHBwUazZs0cyg8dOmTk5uYahmEYnTp1MqpXr17Enlw7RXk9JiQkGGXLlnUqb9OmjXH77bc7lUtyOnaGYRg9e/Y0PDw8jDNnztjLNmzY4FRv3rx5hiRj5syZl23btVaYv22G8b82X3zOjR492pBkHD161KG8devWLo/dtGnTDEnG6tWrL7m/8+fPG2FhYUbdunUL0YuSg0skJYy/v798fHxUqpTj4NNbb72lZs2aqWLFivLx8VGTJk20aNEil9v48MMPFRERoTJlyqh8+fJq1aqVVq9efcn9zps3T6VKldKQIUOcnps0aZKqV68uHx8ftW7dWj/99JNTnfXr16tly5YqW7as/P391a1bN/3yyy8OdUaNGiWLxaI9e/bosccek7+/v/z8/JSQkOA0FJvfjyZNmsjHx0cVKlRQr169nIYjC3Lo0CH17dtXQUFBslqtqlGjhp566inl5uba6/z+++968MEHVaFCBZUpU0Z33323VqxY4bCd/GH2hQsXavTo0QoODtYtt9yinj17KjMzUzk5OXr22WdVuXJllStXTgkJCcrJyXHYhsVi0cCBA/XRRx+pbt268vb2VpMmTfTVV1851Nu/f7+efvpp1a1bVz4+PqpYsaIefPBBp/kU+ZcUvvzySz399NOqXLmyqlWr5vDchets2bJFMTExCggIkI+Pj2rUqKHHH3/cYZvZ2dl67rnnFBISIqvVqrp16+qtt96ScdGXMef3ZenSpWrYsKGsVqtuv/12paSkOP0Odu7cqQMHDlz6F1VI+b+HvXv3asWKFfah6vz+Goah6dOn28svxcvLS+XLl3d6jQUFBal06dJFbtu5c+dUoUIFJSQkOD2XlZUlb29vh5GVqVOn6vbbb7e/Pps2baoFCxYUeb+uWCwWzZkzR9nZ2U7HaMOGDfrvf/9rL09NTb3ktvLnuVx4nO655x6nej169JAkp9f7xTp37qyaNWu6fC4qKkpNmza1P16zZo1atGghf39/lStXTnXr1tVLL710ye0X1j333KP4+HhJ0l133SWLxaLHHntMoaGh9pGxSpUqyWKxaNSoUZfcVpUqVSTJ6Vy6mKenp0JCQq6bS0lm4RLJdS4zM1PHjh2TYRg6cuSIpk6dqlOnTumRRx5xqDdlyhR17dpVDz/8sHJzc/Xxxx/rwQcf1PLly9WpUyd7vdGjR2vUqFFq1qyZxowZIy8vL23cuFHr169Xu3btXLbhvffe05NPPqmXXnpJr776qsNzH3zwgU6ePKkBAwbo7NmzmjJliu699179+OOPCgwMlCStXbtWHTp0UM2aNTVq1CidOXNGU6dOVfPmzbVt2zana9kPPfSQatSooaSkJG3btk3vv/++KleurNdff91eZ9y4cXrllVf00EMP6YknntDRo0c1depUtWrVSt9///0lJ1/9+eefioiI0IkTJ9S/f3/Vq1dPhw4d0qJFi3T69Gl5eXkpIyNDzZo10+nTpzVo0CBVrFhR8+bNU9euXbVo0SL7H818SUlJ8vHx0dChQ7Vnzx5NnTpVpUuXloeHh/7++2+NGjVK3333nebOnasaNWpoxIgRDut/+eWXSk5O1qBBg2S1WvX222+rffv22rRpkxo2bCjpn2Hbb7/9Vr169VK1atW0b98+vfPOO7rnnnv0888/24dg8z399NOqVKmSRowYoezsbJfH4siRI2rXrp0qVaqkoUOHyt/fX/v27dOSJUvsdQzDUNeuXbVhwwb17dtX4eHhWrVqlYYMGaJDhw45Dal/8803WrJkiZ5++mndcsst+n//7//pgQce0IEDB1SxYkV7vfr166t169aX/UeWL/+1cCGLxaKKFSuqfv36mj9/vgYPHqxq1arZh8AbN25sn4tx4TD/hU6ePGnf7vHjx7VgwQL99NNPmjVrVqHadTmlS5dWjx49tGTJEr377rsOlyWWLl2qnJwc9erVS5I0c+ZMDRo0SD179tQzzzyjs2fPaseOHdq4caP69Olz2X2dPn3a6RhJ/7wxKVWqlObPn6/33ntPmzZt0vvvvy/pf8do3LhxOnXqlH2Yv379+vb1z549a99udna2/vOf/2jevHnq06fPZf955l+KCggIuGS92NhYxcXFafPmzfZLVtI/wfq7777Tm2++KemfOQydO3dWo0aNNGbMGFmtVu3Zs0f/+c9/Lnd4JP0T+Fwdo7Jly8rHx0fDhw9X3bp19d5779kvy9WqVUvdu3fXBx98oE8//VTvvPOOypUrp0aNGtnXz8vLs2/33Llz+uWXXzRy5EjVrl1bzZs3d9pfdna2zpw5o8zMTH3++ef64osvFBsbW6g+lBjuHUBBQfKHhS9erFarMXfuXKf6p0+fdnicm5trNGzY0Lj33nvtZb/++qvh4eFh9OjRw8jLy3Oob7PZ7D9fOIw4ZcoUw2KxGGPHjnWonz8k6+PjY/zxxx/28o0bNxqSjMGDB9vLwsPDjcqVKxt//fWXveyHH34wPDw8jLi4OHvZyJEjDUnG448/7rCvHj16GBUrVrQ/3rdvn+Hp6WmMGzfOod6PP/5olCpVyqn8YnFxcYaHh4fLIff84/Dss88akoyvv/7a/tzJkyeNGjVqGKGhofbjlz/M3rBhQ/vwuWEYRu/evQ2LxWJ06NDBYftRUVFOQ+v5v9stW7bYy/bv3294e3sbPXr0sJdd/Ds2DMNIS0szJBkffPCBvSz/3GnRooVx/vx5h/r5z+3du9cwDMP49NNPL3v5YenSpYYk49VXX3Uo79mzp2GxWIw9e/Y49MXLy8uh7IcffjAkGVOnTnXqd+vWrQvc78VtLuj1cKGChsDlYpg//3d38eLh4XHZc6iol0hWrVplSDKWLVvmUN6xY0ejZs2a9sfdunVzOdR+Ofmvx4KWtLQ0e934+HiXl0gKGuYvaJvdu3c3zp49e9m29e3b1/D09DR27959yXqZmZmG1Wo1nnvuOYfyN954w7BYLMb+/fsNwzCMSZMmubxMURjVq1cvsD9JSUn2egVdlsv/G+XqEomrbdavX9/4/fffXbblX//6l8M517NnT+P48eNF7tP1jEsk17np06drzZo1WrNmjT788EO1adNGTzzxhMM7TEkOk6f+/vtvZWZmqmXLltq2bZu9fOnSpbLZbBoxYoQ8PBx/9a6Gjd944w0988wzev311/Xyyy+7bF/37t0VHBxsfxwREaHIyEitXLlSknT48GFt375djz32mCpUqGCv16hRI7Vt29Ze70JPPvmkw+OWLVvqr7/+UlZWlqR/ZqrbbDY99NBDOnbsmH2pUqWK6tSpow0bNrhsqyTZbDYtXbpUXbp0cRhyvfg4rFy5UhEREWrRooX9uXLlyql///7at2+ffv75Z4f14uLiHIbPIyMjZRiG06WGyMhIHTx4UOfPn3coj4qKUpMmTeyPb731VnXr1k2rVq1SXl6eJMff8blz5/TXX3+pdu3a8vf3d/g95+vXr588PT0LPBaS7CM9y5cv17lz51zWWblypTw9PTVo0CCH8ueee06GYTjd1RQdHa1atWrZHzdq1Ei+vr76/fffHeoZhlHo0QvJ8bWQv5hxR9WIESPs20tOTlbv3r01fPhwTZky5aq3ne/ee+9VQECAkpOT7WV///231qxZ4/Cu1d/fX3/88Yc2b958Rfvp37+/0zFas2aNGjRocFXt79atm31bn332mYYNG6aUlBT16dPH6TLZhRYsWKBZs2bpueeeU506dS65D19fX3Xo0EELFy502GZycrLuvvtu3XrrrZL+d85+9tlnstlsRe5LZGSky2PUu3fvIm/rQqGhoQ7n5eTJk5WZmakOHTro6NGjTvWfffZZrVmzRvPmzVOHDh2Ul5fncIn2RsAlkutcRESEwz/C3r17q3Hjxho4cKA6d+5sH25dvny5Xn31VW3fvt3hGv+FweG3336Th4dHof7YfPnll1qxYoVefPFFl/Mu8rn6o3Hbbbdp4cKFkv4Z3pSkunXrOtWrX7++Vq1apezsbJUtW9Zenv+HJF/58uUl/fMH2dfXV7/++qsMwyjwD9alrpMfPXpUWVlZ9ssOBdm/f78iIyNdtjn/+Qu3cXGb/fz8JEkhISFO5TabTZmZmQ6XCwo6jqdPn9bRo0dVpUoVnTlzRklJSZozZ44OHTrk8Ec4MzPTaX1Xd1xcrHXr1nrggQc0evRoTZo0Sffcc4+6d++uPn362O802b9/v4KCgnTLLbcUeCwudPGxkP75Hf7999+Xbc+lXPxaMMsdd9zhcKfAQw89pMzMTA0dOlR9+vRRpUqVrnofpUqV0gMPPKAFCxYoJydHVqtVS5Ys0blz5xwCxosvvqi1a9cqIiJCtWvXVrt27dSnTx+XQ+yu1KlTx6EvZqlWrZrDdrt27aqKFSvq+eef1/Lly9WlSxendb7++mv17dtXMTExGjduXKH2Exsbq6VLlyotLU3NmjXTb7/9pq1btzp8bklsbKzef/99PfHEExo6dKjuu+8+3X///erZs6fTGydXAgICrskxKlu2rMN227dvrxYtWqhp06Z67bXXNGHCBIf69erVU7169ST98walXbt26tKlizZu3HjZeUIlBSMYJYyHh4fatGmjw4cP69dff5X0zwu5a9eu8vb21ttvv62VK1dqzZo1l313cSm333676tatq/nz52vv3r1mduGyCnrXnd8Xm80mi8WilJQUl+9E3n333eJsrqSC23y5vhTF//3f/2ncuHF66KGHtHDhQq1evVpr1qxRxYoVXb6TK8wtgRaLRYsWLVJaWpoGDhyoQ4cO6fHHH1eTJk106tSpIrdRMrfP7nLffffp7Nmz2rRpk2nb7NWrl06ePGkfdVm4cKHq1aunsLAwe5369etr165d+vjjj9WiRQstXrxYLVq0cLrt9npw3333SZLTZGRJ+uGHH9S1a1c1bNhQixYtuuw8jXxdunRRmTJl7G9QFi5cKA8PDz344IP2Oj4+Pvrqq6+0du1aPfroo9qxY4diY2PVtm1b+2jf9aJJkyby8/NzeYwu1rNnT23evFm7d+8uhpYVDwJGCZQ/vJ7/D2Dx4sXy9vbWqlWr9Pjjj6tDhw4uE3qtWrVks9mchvddCQgI0Nq1a1W6dGndd999+vPPP13Wyw85F9q9e7d94mb16tUlSbt27XKqt3PnTgUEBDiMXhRGrVq1ZBiGatSooejoaKfl7rvvLnDdSpUqydfX1+WdLheqXr16gW3Of95MBR3HMmXK2N9BL1q0SPHx8ZowYYJ69uyptm3bqkWLFqbMPL/77rs1btw4bdmyRR999JH++9//6uOPP5b0T1///PNPnTx50mGda3UsrgcXv8bM0KpVK1WtWlXJyck6duyY1q9f73JSX9myZRUbG6s5c+bowIED6tSpk8aNG6ezZ8+a1hYzFHSMfvvtN7Vv316VK1fWypUrVa5cuUJvs2zZsurcubM++eQT2Ww2JScnq2XLlk6fO+Lh4aH77rtPEydO1M8//6xx48Zp/fr1l7w86i55eXmFOo/OnDkjyfVoZElFwChhzp07p9WrV8vLy8s+RO3p6SmLxeKQ3vft26elS5c6rNu9e3d5eHhozJgxTu94Xb27rFatmtauXaszZ86obdu2+uuvv5zqLF26VIcOHbI/3rRpkzZu3KgOHTpIkqpWrarw8HDNmzfP4R/hTz/9pNWrV7v8UKDLuf/+++Xp6anRo0c7tdswDJftzJf/EcjLli3Tli1bnJ7P317Hjh21adMmpaWl2Z/Lzs7We++9p9DQ0Ku+pn2xtLQ0h3kUBw8e1GeffaZ27drZRwQ8PT2d+jt16tSretf2999/O20z/6Oj8y+1dezYUXl5eZo2bZpDvUmTJslisdh/10Vl5m2qZlu+fLkkOYwuXC0PDw/17NlTy5Yt0/z583X+/HmngHHxuevl5aUGDRrIMIwC58i4S/4nT154jNLT09WuXTt5eHho1apVV3R5KTY2Vn/++afef/99/fDDD07H6Pjx407rXHzOXi82bNigU6dOORyjI0eOONU7d+6cPvjgA/n4+Jj+t8WdmINxnfviiy/s7xSPHDmiBQsW6Ndff9XQoUPl6+srSerUqZMmTpyo9u3bq0+fPjpy5IimT5+u2rVra8eOHfZt1a5dW8OHD9fYsWPVsmVL3X///bJardq8ebOCgoLst6ddqHbt2lq9erXuuecexcTEaP369fb95j/fokULPfXUU8rJydHkyZNVsWJFvfDCC/Y6b775pjp06KCoqCj17dvXfpuqn5/fZe8jd6VWrVp69dVXNWzYMO3bt0/du3fXLbfcor179+rTTz9V//79HT5X4GLjx4/X6tWr1bp1a/Xv31/169fX4cOH9cknn+ibb76Rv7+/hg4dqn//+9/q0KGDBg0apAoVKmjevHnau3evFi9eXKhrvUXRsGFDxcTEONymKv1zW3G+zp07a/78+fLz81ODBg2UlpamtWvXOszlKKp58+bp7bffVo8ePVSrVi2dPHlSM2fOlK+vrz38denSRW3atNHw4cO1b98+hYWFafXq1frss8/07LPPOkzoLIqi3qZ64WvhQs2aNSvw8xMK4+uvv7aPDhw/flyff/65vvzyS/Xq1ct+jVySduzYoc8//1yStGfPHmVmZtpv2w4LC3M5D+FisbGxmjp1qkaOHKk77rjD4VZQSWrXrp2qVKmi5s2bKzAwUL/88oumTZumTp06Oc2BcWXbtm368MMPncpr1aqlqKioy65fkN27d9u3e/r0aX333XeaN2+eateubf84dumfeQe///67XnjhBX3zzTf65ptv7M8FBgaqbdu2l91Xx44ddcstt+j555+Xp6enHnjgAYfnx4wZo6+++kqdOnVS9erVdeTIEb399tuqVq2aw6Tsghw6dMjlMSpXrtxVff9KZmamfbvnz5/Xrl279M4779hvX8/3r3/9S1lZWWrVqpWCg4OVnp6ujz76SDt37tSECROKNOJz3Svmu1ZQSK5uzfP29jbCw8ONd955x+G2UsMwjFmzZhl16tQxrFarUa9ePWPOnDn2W6ouNnv2bKNx48aG1Wo1ypcvb7Ru3dpYs2aN/XlXt/pt3LjRuOWWW4xWrVoZp0+fdvjkwAkTJhghISGG1Wo1WrZsafzwww9O+1y7dq3RvHlzw8fHx/D19TW6dOli/Pzzzw51CroF7OJbK/MtXrzYaNGihVG2bFmjbNmyRr169YwBAwYYu3btuuzx3b9/vxEXF2dUqlTJsFqtRs2aNY0BAwYYOTk59jq//fab0bNnT8Pf39/w9vY2IiIijOXLlztsp6BPgyzKbW76/2+h/PDDD+2/w8aNGzt9KuLff/9tJCQkGAEBAUa5cuWMmJgYY+fOnUb16tWN+Pj4y+7b1bHctm2b0bt3b+PWW281rFarUblyZaNz584Ot8waxj+36A4ePNgICgoySpcubdSpU8d48803nc7D/L5c7OI25te92ttUJRlz5sxx2M/V3Kbq5eVl1KtXzxg3bpzDbceXa8fFfSuIzWYzQkJCXN72axiG8e677xqtWrUyKlasaFitVqNWrVrGkCFDjMzMzEtu93K3qV7Yvqu9TdXT09OoVq2a0b9/fyMjI+OSdS9cCvO7zvfwww8bkozo6Gin59atW2d069bNCAoKMry8vIygoCCjd+/el70N1jAufZvqhbcdX+1tqhaLxahQoYLRtWtXY+vWrQ51//3vfxvR0dFGYGCgUapUKaN8+fJGdHS08dlnnxX6+JQUFsMoQTOvgBuQxWLRgAEDnC5BAEBJxhwMAABgOgIGAAAwHQEDAACYzq0B46uvvlKXLl0UFBQki8XidFulK6mpqbrzzjtltVpVu3ZtzZ0795q3E7iWDMNg/gWAG45bA0Z2drbCwsI0ffr0QtXfu3evOnXqpDZt2mj79u169tln9cQTT2jVqlXXuKUAAKAorpu7SCwWiz799NNL3of84osvasWKFQ6fwtirVy+dOHFCKSkpxdBKAABQGCXqg7bS0tKcPgI7JiZGzz77bIHr5OTkOHy6m81m0/Hjx1WxYsUb5gtlAAAoDoZh6OTJkwoKCrrsBw6WqICRnp6uwMBAh7LAwEBlZWXpzJkzLr/cKSkpyeHTEAEAwNU5ePCgqlWrdsk6JSpgXIlhw4YpMTHR/jgzM1O33nqrDh486PCR1wAA4NKysrIUEhJSqI+uL1EBo0qVKsrIyHAoy8jIkK+vb4FfTW21WmW1Wp3KfX19CRgAAFyBwkwxKFGfgxEVFaV169Y5lK1Zs+aqvsQHAACYz60B49SpU9q+fbu2b98u6Z/bULdv327/Cudhw4YpLi7OXv/JJ5+0f1Pfzp079fbbb2vhwoUaPHiwO5oPAAAK4NaAsWXLFjVu3FiNGzeWJCUmJqpx48YaMWKEJOnw4cP2sCFJNWrU0IoVK7RmzRqFhYVpwoQJev/99xUTE+OW9gMAANeum8/BKC5ZWVny8/NTZmYmczAAACiCovwPLVFzMAAAQMlAwAAAAKYjYAAAANMRMAAAgOkIGAAAwHQEDAAAYDoCBgBTTZ8+XaGhofL29lZkZKQ2bdpUYN1z585pzJgxqlWrlry9vRUWFqaUlBSHOl999ZW6dOmioKAgWSwWLV261OW2fvnlF3Xt2lV+fn4qW7as7rrrLofP0UHJ545zy2KxuFzefPNNs7t3wyFgADBNcnKyEhMTNXLkSG3btk1hYWGKiYnRkSNHXNZ/+eWX9e6772rq1Kn6+eef9eSTT6pHjx76/vvv7XWys7MVFham6dOnF7jf3377TS1atFC9evWUmpqqHTt26JVXXpG3t7fpfYR7uOvcOnz4sMMye/ZsWSwWPfDAA6b38YZj3GQyMzMNSUZmZqa7m+JW06ZNM6pXr25YrVYjIiLC2LhxY4F1c3NzjdGjRxs1a9Y0rFar0ahRI+OLL75wqPPll18anTt3NqpWrWpIMj799FOn7SxevNho27atUaFCBUOS8f3335vcK7hbRESEMWDAAPvjvLw8IygoyEhKSnJZv2rVqsa0adMcyu6//37j4Ycfdlm/oHMrNjbWeOSRR6684bjuuevculi3bt2Me++9t/ANv8EU5X8oIxg3IXe9E8jOzlaLFi30+uuvm94nuF9ubq62bt2q6Ohoe5mHh4eio6OVlpbmcp2cnBynUQYfHx998803hd6vzWbTihUrdNtttykmJkaVK1dWZGRkgZdSUPK469y6WEZGhlasWKG+ffte8TZuKsUQeK4rjGC4/53A3r17GcG4AR06dMiQZHz77bcO5UOGDDEiIiJcrtO7d2+jQYMGxu7du428vDxj9erVho+Pj+Hl5eWyvqtz6/Dhw4Yko0yZMsbEiRON77//3khKSjIsFouRmppqSt/gXu46ty72+uuvG+XLlzfOnDlzRf24ETCCgQJdL+8EAEmaMmWK6tSpo3r16snLy0sDBw5UQkKCPDwK/6fJZrNJkrp166bBgwcrPDxcQ4cOVefOnTVjxoxr1XRc58w4ty42e/ZsPfzww8ztKSQCxk3m2LFjysvLU2BgoEN5YGCg0tPTXa4TExOjiRMn6tdff5XNZtOaNWu0ZMkSHT58uDiajBIiICBAnp6eysjIcCjPyMhQlSpVXK5TqVIlLV26VNnZ2dq/f7927typcuXKqWbNmkXab6lSpdSgQQOH8vr163MXyQ3CXefWhb7++mvt2rVLTzzxxBWtfzMiYOCyrsU7Adx4vLy81KRJE61bt85eZrPZtG7dOkVFRV1yXW9vbwUHB+v8+fNavHixunXrVqT93nXXXdq1a5dD+e7du1W9evWidQLXJXedWxeaNWuWmjRporCwsCta/2ZUyt0NQPG6mncCZ8+e1V9//aWgoCANHTr0it8J4MaVmJio+Ph4NW3aVBEREZo8ebKys7OVkJAgSYqLi1NwcLCSkpIkSRs3btShQ4cUHh6uQ4cOadSoUbLZbHrhhRfs2zx16pT27Nljf7x3715t375dFSpU0K233ipJGjJkiGJjY9WqVSu1adNGKSkpWrZsmVJTU4uv87im3HVuSf98Rfknn3yiCRMmFFNvbxDFMCfkusIkz38meQ4cOND+OC8vzwgODi5wkufFcnNzjVq1ahnDhg1z+byY5HlTmzp1qnHrrbcaXl5eRkREhPHdd9/Zn2vdurURHx9vf5yammrUr1/fsFqtRsWKFY1HH33UOHTokMP2NmzYYEhyWi7cjmEYxqxZs4zatWsb3t7eRlhYmLF06dJr2U24gbvOrXfffdfw8fExTpw4cS27VyIU5X+oxTAMwx3Bxl2ysrLk5+enzMxM+fr6urs5bpGcnKz4+Hi9++679ncCCxcu1M6dOxUYGFiodwJ79+7Vtm3b5O/vL8nxnUDjxo01ceJEtWnTxuGdwPHjx3XgwAH9+eef6tSpkz7++GPVrVtXVapUKXD0BABw/SjK/1AukdyEYmNjdfToUY0YMULp6ekKDw9XSkqKfeLngQMHHOZXnD17Vi+//LJ+//13lStXTh07dtT8+fPt4UKStmzZojZt2tgfJyYmSpLi4+M1d+5cSdLnn39uH86UpF69ekmSRo4cqVGjRl2j3gIA3IERDAAAUCiMYAA3kNBhK9zdBFxj+5I6uWW/y/bxhV03ui6hQ9y2b+4zBAAApmMEwyT//v4PdzcB11jvxtXc3QQAKDEYwQAAAKYjYAAAANMRMAAAgOkIGAAAwHQEDAAAYDoCBgAAMB0BAwAAmI6AAQAATEfAAAAApiNgAAAA0xEwAACA6QgYAADAdAQMAABgOgIGAAAwHQEDAACYjoABAABMR8AAAACmI2AAAADTETAAAIDpCBgAAMB0BAwAAGA6AgYAADAdAQMAAJiOgAEAAExHwAAAAKYjYAAAANMRMAAAgOkIGAAAwHRuDxjTp09XaGiovL29FRkZqU2bNl2y/uTJk1W3bl35+PgoJCREgwcP1tmzZ4uptQAAoDDcGjCSk5OVmJiokSNHatu2bQoLC1NMTIyOHDnisv6CBQs0dOhQjRw5Ur/88otmzZql5ORkvfTSS8XccgAAcCluDRgTJ05Uv379lJCQoAYNGmjGjBkqU6aMZs+e7bL+t99+q+bNm6tPnz4KDQ1Vu3bt1Lt378uOegAAgOLltoCRm5urrVu3Kjo6+n+N8fBQdHS00tLSXK7TrFkzbd261R4ofv/9d61cuVIdO3YsljYDAIDCKeWuHR87dkx5eXkKDAx0KA8MDNTOnTtdrtOnTx8dO3ZMLVq0kGEYOn/+vJ588slLXiLJyclRTk6O/XFWVpY5HQAAAAVy+yTPokhNTdX48eP19ttva9u2bVqyZIlWrFihsWPHFrhOUlKS/Pz87EtISEgxthgAgJuT20YwAgIC5OnpqYyMDIfyjIwMValSxeU6r7zyih599FE98cQTkqQ77rhD2dnZ6t+/v4YPHy4PD+e8NGzYMCUmJtofZ2VlETIAALjG3DaC4eXlpSZNmmjdunX2MpvNpnXr1ikqKsrlOqdPn3YKEZ6enpIkwzBcrmO1WuXr6+uwAACAa8ttIxiSlJiYqPj4eDVt2lQRERGaPHmysrOzlZCQIEmKi4tTcHCwkpKSJEldunTRxIkT1bhxY0VGRmrPnj165ZVX1KVLF3vQAAAA7ufWgBEbG6ujR49qxIgRSk9PV3h4uFJSUuwTPw8cOOAwYvHyyy/LYrHo5Zdf1qFDh1SpUiV16dJF48aNc1cXAACACxajoGsLN6isrCz5+fkpMzPT1Msl//7+D9O2hetT78bV3LLf0GEr3LJfFJ99SZ3cst9l+950y35RfLqEDjF1e0X5H1qi7iIBAAAlAwEDAACYjoABAABMR8AAAACmI2AAAADTETAAAIDpCBgAAMB0BAwAAGA6AgYAADAdAQMAAJiOgAEAAExHwAAAAKYjYAAAANMRMAAAgOkIGAAAwHQEDAAAYDoCBgAAMB0BAwAAmI6AAQAATEfAAAAApiNgAAAA0xEwAACA6QgYAADAdAQMAABgOgIGAAAwHQEDAACYjoABAABMR8AAAACmI2AAAADTETAAAIDpCBgAAMB0BAwAAGA6AgYAADAdAQMAAJiOgAEAAExHwAAAAKYjYAAAANMRMAAAgOkIGAAAwHQEDAAAYDoCBgAAMB0BAwAAmI6AAQAATEfAAAAApiNgAAAA0xEwAACA6QgYAADAdAQMAABgOgIGAAAwHQEDAACYjoABAABM5/aAMX36dIWGhsrb21uRkZHatGnTJeufOHFCAwYMUNWqVWW1WnXbbbdp5cqVxdRaAABQGKXcufPk5GQlJiZqxowZioyM1OTJkxUTE6Ndu3apcuXKTvVzc3PVtm1bVa5cWYsWLVJwcLD2798vf3//4m88AAAokFsDxsSJE9WvXz8lJCRIkmbMmKEVK1Zo9uzZGjp0qFP92bNn6/jx4/r2229VunRpSVJoaGhxNhkAABSC2y6R5ObmauvWrYqOjv5fYzw8FB0drbS0NJfrfP7554qKitKAAQMUGBiohg0bavz48crLyytwPzk5OcrKynJYAADAteW2gHHs2DHl5eUpMDDQoTwwMFDp6eku1/n999+1aNEi5eXlaeXKlXrllVc0YcIEvfrqqwXuJykpSX5+fvYlJCTE1H4AAABnbp/kWRQ2m02VK1fWe++9pyZNmig2NlbDhw/XjBkzClxn2LBhyszMtC8HDx4sxhYDAHBzctscjICAAHl6eiojI8OhPCMjQ1WqVHG5TtWqVVW6dGl5enray+rXr6/09HTl5ubKy8vLaR2r1Sqr1Wpu4wEAwCW5bQTDy8tLTZo00bp16+xlNptN69atU1RUlMt1mjdvrj179shms9nLdu/erapVq7oMFwAAwD3ceokkMTFRM2fO1Lx58/TLL7/oqaeeUnZ2tv2ukri4OA0bNsxe/6mnntLx48f1zDPPaPfu3VqxYoXGjx+vAQMGuKsLAADABbfephobG6ujR49qxIgRSk9PV3h4uFJSUuwTPw8cOCAPj/9loJCQEK1atUqDBw9Wo0aNFBwcrGeeeUYvvviiu7oAAABccGvAkKSBAwdq4MCBLp9LTU11KouKitJ33313jVsFAACuRom6iwQAAJQMBAwAAGA6AgYAADAdAQMAAJiOgAEAAExHwAAAAKYjYAAAANMRMAAAgOkIGAAAwHQEDAAAYLoifVR4+fLlZbFYnMr9/Px022236fnnn1fbtm1NaxwAACiZihQwJk+e7LL8xIkT2rp1qzp37qxFixapS5cuZrQNAACUUEUKGPHx8Zd8Pjw8XElJSQQMAABucqbOwejcubN27txp5iYBAEAJZGrAyMnJkZeXl5mbBAAAJZCpAWPWrFkKDw83c5MAAKAEKtIcjMTERJflmZmZ2rZtm3bv3q2vvvrKlIYBAICSq0gB4/vvv3dZ7uvrq7Zt22rJkiWqUaOGKQ0DAAAlV5ECxoYNG65VOwAAwA3kqudg/PHHH/rjjz/MaAsAALhBXFHAsNlsGjNmjPz8/FS9enVVr15d/v7+Gjt2rGw2m9ltBAAAJUyRLpHkGz58uGbNmqXXXntNzZs3lyR98803GjVqlM6ePatx48aZ2kgAAFCyXFHAmDdvnt5//3117drVXtaoUSMFBwfr6aefJmAAAHCTu6JLJMePH1e9evWcyuvVq6fjx49fdaMAAEDJdkUBIywsTNOmTXMqnzZtmsLCwq66UQAAoGS7okskb7zxhjp16qS1a9cqKipKkpSWlqaDBw9q5cqVpjYQAACUPFc0gtG6dWvt3r1bPXr00IkTJ3TixAndf//92rVrl1q2bGl2GwEAQAlzRSMYkhQUFMRkTgAA4FKRAsaOHTsKVa9Ro0ZX1BgAAHBjKFLACA8Pl8VikWEYBdaxWCzKy8u76oYBAICSq0gBY+/evdeqHQAA4AZSpIBRvXp1+89nz57Vjh07dOTIEYePB7dYLA71AADAzeeKJnmmpKQoLi5Ox44dc3qOSyQAAOCKblP9v//7Pz344IM6fPiwbDabw0K4AAAAVxQwMjIylJiYqMDAQLPbAwAAbgBXFDB69uyp1NRUk5sCAABuFFc0B2PatGl68MEH9fXXX+uOO+5Q6dKlHZ4fNGiQKY0DAAAl0xUFjH//+99avXq1vL29lZqaKovFYn/OYrEQMAAAuMldUcAYPny4Ro8eraFDh8rD44qusgAAgBvYFaWD3NxcxcbGEi4AAIBLV5QQ4uPjlZycbHZbAADADeKKLpHk5eXpjTfe0KpVq9SoUSOnSZ4TJ040pXEAAKBkuqKA8eOPP6px48aSpJ9++snhuQsnfAIAgJvTFQWMDRs2mN0OAABwA2GWJgAAMB0BAwAAmI6AAQAATEfAAAAApiNgAAAA0xEwAACA6QgYAADAdNdFwJg+fbpCQ0Pl7e2tyMhIbdq0qVDrffzxx7JYLOrevfu1bSAAACgStweM5ORkJSYmauTIkdq2bZvCwsIUExOjI0eOXHK9ffv26fnnn1fLli2LqaUAAKCw3B4wJk6cqH79+ikhIUENGjTQjBkzVKZMGc2ePbvAdfLy8vTwww9r9OjRqlmzZjG2FgAAFIZbA0Zubq62bt2q6Ohoe5mHh4eio6OVlpZW4HpjxoxR5cqV1bdv38vuIycnR1lZWQ4LAAC4ttwaMI4dO6a8vDwFBgY6lAcGBio9Pd3lOt98841mzZqlmTNnFmofSUlJ8vPzsy8hISFX3W4AAHBpbr9EUhQnT57Uo48+qpkzZyogIKBQ6wwbNkyZmZn25eDBg9e4lQAA4Iq+TdUsAQEB8vT0VEZGhkN5RkaGqlSp4lT/t99+0759+9SlSxd7mc1mkySVKlVKu3btUq1atRzWsVqtslqt16D1AACgIG4dwfDy8lKTJk20bt06e5nNZtO6desUFRXlVL9evXr68ccftX37dvvStWtXtWnTRtu3b+fyBwAA1wm3jmBIUmJiouLj49W0aVNFRERo8uTJys7OVkJCgiQpLi5OwcHBSkpKkre3txo2bOiwvr+/vyQ5lQMAAPdxe8CIjY3V0aNHNWLECKWnpys8PFwpKSn2iZ8HDhyQh0eJmioCAMBNz+0BQ5IGDhyogQMHunwuNTX1kuvOnTvX/AYBAICrwtAAAAAwHQEDAACYjoABAABMR8AAAACmI2AAAADTETAAAIDpCBgAAMB0BAwAAGA6AgYAADAdAQMAAJiOgAEAAExHwAAAAKYjYAAAANMRMAAAgOkIGAAAwHQEDAAAYDoCBgAAMB0BAwAAmI6AAQAATEfAAAAApiNgAAAA0xEwAACA6QgYAADAdAQMAABgOgIGAAAwHQEDAACYjoABAABMR8AAAACmI2AAAADTETAAAIDpCBgAAMB0BAwAAGA6AgYAADAdAQMAAJiOgAEAAExHwAAAAKYjYAAAANMRMAAAgOkIGAAAwHQEDAAAYDoCBgAAMB0BAwAAmI6AAQAATEfAAAAApiNgAAAA0xEwAACA6QgYAADAdAQMAABgOgIGAAAwHQEDAACY7roIGNOnT1doaKi8vb0VGRmpTZs2FVh35syZatmypcqXL6/y5csrOjr6kvUBAEDxc3vASE5OVmJiokaOHKlt27YpLCxMMTExOnLkiMv6qamp6t27tzZs2KC0tDSFhISoXbt2OnToUDG3HAAAFMTtAWPixInq16+fEhIS1KBBA82YMUNlypTR7NmzXdb/6KOP9PTTTys8PFz16tXT+++/L5vNpnXr1hVzywEAQEHcGjByc3O1detWRUdH28s8PDwUHR2ttLS0Qm3j9OnTOnfunCpUqHCtmgkAAIqolDt3fuzYMeXl5SkwMNChPDAwUDt37izUNl588UUFBQU5hJQL5eTkKCcnx/44KyvryhsMAAAKxe2XSK7Ga6+9po8//liffvqpvL29XdZJSkqSn5+ffQkJCSnmVgIAcPNxa8AICAiQp6enMjIyHMozMjJUpUqVS6771ltv6bXXXtPq1avVqFGjAusNGzZMmZmZ9uXgwYOmtB0AABTMrQHDy8tLTZo0cZigmT9hMyoqqsD13njjDY0dO1YpKSlq2rTpJfdhtVrl6+vrsAAAgGvLrXMwJCkxMVHx8fFq2rSpIiIiNHnyZGVnZyshIUGSFBcXp+DgYCUlJUmSXn/9dY0YMUILFixQaGio0tPTJUnlypVTuXLl3NYPAADwP24PGLGxsTp69KhGjBih9PR0hYeHKyUlxT7x88CBA/Lw+N9AyzvvvKPc3Fz17NnTYTsjR47UqFGjirPpAACgAG4PGJI0cOBADRw40OVzqampDo/37dt37RsEAACuSom+iwQAAFyfCBgAAMB0BAwAAGA6AgYAADAdAQMAAJiOgAEAAExHwAAAAKYjYAAAANMRMAAAgOkIGAAAwHQEDAAAYDoCBgAAMB0BAwAAmI6AAQAATEfAAAAApiNgAAAA0xEwAACA6QgYAADAdAQMAABgOgIGAAAwHQEDAACYjoABAABMR8AAAACmI2AAAADTETAAAIDpCBgAAMB0BAwAAGA6AgYAADAdAQMAAJiOgAEAAExHwAAAAKYjYAAAANMRMAAAgOkIGAAAwHQEDAAAYDoCBgAAMB0BAwAAmI6AAQAATEfAAAAApiNgAAAA0xEwAACA6QgYAADAdAQMAABgOgIGAAAwHQEDAACYjoABAABMR8AAAACmI2AAAADTETAAAIDpCBgAAMB0BAwAAGC66yJgTJ8+XaGhofL29lZkZKQ2bdp0yfqffPKJ6tWrJ29vb91xxx1auXJlMbUUAAAUhtsDRnJyshITEzVy5Eht27ZNYWFhiomJ0ZEjR1zW//bbb9W7d2/17dtX33//vbp3767u3bvrp59+KuaWAwCAgrg9YEycOFH9+vVTQkKCGjRooBkzZqhMmTKaPXu2y/pTpkxR+/btNWTIENWvX19jx47VnXfeqWnTphVzywEAQEFKuXPnubm52rp1q4YNG2Yv8/DwUHR0tNLS0lyuk5aWpsTERIeymJgYLV261GX9nJwc5eTk2B9nZmZKkrKysq6y9Y5Onzpp6vZw/TH7nCksW85pt+wXxcdd59bpk2fdsl8UH7PPrfztGYZx2bpuDRjHjh1TXl6eAgMDHcoDAwO1c+dOl+ukp6e7rJ+enu6yflJSkkaPHu1UHhIScoWtxs3qCXc3ADcsv0nubgFuXCOuyVZPnjwpPz+/S9Zxa8AoDsOGDXMY8bDZbDp+/LgqVqwoi8XixpaVbFlZWQoJCdHBgwfl6+vr7ubgBsK5hWuFc+vqGYahkydPKigo6LJ13RowAgIC5OnpqYyMDIfyjIwMValSxeU6VapUKVJ9q9Uqq9XqUObv73/ljYYDX19fXqi4Jji3cK1wbl2dy41c5HPrJE8vLy81adJE69ats5fZbDatW7dOUVFRLteJiopyqC9Ja9asKbA+AAAofm6/RJKYmKj4+Hg1bdpUERERmjx5srKzs5WQkCBJiouLU3BwsJKSkiRJzzzzjFq3bq0JEyaoU6dO+vjjj7Vlyxa999577uwGAAC4gNsDRmxsrI4ePaoRI0YoPT1d4eHhSklJsU/kPHDggDw8/jfQ0qxZMy1YsEAvv/yyXnrpJdWpU0dLly5Vw4YN3dWFm5LVatXIkSOdLj8BV4tzC9cK51bxshiFudcEAACgCNz+QVsAAODGQ8AAAACmI2AAAADTETDgUnp6utq2bauyZcvaPzfEVRlQVJxbuFY4t64vBIyb1GOPPSaLxeK0tG/fXpI0adIkHT58WNu3b9fu3bsLLAsNDbWv6+npqaCgIPXt21d///23fV9nz57VY489pjvuuEOlSpVS9+7di72/KD7FeW6lpqaqW7duqlq1qsqWLavw8HB99NFHxd9pFIviPLd27dqlNm3aKDAwUN7e3qpZs6ZefvllnTt3rvg7XkK5/TZVuE/79u01Z84ch7L827d+++03NWnSRHXq1LE/56pMksaMGaN+/fopLy9Pu3fvVv/+/TVo0CDNnz9fkpSXlycfHx8NGjRIixcvvsa9wvWguM6tb7/9Vo0aNdKLL76owMBALV++XHFxcfLz81Pnzp2vcS/hDsV1bpUuXVpxcXG688475e/vrx9++EH9+vWTzWbT+PHjr3EvbxAGbkrx8fFGt27dXD5XvXp1Q5J9iY+Pd1mWX3fSpEkO648dO9Zo0KBBkfeLG4O7zq18HTt2NBISEkzoCa437j63Bg8ebLRo0cKEntwcGMGAk82bNysuLk6+vr6aMmWKfHx8lJub61TmyqFDh7Rs2TJFRkYWc6tREhTHuZWZman69etfi+bjOnatz609e/YoJSVF999//7Xqwg2HORg3seXLl6tcuXIOy/jx41WpUiVZrVb5+PioSpUq8vPzc1mW78UXX1S5cuXk4+OjatWqyWKxaOLEiW7sGdzNXefWwoULtXnzZvtXDeDGU9znVrNmzeTt7a06deqoZcuWGjNmTHF2t0QjYNzE2rRpo+3btzssTz75ZJG3M2TIEG3fvl07duywfxFdp06dlJeXZ3aTUUK449zasGGDEhISNHPmTN1+++1X3Qdcn4r73EpOTta2bdu0YMECrVixQm+99ZYp/bgZcInkJla2bFnVrl37qrcTEBBg306dOnU0efJkRUVFacOGDYqOjr7q7aPkKe5z68svv1SXLl00adIkxcXFXfV+cf0q7nMrJCREktSgQQPl5eWpf//+eu655+Tp6XnVbbjRMYIB0+W/8M6cOePmluBG4+rcSk1NVadOnfT666+rf//+7moaSrjC/N2y2Ww6d+6cbDZbcTWrRGME4yaWk5Oj9PR0h7JSpUopICCgSNs5efKk0tPTZRiGDh48qBdeeEGVKlVSs2bN7HV+/vln5ebm6vjx4zp58qS2b98uSQoPD7/abuA6VFzn1oYNG9S5c2c988wzeuCBB+z79PLyUoUKFczpDK4rxXVuffTRRypdurTuuOMOWa1WbdmyRcOGDVNsbKxKly5tWn9uZASMm1hKSoqqVq3qUFa3bl3t3LmzSNsZMWKERowYIUmqVKmS7rrrLq1evVoVK1a01+nYsaP2799vf9y4cWNJksGX+d6Qiuvcmjdvnk6fPq2kpCQlJSXZ12vdurVSU1OvrhO4LhXXuVWqVCm9/vrr2r17twzDUPXq1TVw4EANHjzYnI7cBPi6dgAAYDrmYAAAANMRMAAAgOkIGAAAwHQEDAAAYDoCBgAAMB0BAwAAmI6AAQAATEfAAAAApiNgAAAA0xEwAACA6QgYAADAdAQMAABguv8P0kxF9SVTSgUAAAAASUVORK5CYII=\n"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\n\n# 1) Plot Training vs Validation Curves\n# --------------------------------------\nepochs = range(1, len(history.history['loss']) + 1)\n\nplt.figure(figsize=(12,4))\nplt.subplot(1,3,1)\nplt.plot(epochs, history.history['loss'],    label='Train Loss')\nplt.plot(epochs, history.history['val_loss'],label='Val Loss')\nplt.title(\"Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\n\nplt.subplot(1,3,2)\nplt.plot(epochs, history.history['accuracy'],     label='Train Acc')\nplt.plot(epochs, history.history['val_accuracy'], label='Val Acc')\nplt.title(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Acc\")\nplt.legend()\n\nplt.subplot(1,3,3)\nplt.plot(epochs, history.history['mean_iou'],      label='Train mIoU')\nplt.plot(epochs, history.history['val_mean_iou'],  label='Val mIoU')\nplt.title(\"Mean IoU\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"mIoU\")\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n# 2) Compute & Plot ROC on the Test Set\n# -------------------------------------\ny_trues = []\ny_probs = []\n\nfor imgs, masks in test_ds:\n    preds = best.predict(imgs, verbose=0)  # shape (B, H, W, 1)\n    y_trues.append(masks.numpy().ravel())\n    y_probs.append(preds.ravel())\n\ny_true = np.concatenate(y_trues)\ny_score = np.concatenate(y_probs)\n\n# If your test set is large you might subsample:\n# idx = np.random.choice(len(y_true), size=200_000, replace=False)\n# y_true, y_score = y_true[idx], y_score[idx]\n\nfpr, tpr, _ = roc_curve(y_true, y_score)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(6,6))\nplt.plot(fpr, tpr, lw=2, label=f\"ROC AUC = {roc_auc:.3f}\")\nplt.plot([0,1],[0,1], linestyle='--', color='gray')\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve (pixel‑wise)\")\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T10:43:42.275758Z","iopub.execute_input":"2025-06-20T10:43:42.276641Z","iopub.status.idle":"2025-06-20T10:43:42.298637Z","shell.execute_reply.started":"2025-06-20T10:43:42.276610Z","shell.execute_reply":"2025-06-20T10:43:42.297705Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/2695998458.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 1) Plot Training vs Validation Curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# --------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"],"ename":"NameError","evalue":"name 'history' is not defined","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\nimport tensorflow as tf\n\n# Load best EffB3 model for fold 0 (adjust fold number if required)\nmodel = tf.keras.models.load_model(\"EffB3_f0.h5\", compile=False)\nmodel.compile(optimizer=Adam(LR), loss=combined_loss, metrics=metrics)\n\n# Prepare test dataset as before\ntest_imgs = sorted(glob(f\"{BASE}/test/images/*.jpg\"))\ntest_masks = [p.replace(\"/images/\",\"/masks/\").replace(\".jpg\",\".png\") for p in test_imgs]\ntest_ds = make_ds(test_imgs, test_masks, train=False)\n\n# Predict on test set\ny_true = []\ny_pred = []\nfor imgs, masks in test_ds:\n    preds = model.predict(imgs)\n    y_true.extend(masks.numpy().flatten())\n    y_pred.extend(preds.flatten())\n\ny_true = np.array(y_true)\ny_pred = np.array(y_pred)\n\n# Compute ROC curve and AUC\nfpr, tpr, thresholds = roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\n\n# Plot ROC curve\nplt.figure(figsize=(6,6))\nplt.plot(fpr, tpr, label=f\"ROC curve (AUC = {roc_auc:.3f})\")\nplt.plot([0,1], [0,1], 'k--')\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"EffB3 Fold 0 ROC Curve on Test Set\")\nplt.legend(loc=\"lower right\")\nplt.grid(True)\nplt.show()\n\n# Assume 'history_effb3' is the training history for EffB3 fold 0\n# Plot training & validation curves\nep = range(1, len(history_effb3.history['loss']) + 1)\nplt.figure(figsize=(12,4))\n\nplt.subplot(1,3,1)\nplt.plot(ep, history_effb3.history['loss'], label='Train Loss')\nplt.plot(ep, history_effb3.history['val_loss'], label='Val Loss')\nplt.title(\"Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\n\nplt.subplot(1,3,2)\nplt.plot(ep, history_effb3.history['accuracy'], label='Train Acc')\nplt.plot(ep, history_effb3.history['val_accuracy'], label='Val Acc')\nplt.title(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\n\nplt.subplot(1,3,3)\nplt.plot(ep, history_effb3.history['mean_iou'], label='Train mIoU')\nplt.plot(ep, history_effb3.history['val_mean_iou'], label='Val mIoU')\nplt.title(\"Mean IoU\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"mIoU\")\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T10:37:43.591108Z","iopub.status.idle":"2025-06-20T10:37:43.591384Z","shell.execute_reply.started":"2025-06-20T10:37:43.591235Z","shell.execute_reply":"2025-06-20T10:37:43.591246Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}